{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joint-crawford",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-oriental",
   "metadata": {},
   "source": [
    "- There are 333 results in the search for \"Machine Learning\" in *Accident Analysis and Prevention*, the journal that Dr. Sun recommended.\n",
    "- I downloaded most of them over four days.  On the UL Library website, I can download 100 per day.  Since I had them sorted by relevance, towards the end, some of the articles were so old (1970's) that UL's subscription doesn't cover them.\n",
    "- I downloaded the BibTeX citations.  If you set the UL Library website to view 100 results at a time, you can download all 100 citations as one .bib file.  There is no daily limit.\n",
    "- I skimmed 28 of the articles as of Sunday morning, and am continuing to read.\n",
    "    - I kept all of my notes in the .bib file.\n",
    "    - I added an *institution* field for the universities, so I can look for active research hubs.\n",
    "    - If the article had *suggestions for future research*, I added an *addendum* field.\n",
    "    - Most articles used a local (city, state, province) database, but if they used some popular database, like SHRP2, and it wasn't listed in the citation already (in the keywords or abstract), I put it in the keywords, so I can see which databases are popular.\n",
    "    - I read the abstracts and created an *annotation* field.\n",
    "    - About a third of the articles had nothing to do with machine learning, although the article might have been interesting for other reasons.  I put \"Not ML\" somewhere in the annotation.\n",
    "    - About half of the articles I flagged for future review by putting \"Interesting\" somewhere in the annotation.\n",
    "- I treated the .bib file as a database file, and did what we do with datasets.\n",
    "    - Who are the prolific authors?\n",
    "    - What are the most common keywords?\n",
    "    - Which universities are the research hubs?\n",
    "    - Which algorithms, metrics, and databases are most mentioned in the keywords and abstracts?\n",
    "- I also glanced at *Transportation Research, Part C: Emerging Technologies* and ran the same analysis on that dataset.  There are 500 results for a search for \"Machine Learning\" there.  \n",
    "- While there may be differences in how the journals handle keywords, based on the common keywords, I suspect that *Transportation Research, Part C: Emerging Technologies* will be more useful than *Accident Analysis and Prevention*\n",
    "    - AAP (333 Entries):\n",
    "\n",
    "'Machine learning': 32,\n",
    " 'Road safety': 14,\n",
    " 'Safety': 13,\n",
    " 'Traffic safety': 9,\n",
    " 'Deep learning': 9,\n",
    " 'Automated driving': 7,\n",
    " 'Crash severity': 7,\n",
    " 'Data mining': 7,\n",
    " 'Support vector machine': 7,\n",
    " 'Connected vehicles': 6,\n",
    " 'Driving simulator': 6,\n",
    " 'Fatigue': 6,\n",
    " 'Driver behavior': 6,\n",
    " \n",
    "    - TRC (500 Entries):\n",
    "\n",
    "'Machine learning': 44,\n",
    " 'Deep learning': 31,\n",
    " 'None': 18,\n",
    " 'Big data': 15,\n",
    " 'Data mining': 14,\n",
    " 'Clustering': 13,\n",
    " 'Traffic flow': 11,\n",
    " 'Reinforcement learning': 10,\n",
    " 'Prediction': 10,\n",
    " 'Traffic forecasting': 9,\n",
    " 'Autonomous vehicles': 9,\n",
    " 'Social media': 8,\n",
    " 'Car-following': 8,\n",
    " 'Air traffic management': 7,\n",
    " 'Classification': 7,\n",
    " 'GPS': 7,\n",
    " 'Intelligent transportation systems': 7,\n",
    " 'Traffic prediction': 7,\n",
    " 'Neural network': 7,\n",
    " 'Calibration': 7,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-sussex",
   "metadata": {},
   "source": [
    "# Sample Augmented BibTeX File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-albuquerque",
   "metadata": {},
   "source": [
    "@article{IJAZ2021106094,\n",
    "\n",
    "title = {A comparative study of machine learning classifiers for injury severity prediction of crashes involving three-wheeled motorized rickshaw},\n",
    "\n",
    "journal = {Accident Analysis \\& Prevention},\n",
    "\n",
    "volume = {154},\n",
    "\n",
    "pages = {106094},\n",
    "\n",
    "year = {2021},\n",
    "\n",
    "issn = {0001-4575},\n",
    "\n",
    "doi = {https://doi.org/10.1016/j.aap.2021.106094},\n",
    "\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S0001457521001251},\n",
    "\n",
    "author = {Muhammad Ijaz and Liu lan and Muhammad Zahid and Arshad Jamal},\n",
    "\n",
    "keywords = {Three-wheeled motorized rickshaws, Crash severity, Machine learning (ML), Rawalpindi},\n",
    "\n",
    "abstract = {Motorcycles and motorcyclists have a variety of attributes that have been found to be a potential contributor to the high liability of vulnerable road users (VRUs). Vulnerable Road Users (VRUs) that include pedestrians, bicyclists, cycle-rickshaw occupants, and motorcyclists constitute by far the highest share of road traffic accidents in developing countries. Motorized three-wheeled Rickshaws (3W-MR) is a popular public transport mode in almost all Pakistani cities and is used primarily for short trips to carry passengers and small-scale goods movement. Despite being an important mode of public transport in the developing world, little work has been done to understand the factors affecting the injury severity of three-wheeled motorized vehicles. Crash injury severity prediction is a promising research target in traffic safety. Traditional statistical models have underlying assumptions and predefined associations, which can yield misleading results if flouted. Machine learning(ML) is an emerging non-parametric method that can effectively capture the non-linear effects of both continuous and discrete variables without prior assumptions and achieve better prediction accuracy. This research analyzed injury severity of three-wheeled motorized rickshaws (3W-MR) using various machine learning-based identification algorithms, i.e., Decision jungle (DJ), Random Forest (RF), and Decision Tree (DT). Three years of crash data (from 2017 to 2019) was collected from Provincial Emergency Response Service RESCUE 1122 for Rawalpindi city, Pakistan. A total of 2,743 3W-MR crashes were reported during the study period that resulted in 258 fatalities. The predictive performance of proposed ML models was assessed using several evaluation metrics such as overall accuracy, macro-average precision, macro-average recall, and geometric means of individual class accuracies. Results revealed that DJ with an overall accuracy of 83.7 \\% outperformed the DT and RF-based on a stratified 10-fold cross-validation approach. Finally, Spearman correlation analysis showed that factors such as the lighting condition, crashes involving young drivers (aged 20–30 years), facilities with high-speed limits (over 60 mph), weekday, off-peak, and shiny weather conditions were more likely to worsen injury severity of 3W-MR crashes. The outcomes of this study could provide necessary and essential guidance to road safety agencies, particularly in the study area, for proactive implementation of appropriate countermeasures to curb road safety issues pertaining to three-wheeled motorized vehicles.},\n",
    "\n",
    "institution = {Southwest Jiaotong U},\n",
    "\n",
    "annotation = {Nothing new.},\n",
    "\n",
    "addendum = {Future studies could seek more advanced techniques such as ensemble and deep learning on other detailed datasets to explore factors contributing to this VRUs group.}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joined-welcome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\tableofcontents\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-fourth",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-possible",
   "metadata": {},
   "source": [
    "## Parse .bib Files, Choose Journal, and Create Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "combined-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Accident_Analysis_and_Prevention.bib') as bibtex_file:\n",
    "    bib_database = bibtexparser.load(bibtex_file)\n",
    "AAP = pd.DataFrame(bib_database.entries)\n",
    "\n",
    "with open('Transportation_Research_Part_C.bib') as bibtex_file:\n",
    "    bib_database = bibtexparser.load(bibtex_file)\n",
    "TRC = pd.DataFrame(bib_database.entries)\n",
    "\n",
    "P = AAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-suffering",
   "metadata": {},
   "source": [
    "# Fields in .bib File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "academic-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\n",
      "keywords\n",
      "author\n",
      "url\n",
      "doi\n",
      "issn\n",
      "year\n",
      "pages\n",
      "volume\n",
      "journal\n",
      "title\n",
      "ENTRYTYPE\n",
      "ID\n",
      "addendum\n",
      "annotation\n",
      "institution\n",
      "note\n",
      "number\n"
     ]
    }
   ],
   "source": [
    "for row in P:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-regression",
   "metadata": {},
   "source": [
    "# *Accident Analysis and Prevention*\n",
    "## Keywords\n",
    "### Sort Keywords by Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secure-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 None\n",
      "32 Machine learning\n",
      "14 Road safety\n",
      "13 Safety\n",
      "9 Traffic safety\n",
      "9 Deep learning\n",
      "7 Automated driving\n",
      "7 Crash severity\n",
      "7 Data mining\n",
      "7 Support vector machine\n"
     ]
    }
   ],
   "source": [
    "P['keywords'] = P['keywords'].fillna('None')\n",
    "A = [ x.split(', ') for x in P['keywords'].tolist() ]\n",
    "B = [item for sublist in A for item in sublist]\n",
    "C = {x:B.count(x) for x in B}\n",
    "D = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n",
    "for item in D:\n",
    "    if D[item] > 6:\n",
    "        print (D[item], item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-parcel",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "### Create Dictionary of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "encouraging-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithms = {\n",
    "    'ANN:  Artificial Neural Network': ['Artificial Neural Network'],\n",
    "    'Bagging': ['Bagging'],\n",
    "    'Bayesian': ['Bayesian Logistics Regression', 'Bayes'],\n",
    "    'Binomial Regression': ['Binomial Regression'],\n",
    "    'Convex Hull Algorithm': ['Convex Hull'],\n",
    "    'CNN:  Convolutional Neural Network': ['Convolutional Neural Network', 'CNN'],\n",
    "    'CIF: Cumulative Incidence Function': ['Cumulative Incidence Function'],\n",
    "    'Decision Jungle': ['Decision Jungle'],\n",
    "    'Deep Learning': ['Deep Learning', 'deep-learning'],\n",
    "    'Dimensionality Reduction': ['Dimensionality Reduction'],\n",
    "    'Dynamic Bayesian Network': ['Dynamic Bayesian'],\n",
    "    'Ensemble': ['Ensemble'],\n",
    "    'Ensemble Tree': ['Ensemble Tree'],\n",
    "    'Feature Extraction': ['Feature Extraction'],\n",
    "    'Fuzzy Logic': ['Fuzzy Logic'],\n",
    "    'Genetic Algorithm': ['Genetic Algorithm', 'Genetic Programming'],\n",
    "    'Hierarchical': ['Hierarchical'],\n",
    "    'IGA: Intelligent Genetic Algorithm': ['Intelligent Genetic Algorithm'],\n",
    "    'Logistic Regression': ['Logistic Regression'],\n",
    "    'LSTM: Long Short-Term Memory': ['Long Short-term Memory'],\n",
    "    'Marginal Effect Analysis': ['Marginal Effect Analysis'],\n",
    "    'MDU: Maximum Dissimilarity Undersampling': ['maximum dissimilarity undersampling'],\n",
    "    'Mixed Methods': ['Mixed Methods'],\n",
    "    'Neural Network': ['Neural Network'],\n",
    "    'Random Forest':['Random Forest'],\n",
    "    'RSF: Random Survival Forest': ['Random Survival Forest'],\n",
    "    'Self-Organizing Maps': ['Self-Organizing Maps', 'Self Organizing Maps'],\n",
    "    'Shapley': ['Shapley'],\n",
    "    'Statistical Learning': ['Statistical learning'],\n",
    "    'SMO: Synthetic Minority Oversampling': ['synthetic minority oversampling'],\n",
    "    't-SNE': ['t-SNE'],\n",
    "    'VIMP: Variable Importance': ['Variable Importance'],\n",
    "    'XGBoost':['XGBoost', 'XGB'],\n",
    "\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-tours",
   "metadata": {},
   "source": [
    "### Find Mentions of Algorithms in Abstracts or Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worthy-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in Algorithms:\n",
    "    P[alg] = P['abstract'].str.contains('|'.join(Algorithms[alg]), case=False) | P['keywords'].str.contains('|'.join(Algorithms[alg]), case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-passing",
   "metadata": {},
   "source": [
    "### Count Mentions of Algorithms in Abstracts or Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verbal-garden",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bayesian                                    45\n",
       "Neural Network                              33\n",
       "Random Forest                               28\n",
       "Logistic Regression                         19\n",
       "Deep Learning                               16\n",
       "ANN:  Artificial Neural Network              9\n",
       "XGBoost                                      9\n",
       "Hierarchical                                 8\n",
       "CNN:  Convolutional Neural Network           8\n",
       "LSTM: Long Short-Term Memory                 8\n",
       "Genetic Algorithm                            6\n",
       "Ensemble                                     5\n",
       "Feature Extraction                           5\n",
       "SMO: Synthetic Minority Oversampling         4\n",
       "VIMP: Variable Importance                    4\n",
       "Statistical Learning                         4\n",
       "Fuzzy Logic                                  3\n",
       "Dynamic Bayesian Network                     3\n",
       "Binomial Regression                          2\n",
       "Bagging                                      2\n",
       "Shapley                                      2\n",
       "t-SNE                                        1\n",
       "Self-Organizing Maps                         1\n",
       "RSF: Random Survival Forest                  1\n",
       "Decision Jungle                              1\n",
       "Convex Hull Algorithm                        1\n",
       "Mixed Methods                                1\n",
       "MDU: Maximum Dissimilarity Undersampling     1\n",
       "CIF: Cumulative Incidence Function           1\n",
       "IGA: Intelligent Genetic Algorithm           1\n",
       "Ensemble Tree                                1\n",
       "Dimensionality Reduction                     1\n",
       "Marginal Effect Analysis                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = P[Algorithms.keys()].sum()\n",
    "A.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-prisoner",
   "metadata": {},
   "source": [
    "## Analysis Tools\n",
    "### Create Dictionary of Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "higher-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis_Tools = {\n",
    "    'Sensitivity': ['Sensitivity'],\n",
    "    'Area under Curve': ['Area under Curve'],\n",
    "    'False Alarm Rate': ['False Alarm Rate'],\n",
    "    'Accuracy': ['accuracy'],\n",
    "    'Precision': ['macro-average precision'], \n",
    "    'Recall': ['macro-average recall'], \n",
    "    'Geometric Mean': ['geometric mean'],\n",
    "    'Hyperparameters': ['Hyperparameter'],\n",
    "    'Spearman': ['Spearman'],\n",
    "    'Aggregated Gain': ['Aggregated Gain'],\n",
    "    'Time Dependencies': ['Time dependencies'],\n",
    "    'Temporal': ['Temporal'],\n",
    "    'Kinematic': ['Kinematic'],\n",
    "    'Visualization': ['Visualization'],\n",
    "    'F1 Loss Function': ['F1'],\n",
    "    'Connected Vehicles': ['Connected Vehicles'],\n",
    "    'Imbalanced Data': ['Imbalanced Data'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-chick",
   "metadata": {},
   "source": [
    "### Find Mentions of Analysis Tools in Abstracts or Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "preliminary-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in Analysis_Tools:\n",
    "    P[alg] = P['abstract'].str.contains('|'.join(Analysis_Tools[alg]), case=False) | P['keywords'].str.contains('|'.join(Analysis_Tools[alg]), case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-syndication",
   "metadata": {},
   "source": [
    "### Count Mentions of Analysis Tools in Abstracts or Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southwest-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy              72\n",
       "Sensitivity           29\n",
       "Temporal              23\n",
       "Kinematic             10\n",
       "Imbalanced Data        9\n",
       "Connected Vehicles     8\n",
       "False Alarm Rate       6\n",
       "Visualization          4\n",
       "F1 Loss Function       4\n",
       "Geometric Mean         2\n",
       "Hyperparameters        2\n",
       "Aggregated Gain        2\n",
       "Recall                 1\n",
       "Area under Curve       1\n",
       "Time Dependencies      1\n",
       "Precision              1\n",
       "Spearman               1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = P[Analysis_Tools.keys()].sum()\n",
    "A.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-perception",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### Create Dictionary of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "central-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = {\n",
    "    'Second Highway Research Program (Data Set)': ['Second Highway Research Program', 'SHRP2'],\n",
    "    'Virginia 100-car Database': ['Virginia', '100-car', '100 car'],\n",
    "    'NGSIM Trajectory Data': ['NGSIM'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-criminal",
   "metadata": {},
   "source": [
    "### Find Mentions of Dataset in Abstract and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hindu-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in Datasets:\n",
    "    P[x] = P['abstract'].str.contains('|'.join(Datasets[x]), case=False) | P['keywords'].str.contains('|'.join(Datasets[x]), case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-captain",
   "metadata": {},
   "source": [
    "### Count Mentions of Datasets in Abstracts and Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-release",
   "metadata": {},
   "source": [
    "A = P[Datasets.keys()].sum()\n",
    "A.sort_values(ascending=False)\n",
    "\n",
    "## Authors\n",
    "\n",
    "### Sort Authors by Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crude-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Mohamed Abdel-Aty\n",
      "7 Zhibin Li\n",
      "6 Junhua Wang\n",
      "6 Rongjie Yu\n",
      "6 Pan Liu\n",
      "5 Asad J. Khattak\n",
      "5 Ting Fu\n",
      "5 Mohammed Quddus\n",
      "5 Jinghui Yuan\n",
      "5 Mark King\n",
      "5 Chengcheng Xu\n"
     ]
    }
   ],
   "source": [
    "P['author'] = P['author'].fillna('None')\n",
    "A = [ x.split(' and ') for x in P['author'].tolist() ]\n",
    "B = [item for sublist in A for item in sublist]\n",
    "C = {x:B.count(x) for x in B}\n",
    "D = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n",
    "for item in D:\n",
    "    if D[item] > 4:\n",
    "        print (D[item], item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-brave",
   "metadata": {},
   "source": [
    "### Who are these Authors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-casino",
   "metadata": {},
   "source": [
    "### Mohamed Abdel-Aty\n",
    "- U of Central Florida\n",
    "- Editor in Chief Emeritus of the journal\n",
    "- PhD from Davis\n",
    "\n",
    "### Zhibin Li\n",
    "- Southeast University, Nanjing\n",
    "\n",
    "### Junhua Wang\n",
    "- Tongji U, Shanghai\n",
    "\n",
    "### Rongjie Yu\n",
    "- Coauthor with Mohamed Abdel-Aty\n",
    "- Tongji U, Shanghai\n",
    "\n",
    "### Pan Liu\n",
    "- Southeast University, Nanjing\n",
    "- Coauthors:\n",
    "    - Jie Bao (2)\n",
    "    - Satish V. Ukkusuri\n",
    "    - Xiao Qin \n",
    "    - Huaguo Zhou\n",
    "    - Yanyong Guo \n",
    "    - Zhibin Li (2)\n",
    "    - Yao Wu\n",
    "    - Wei Wang (2)\n",
    "    - Chengcheng Xu (2)\n",
    "\n",
    "### Asad J. Khattak\n",
    "- U of Tennessee\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-highlight",
   "metadata": {},
   "source": [
    "## Institutions\n",
    "- Note that the Institutions aren't in the database until I manually add them.\n",
    "### Sort Institutions by Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesser-paradise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'None': 308,\n",
       " 'Louisiana State U': 3,\n",
       " 'Tsinghua U': 2,\n",
       " 'Tongji U': 2,\n",
       " 'U of Central Florida': 2,\n",
       " 'Southeast U': 2,\n",
       " 'Nanjing': 2,\n",
       " 'Queensland U of Technology': 2,\n",
       " 'U of Natural Resources and Life Sciences': 2,\n",
       " 'Vienna': 2,\n",
       " 'North Dakota State U': 1,\n",
       " 'Southwest Jiaotong U': 1,\n",
       " 'Shanghai': 1,\n",
       " 'Hefei U of Technology': 1,\n",
       " 'Changsha U of Technology': 1,\n",
       " 'Nanyang Technological U': 1,\n",
       " 'Oak Ridge National Laboratory': 1,\n",
       " 'Virginia Transportation Research Council': 1,\n",
       " 'Northwestern U': 1,\n",
       " 'Shahid Bahonar U': 1,\n",
       " 'Texas A\\\\&M U': 1,\n",
       " 'Nanyang U': 1,\n",
       " 'City University of Hong Kong': 1,\n",
       " 'Texas A \\\\& M U': 1,\n",
       " 'Federal University of Rio Grade do Sul (Brazil)': 1,\n",
       " 'Federal Rural University of Semi-Arid (Brazil)': 1,\n",
       " 'Jiangsu U': 1,\n",
       " 'Deft U': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'institution'\n",
    "P[x] = P[x].fillna('None')\n",
    "A = [ x.split(', ') for x in P[x].tolist() ]\n",
    "B = [item for sublist in A for item in sublist]\n",
    "C = {x:B.count(x) for x in B}\n",
    "D = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-function",
   "metadata": {},
   "source": [
    "## Interesting Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "approximate-integral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12     A data-driven, kinematic feature-based, near r...\n",
       "71     A deep learning based traffic crash severity p...\n",
       "84     A Bayesian modeling framework for crash severi...\n",
       "106    A hierarchical machine learning classification...\n",
       "124    A multivariate analysis of environmental effec...\n",
       "142    A contextual and temporal algorithm for driver...\n",
       "148    A feature learning approach based on XGBoost f...\n",
       "157    A long short-term memory-based framework for c...\n",
       "161    A methodology to design heuristics for model s...\n",
       "188    A Comprehensive Railroad-Highway Grade Crossin...\n",
       "197    A forward collision avoidance algorithm based ...\n",
       "239    A genetic programming approach to explore the ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P['annotation'] = P['annotation'].fillna('None')\n",
    "Interesting = P[P['annotation'].str.contains('Interesting', case=False)]\n",
    "Interesting['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-bridge",
   "metadata": {},
   "source": [
    "## Not Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "transparent-clock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34     A Bayesian Tobit quantile regression approach ...\n",
       "57     A crash risk identification method for freeway...\n",
       "81     A comparative study of state-of-the-art drivin...\n",
       "84     A Bayesian modeling framework for crash severi...\n",
       "101    A driver behavior assessment and recommendatio...\n",
       "116    A crash prediction method based on bivariate e...\n",
       "130    “It is frustrating to not have control even th...\n",
       "170    A multivariate-based variable selection framew...\n",
       "197    A forward collision avoidance algorithm based ...\n",
       "239    A genetic programming approach to explore the ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = P[P['annotation'].str.contains('Not ML', case=False)]\n",
    "A['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-romance",
   "metadata": {},
   "source": [
    "# *Transportation Research Part C: Emerging Technologies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlikely-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = TRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-solution",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "leading-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Machine learning\n",
      "31 Deep learning\n",
      "18 None\n",
      "15 Big data\n",
      "14 Data mining\n",
      "13 Clustering\n",
      "11 Traffic flow\n",
      "10 Reinforcement learning\n",
      "10 Prediction\n",
      "9 Traffic forecasting\n",
      "9 Autonomous vehicles\n",
      "8 Social media\n",
      "8 Car-following\n",
      "7 Air traffic management\n",
      "7 Classification\n",
      "7 GPS\n",
      "7 Intelligent transportation systems\n",
      "7 Traffic prediction\n",
      "7 Neural network\n",
      "7 Calibration\n"
     ]
    }
   ],
   "source": [
    "P['keywords'] = P['keywords'].fillna('None')\n",
    "A = [ x.split(', ') for x in P['keywords'].tolist() ]\n",
    "B = [item for sublist in A for item in sublist]\n",
    "C = {x:B.count(x) for x in B}\n",
    "D = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n",
    "for item in D:\n",
    "    if D[item] > 6:\n",
    "        print (D[item], item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-helena",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
