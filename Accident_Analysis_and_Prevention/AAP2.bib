@article{HUANG2021105850,
title = {Key drivers of trucking safety climate from the perspective of leader-member exchange: Bayesian network predictive modeling approach},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105850},
year = {2021},
author = {Yueng-hsiang Huang and Yimin He and Jin Lee and Changya Hu},
keywords = {Safety climate, Bayesian network analysis, Leader-member exchange},
abstract = {Purpose
Safety climate, which is defined as workers’ shared perceptions of organizational policies, procedures, and practices as they relate to the true or relative value and importance of safety within an organization, is one of the best indicators of organizational safety outcomes. This study identifies key drivers of safety climate from the perspective of leader-member exchange (LMX). LMX is a theory describing the nature and processes of social interactions between a supervisor and a subordinate. This study examines the impact of individual drivers and combinations of drivers on safety climate through Bayesian Network simulations to predict practices which most effectively improve safety climate in the trucking industry.
Method
Survey data were collected from 5083 truck drivers in a large U.S. trucking company. Bayesian Network analysis was used to identify key drivers (factors) of safety climate and the best joint strategies for improvement. The impact of the drivers on safety climate was assessed and the simulation identified their potential impact independently and in concert with other drivers.
Results
The results from Bayesian Network analyses showed that the effects of LMX on organization- and group-level safety climate were conditionally dependent on four other drivers including psychological ownership, supervisory integrity, situation awareness, and safety communication. Among the five contributing factors, supervisory integrity and LMX had the strongest independent effects on organization- and group-level safety climate. Moreover, the results indicated that the best two joint strategies for promoting organizational (company/top management level) safety climate were LMX and psychological ownership as well as LMX and situation awareness, whereas the best two joint strategies for improving group (workgroup/supervisor level) safety climate were joint optimization of LMX and safety communication as well as LMX and psychological ownership.
Implications
Based on the study results, the strategies that may have the most potential to improve trucking safety climate are: enhancing leaders' ability to engage in high-quality exchanges (e.g., caring about employees), developing training to encourage employees/leaders to deliver on promises, and providing employees with more autonomy to enhance their ownership.},
institution = {Oregon Health and Science U, U of Nebraska, Kansas State U, National Chengchi U},
annotation = {Not our data, Not ML.  Truckers' Opinions of Safety.},
addendum = {},
}

@article{GUO2020105684,
title = {Generalized criteria for evaluating hotspot identification methods},
journal = {Accident Analysis \& Prevention},
volume = {145},
number = {nan},
pages = {105684},
year = {2020},
author = {Xiaoyu Guo and Lingtao Wu and Dominique Lord},
keywords = {Network screening, Hotspot identification method, Performance evaluation, Multiple periods},
abstract = {Hotspot identification (HSID) is one of the most important components in the highway safety management process. Previous research has found that hazardous sites identified with different methods are not consistent. It is therefore necessary to evaluate the performance of various HSID methods. The existing evaluation criteria are limited to two consecutive periods, and do not consider the temporal instability of crashes. In addition, one existing criterion does not precisely evaluate HSID method under given circumstances. This paper proposed three generalized criteria to evaluate the performance of HSID methods: (1) High Crashes Consistency Test (HCCT) is proposed to evaluate HSID methods in terms of their reliabilities of identifying sites with high crash counts; (2) Common Sites Consistency Test (CSCT) is proposed to gauge HSID methods in consistently identifying a set of common sites as hazardous sites; and, (3) Absolute Rank Differences Test (ARDT) is proposed to measure the consistency of HSID methods in measuring the absolute differences in rankings. Further, three commonly used HSID methods are applied to estimate crashes on Texas rural two-lane roadway segments with eight years of crash data. The performance of these three HSID methods were evaluated to validate the proposed criteria. Comparisons between the existing criteria and the generalized criteria revealed that: (1) the generalized criteria are capable of evaluating different HSID methods over multiple periods; and (2) the generalized criteria are enhanced with a consistent result and with less discrepancy in scores of the best identified HSID method.},
institution = {Texas A\&M},
annotation = {Not ML},
addendum = {},
}

@article{KERAMATI2020105683,
title = {A crash severity analysis at highway-rail grade crossings: The random survival forest method},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105683},
year = {2020},
author = {Amin Keramati and Pan Lu and Amirfarrokh Iranitalab and Danguang Pan and Ying Huang},
keywords = {Accident prediction, Railroad grade crossing, Machine learning, Random survival forests},
abstract = {This paper proposes a machine learning approach, the random survival forest (RSF) for competing risks, to investigate highway-rail grade crossing (HRGC) crash severity during a 29-year analysis period. The benefits of the RSF approach are that it (1) is a special type of survival analysis able to accommodate the competing nature of multiple-event outcomes to the same event of interest (here the competing multiple events are crash severities), (2) is able to conduct an event-specific selection of risk factors, (3) has the capability to determine long-term cumulative effects of contributors with the cumulative incidence function (CIF), (4) provides high prediction performance, and (5) is effective in high-dimensional settings. The RSF approach is able to consider complexities in HRGC safety analysis, e.g., non-linear relationships between HRGCs crash severities and the contributing factors and heterogeneity in data. Variable importance (VIMP) technique is adopted in this research for selecting the most predictive contributors for each crash-severity level. Moreover, marginal effect analysis results real several HRGC countermeasures’ effectiveness. Several insightful findings are discovered. For examples, adding stop signs to HRGCs that already have a combination of gate, standard flashing lights, and audible devices will reduce the likelihood of property damage only (PDO) crashes for up to seven years; but after the seventh year, the crossings are more likely to have PDO crashes. Adding audible devices to crossing with gates and standard flashing lights will reduce crash likelihood, PDO, injury, and fatal crashes by 49 \%, 52 \%, 46 \%, and 50 \%, respectively.},
institution = {North Dakota State U},
annotation = {Highway-Rail Grade Crossing, found two correlated countermeasures, with temporal effects.},
addendum = {None},
}

@article{GRAHN2020105717,
title = {Expert Drivers’ Prospective Thinking-Aloud to Enhance Automated Driving Technologies – Investigating Uncertainty and Anticipation in Traffic},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105717},
year = {2020},
author = {Hilkka Grahn and Tuomo Kujala and Johanna Silvennoinen and Aino Leppänen and Pertti Saariluoma},
keywords = {Automated driving, expert driver, prospective thinking-aloud, traffic safety, uncertainty, anticipation},
abstract = {Current automated driving technology cannot cope in numerous conditions that are basic daily driving situations for human drivers. Previous studies show that profound understanding of human drivers’ capability to interpret and anticipate traffic situations is required in order to provide similar capacities for automated driving technologies. There is currently not enough a priori understanding of these anticipatory capacities for safe driving applicable to any given driving situation. To enable the development of safer, more economical, and more comfortable automated driving experience, expert drivers’ anticipations and related uncertainties were studied on public roads. First, driving instructors’ expertise in anticipating traffic situations was validated with a hazard prediction test. Then, selected driving instructors drove in real traffic while thinking aloud anticipations of unfolding events. The results indicate sources of uncertainty and related adaptive and social behaviors in specific traffic situations and environments. In addition, the applicability of these anticipatory capabilities to current automated driving technology is discussed. The presented method and results can be utilized to enhance automated driving technologies by indicating their potential limitations and may enable improved situation awareness for automated vehicles. Furthermore, the produced data can be utilized for recognizing such upcoming situations, in which the human should take over the vehicle, to enable timely take-over requests.},
institution = {U of Jyväskylä},
annotation = {Not ML, Not our data.},
addendum = {},
}

@article{SONG2020105638,
title = {Combined latent class and partial proportional odds model approach to exploring the heterogeneities in truck-involved severities at cross and T-intersections},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105638},
year = {2020},
author = {Li Song and Wei Fan},
keywords = {Severity analysis, Truck crashes, Intersection, Latent class clustering, Partial proportional odds model},
abstract = {Although the fatal rate of passenger vehicle-involved crashes has decreased in the United States, the fatal rate of truck-involved crashes has increased. This has, in recent years, become a more severe problem than that caused by passenger vehicle-involved crashes. More studies need to be conducted in order to investigate factors that impact the severity of truck-involved crashes within specific scenarios. This study identifies and evaluates the factors that affect the severity of the truck-involved crashes at cross and T-intersections in North Carolina from 2005 to 2017. A latent class clustering for data segmentation is implemented to mitigate unobserved heterogeneity inherent in the crash data. Four partial proportional odds models, which include fixed and unfixed parameters, are developed considering the heterogeneous and ordinal nature inherent in severities. Estimated parameters and marginal effects are further investigated for better interpreting the impacts. Results show heterogeneous explanatory variables and associated coefficients for different classes and severity levels, which indicate the superiority of this combined approach to obtaining more specific factors and accurate coefficients that are estimated in different scenarios. Many factors are found to contribute to the severities, and crossroad scenarios are found to be more severe than T-intersections. The top five driving behaviors at intersections that contribute to the severity include disregarded signs, improper lane use, followed too closely, ignored signals, and failure to yield. These behaviors arouse a necessity to amend the traffic laws and strengthen drivers’ education while giving further insights to engineering practitioners and researchers.},
institution = {UNC Charlotte},
annotation = {Not ML},
addendum = {In summary, future research could explore the cause of the
heterogeneities within variables and between classes, and study the
correlation between different factors, as well as include external data
for a better understanding of the impact and the transferability of the
factors.},
}

@article{TSELENTIS2021106081,
title = {Temporal analysis of driving efficiency using smartphone data},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106081},
year = {2021},
author = {Dimitrios I. Tselentis and Eleni I. Vlahogianni and George Yannis},
keywords = {Driving behavior, Driving safety efficiency, Temporal evolution, K-means clustering, Smartphone data},
abstract = {This paper attempts to shed light on the temporal evolution of driving safety efficiency with the aim to acquire insights useful for both driving behavior and road safety improvement. Data exploited herein are collected from a sophisticated platform that uses smartphone device sensors during a naturalistic driving experiment, at which the driving behavior from a sample of two hundred (200) drivers during 7-months is continuously recorded in real time. The main driving behavior analytics taken into consideration for the driving assessment include distance travelled, acceleration, braking, speed and smartphone usage. The analysis is performed using statistical, optimization and machine learning techniques. The driver’s safety efficiency index is estimated both in total and in several consecutive time windows to allow for the investigation of safety efficiency evolution in time. Initial data analysis results to the most critical components of microscopic driving behaviour evolution, which are used as inputs in the k-means algorithm to perform the clustering analysis. The main driving characteristics of each cluster are identified and lead to the conclusion that there are three main driving groups of the a) moderate drivers, b) unstable drivers and c) cautious drivers.},
institution = {National Technical U of Athens},
annotation = {Interesting if we want to study types of drivers and whether that predicts crashes.  
Driving safety efficiency in this study
refers to the amount of driving events (harsh braking, harsh acceleration,
mobile phone usage, speeding) occurred during a certain driving
period (Tselentis et al., 2019). The most efficient drivers are those with
the least number of events.},
addendum = {},
}

@article{VANDERWALL2020105822,
title = {The use of machine learning improves the assessment of drug-induced driving behaviour},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105822},
year = {2020},
author = {H.E.C. {van der Wall} and R.J. Doll and G.J.P. {van Westen} and I. Koopmans and R.G. Zuiker and J. Burggraaf and A.F. Cohen},
keywords = {Safety, Machine learning, Automobile driving, Driving under the influence},
abstract = {Rationale
Car-driving performance is negatively affected by the intake of alcohol, tranquillizers, sedatives and sleep deprivation. Although several studies have shown that the standard deviation of the lateral position on the road (SDLP) is sensitive to drug-induced changes in simulated and real driving performance tests, this parameter alone might not fully assess and quantify deviant or unsafe driving.
Objective
Using machine learning we investigated if including multiple simulator-derived parameters, rather than the SDLP alone would provide a more accurate assessment of the effect of substances affecting driving performance. We specifically analysed the effects of alcohol and alprazolam.
Methods
The data used in the present study were collected during a previous study on driving effects of alcohol and alprazolam in 24 healthy subjects (12 M, 12 F, mean age 26 years, range 20–43 years). Various driving features, such as speed and steering variations, were quantified and the influence of administration of alcohol or alprazolam was assessed to assist in designing a predictive model for abnormal driving behaviour.
Results
Adding additional features besides the SDLP increased the model performance for prediction of drug-induced abnormal driving behaviour (from an accuracy of 65 \%–83 \% after alprazolam intake and from 50 \% to 76 \% after alcohol ingestion). Driving behaviour influenced by alcohol and alprazolam was characterised by different feature importance, indicating that the two interventions influenced driving behaviour in a different way.
Conclusion
Machine learning using multiple driving features in addition to the state-of-the-art SDLP improves the assessment of drug-induced abnormal driving behaviour. The created models may facilitate quantitative description of abnormal driving behaviour in the development and application of psychopharmacological medicines. Our models require further validation using similar and unknown interventions.},
institution = {Leiden U},
annotation = {Not our data},
addendum = {},
}

@article{YAHAYA2021105851,
title = {Ensemble-based model selection for imbalanced data to investigate the contributing factors to multiple fatality road crashes in Ghana},
journal = {Accident Analysis \& Prevention},
volume = {151},
number = {nan},
pages = {105851},
year = {2021},
author = {Mahama Yahaya and Runhua Guo and Xinguo Jiang and Kamal Bashir and Caroline Matara and Shiwei Xu},
keywords = {Multiple fatal injury crash, Classification, Model selection, Class imbalance, Oversampling, Ensemble classifiers},
abstract = {The study aims to identify relevant variables to improve the prediction performance of the crash injury severity (CIS) classification model. Unfortunately, the CIS database is invariably characterized by the class imbalance. For instance, the samples of multiple fatal injury (MFI) severity class are typically rare as opposed to other classes. The imbalance phenomenon may introduce a prediction bias in favour of the majority class and affect the quality of the learning algorithm. The paper proposes an ensemble-based variable ranking scheme that incorporates the data resampling. At the data pre-processing level, majority weighted minority oversampling (MWMOTE) is employed to treat the imbalanced training data. Ensemble of classifiers induced from the balanced data is used to evaluate and rank the individual variables according to their importance to the injury severity prediction. The relevant variables selected are then applied to the balanced data to form a training set for the CIS classification modelling. An empirical comparison is conducted through considering the variable ranking by: 1) the learning of single inductive algorithm with imbalanced data where the relevant variables are applied to the imbalanced data to form the training data; 2) the learning of single inductive algorithm with MWMOTE data and the relevant variables identified are applied to the balanced data to form the training data; and 3) the learning of ensembles with imbalanced data where the relevant variables identified are applied to the imbalanced data to form the training data. Bayesian Networks (BNs) classifiers are then developed for each ranking method, where nested subsets of the top ranked variables are adopted. The model predictions are captured in four performance indicators in the comparative study. Based on three-year (2014–2016) crash data in Ghana, the empirical results show that the proposed method is effective to identify the most prolific predictors of the CIS level. Finally, based on the inference results of BNs developed on the best subset, the study offers the most probable explanations to the occurrence of MFI crashes in Ghana.},
institution = {Southwest Jiaotong U, Tsinghua U, Taiyuan U of Science and Technology},
annotation = {Not ML.  Interesting for different methods for imbalanced data.},
addendum = {Our future work will
devise a framework to simultaneously handle crash data imbalance and
noise, since their presence is counterproductive for prediction and data
analysis (Drummond and Holte, 2005; Saez et al., 2015).},
}

@article{IJAZ2021106094,
title = {A comparative study of machine learning classifiers for injury severity prediction of crashes involving three-wheeled motorized rickshaw},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106094},
year = {2021},
author = {Muhammad Ijaz and Liu lan and Muhammad Zahid and Arshad Jamal},
keywords = {Three-wheeled motorized rickshaws, Crash severity, Machine learning (ML), Rawalpindi},
abstract = {Motorcycles and motorcyclists have a variety of attributes that have been found to be a potential contributor to the high liability of vulnerable road users (VRUs). Vulnerable Road Users (VRUs) that include pedestrians, bicyclists, cycle-rickshaw occupants, and motorcyclists constitute by far the highest share of road traffic accidents in developing countries. Motorized three-wheeled Rickshaws (3W-MR) is a popular public transport mode in almost all Pakistani cities and is used primarily for short trips to carry passengers and small-scale goods movement. Despite being an important mode of public transport in the developing world, little work has been done to understand the factors affecting the injury severity of three-wheeled motorized vehicles. Crash injury severity prediction is a promising research target in traffic safety. Traditional statistical models have underlying assumptions and predefined associations, which can yield misleading results if flouted. Machine learning(ML) is an emerging non-parametric method that can effectively capture the non-linear effects of both continuous and discrete variables without prior assumptions and achieve better prediction accuracy. This research analyzed injury severity of three-wheeled motorized rickshaws (3W-MR) using various machine learning-based identification algorithms, i.e., Decision jungle (DJ), Random Forest (RF), and Decision Tree (DT). Three years of crash data (from 2017 to 2019) was collected from Provincial Emergency Response Service RESCUE 1122 for Rawalpindi city, Pakistan. A total of 2,743 3W-MR crashes were reported during the study period that resulted in 258 fatalities. The predictive performance of proposed ML models was assessed using several evaluation metrics such as overall accuracy, macro-average precision, macro-average recall, and geometric means of individual class accuracies. Results revealed that DJ with an overall accuracy of 83.7 \% outperformed the DT and RF-based on a stratified 10-fold cross-validation approach. Finally, Spearman correlation analysis showed that factors such as the lighting condition, crashes involving young drivers (aged 20–30 years), facilities with high-speed limits (over 60 mph), weekday, off-peak, and shiny weather conditions were more likely to worsen injury severity of 3W-MR crashes. The outcomes of this study could provide necessary and essential guidance to road safety agencies, particularly in the study area, for proactive implementation of appropriate countermeasures to curb road safety issues pertaining to three-wheeled motorized vehicles.},
institution = {Southwest Jiaotong U},
annotation = {Nothing new.},
addendum = {Future studies could seek more advanced techniques such as ensemble and deep learning on other detailed datasets to explore factors contributing to this VRUs group.},
}

@article{HYUN2021105858,
title = {Understanding the effects of vehicle platoons on crash type and severity},
journal = {Accident Analysis \& Prevention},
volume = {149},
number = {nan},
pages = {105858},
year = {2021},
author = {Kyung (Kate) Hyun and Suman Kumar Mitra and Kyungsoo Jeong and Andre Tok},
keywords = {Vehicle platoon, Interaction, Crash type, Severity, GSEM},
abstract = {Crash type is an informative indicator to infer driving behaviors and conditions that cause a crash. For example, rear-end and side-swipe crashes are typically caused by improper vehicle interaction such as sudden lane-changing or speed control while hit-object crashes are likely the result of a single driver’s mistake. This study investigated the impact of vehicles travelling as a group (platoon) and its configuration (i.e., types of vehicles consisting of the platoon) on crash type and severity since the vehicles could affect each other when travelling in close proximity. This study applied Generalized Structure Equation Modeling (GSEM) to capture the complex relationships among the various crash factors such as traffic condition, driver characteristics, environmental conditions, and vehicle interaction to the crash attributes including type and severity. This study collected over 3 million individual vehicle data from 39 traffic count sites in California to estimate the vehicle interactions and driving behaviors. The microscopic traffic data are matched to 1417 crash reports. Results showed that vehicles traveling in platoons are associated with more rear-end and side-swipe crashes. Speed difference in the platoon had a positive effect on hit-object crashes if the platoon comprises vehicles of homogeneous type – either trucks or non-trucks. In addition, human factors such as age and gender were identified as significant influential factors in all type of crashes, however truck involvement particularly played an important role amongst side-swipe crashes. Crash severity was negatively affected by total flow, and rear-end crashes were more likely to be severe compared with hit-object crashes. Based on findings, this study suggests practical operational strategies to reduce traffic instability associated with platooned vehicle patterns. Understanding the high-risk factors for different crash types and severities would provide valuable insights for decision-makers and transportation engineers to develop targeted intervention strategies in consideration of road users and traffic conditions such as fleet mix and speed.},
institution = {},
annotation = {},
addendum = {},
}

@article{FURLAN2020105741,
title = {Advanced vehicle technologies and road safety: A scoping review of the evidence},
journal = {Accident Analysis \& Prevention},
volume = {147},
number = {nan},
pages = {105741},
year = {2020},
author = {Andrea D. Furlan and Tara Kajaks and Margaret Tiong and Martin Lavallière and Jennifer L. Campos and Jessica Babineau and Shabnam Haghzare and Tracey Ma and Brenda Vrkljan},
keywords = {Advanced vehicle technologies, Advanced driver assistance systems, Driving, Drivers, Age},
abstract = {The proliferation of Advanced Vehicle Technologies (AVTs) has generated both excitement and concern among researchers, policymakers, and the general public. An increasing number of driver assistance systems are already available in today’s automobiles; many of which are expected to become standard. Therefore, synthesizing the available evidence specific to the safety of AVTs is critical. The goal of this scoping review was to summarize this evidence with a focus on AVTs that require some driver oversight (i.e., Levels 0–3 as per the Society of Automotive Engineers (SAE) levels of automation taxonomy). A scoping review of research literature on AVTs was conducted for studies up to March 2018. Inclusion criteria consisted of: any study with empirical data of AVTs that included male and female drivers aged 16 years and older, healthy people (i.e., without impairments), passenger vehicles, driving simulators and/or large databases with road safety information that could be analyzed for the purpose of examining AVTs (SAE Levels 0–3), as well as measures of driving outcomes. A total of 324 peer-reviewed studies from 25 countries met the inclusion criteria for this review with over half published in the last 5 years. Data was extracted and summarized according to the following categories: measures used to evaluate the effect of AVTs on road safety (objective) and driver perceptions of the technology (subjective), testing environment, and study populations (i.e., driver age). The most commonly reported objective measures were longitudinal control (50 \%), reaction time (40 \%), and lateral position (23 \%). The most common subjective measures were perceptions of trust (27 \%), workload (20 \%), and satisfaction (17 \%). While most studies investigated singular AVTs (237 of 324 studies), the number of studies after 2013 that examined 2 or more AVTs concurrently increased. Studies involved drivers from different age groups (51 \%) and were conducted in driving simulators (70 \%). Overall, the evidence is generally in favour of AVTs having a positive effect on driving safety, although the nature and design of studies varied widely. Our examination of this evidence highlights the opportunities as well as the challenges involved with investigating AVTs. Ensuring such technologies are congruent with the needs of drivers, particularly younger and older driver age groups, who are known to have a higher crash risk, is critical. With automotive manufacturers keen to adopt the latest AVTs, this scoping review highlights how testing of this technology has been undertaken, with a focus on how new research can be conducted to improve road safety now and in the future.},
institution = {U of Toronto, McMaster U, U of New South Wales},
annotation = {Not ML},
addendum = {},
}

@article{WALI2021105835,
title = {Injury severity analysis of pedestrian and bicyclist trespassing crashes at non-crossings: A hybrid predictive text analytics and heterogeneity-based statistical modeling approach},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105835},
year = {2021},
author = {Behram Wali and Asad J. Khattak and Numan Ahmad},
keywords = {Non-motorist trespassing crashes, Non-crossings, Injury severity, Machine learning, Text analysis, Concept/Entity extraction, Dynamic factor analysis, Heterogeneity-based discrete outcome modeling},
abstract = {Non-motorists involved in rail-trespassing crashes are usually more vulnerable to receiving major or fatal injuries. Previous research has used traditional quantitative crash data for understanding factors contributing to injury outcomes of non-motorists in train involved collisions. However, usually overlooked crash narratives can provide useful and unique contextual crash-specific information regarding factors associated with injury outcomes. The main objective of this study is to harness the rapid advancements in more sophisticated qualitative analysis procedures for identifying thematic concepts in unstructured crash narrative data. A two-staged hybrid approach is proposed where text mining is applied first to extract valuable information from crash narratives followed by inclusion of the new variables derived from text mining in formulation of advanced statistical models for injury outcomes. By using ten-year (2006−2015) non-motorist non-crossing trespassing injury data obtained from the Federal Railroad Administration, statistical procedures and advanced machine learning text analytics are applied to extract unique information on contributory factors of trespassers’ injury outcomes. The key concepts are systematically categorized into trespasser, injury, train, medical, and location related factors. A total of 13 unique variables are extracted from the thematic concepts that are not present in traditional tabular crash data. The analysis reveals a positive statistically significant association between presence of crash narrative and trespasser’s injury outcome (coded as minor, major, and fatal injury). Compared to crashes with minor injuries, crashes involving major and fatal injuries are more likely to be reported with crash narratives. A crosstabulation of new variables derived from text mining with injury outcomes revealed that trespassers with confirmed suicide attempts, trespassers wearing headphones, or talking on cell phones are more likely to receive fatal injuries. Among other factors identified, trespassers under alcohol influence, trespasser hit by commuter train, and advance warnings by engineer are associated with more severe (major and fatal) trespasser injury outcomes. Accounting for unobserved heterogeneity and controlling for other factors, fixed and random parameter discrete outcome models are developed to understand the heterogeneous correlations between trespasser injury outcomes and the new crash specific explanatory variables derived from text mining – providing deeper insights. Practical implications and future research directions are discussed.},
institution = {U of Tennessee},
annotation = {Not our data.  Text analytics of crash narratives.  Railroad crossings.},
addendum = {Thus, in future, with the availability of more crash
narrative data, the methodology in this study can be expanded to account
for potential temporal heterogeneity – allowing even better
interpretation of crash narrative data-analysis findings.},
}

@article{WANG2021106149,
title = {A data-driven, kinematic feature-based, near real-time algorithm for injury severity prediction of vehicle occupants},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106149},
year = {2021},
author = {Qingfan Wang and Shun Gan and Wentao Chen and Quan Li and Bingbing Nie},
keywords = {Motor vehicle crashes, Occupant protection, Injury risk, Prediction models, Machine-learning algorithms},
abstract = {Accurate real-time prediction of occupant injury severity in unavoidable collision scenarios is a prerequisite for enhancing road traffic safety with the development of highly automated vehicles. Specifically, a safety prediction model provides a decision reference for the trajectory planning system in the pre-crash phase and the adaptive restraint system in the in-crash phase. The main goal of the current study is to construct a data-driven, vehicle kinematic feature-based model to realize accurate and near real-time prediction of in-vehicle occupant injury severity. A large-scale numerical database was established focusing on occupant kinetics. A first-step deep-learning model was established to predict occupant kinetics and injury severity using a convolutional neural network (CNN). To reduce the computational time for real-time application, the second step was to extract simplified kinematic features from vehicle crash pulses via a feature extraction method, which was inspired by a visualization approach applied to the CNN-based model. The features were incorporated with a low-complexity machine-learning algorithm and achieved satisfactory accuracy (85.4 \% on the numerical database, 78.7 \% on a 192-case real-world dataset) and decreased computational time (1.2 ± 0.4 ms) on the prediction tasks. This study demonstrated the feasibility of using data-driven and feature-based approaches to achieve accurate injury risk estimation prior to collision. The proposed model is expected to provide a decision reference for integrated safety systems in the next generation of automated vehicles.},
institution = {Tsinghua U},
annotation = {Interesting.  Numerical database of simulations.  },
addendum = {None},
}

@article{ESSA2020105713,
title = {Self-learning adaptive traffic signal control for real-time safety optimization},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105713},
year = {2020},
author = {Mohamed Essa and Tarek Sayed},
keywords = {Adaptive traffic signal control, Real-time safety optimization, Connected vehicles, Reinforcement learning, Traffic simulation, Real-time safety models},
abstract = {Adaptive traffic signal control (ATSC) is a promising technique to improve the efficiency of signalized intersections, especially in the era of connected vehicles (CVs) when real-time information on vehicle positions and trajectories is available. Numerous ATSC algorithms have been proposed to accommodate real-time traffic conditions and optimize traffic efficiency. The common objective of these algorithms is to minimize total delay, decrease queue length, or maximize vehicle throughput. Despite their positive impacts on traffic mobility, the existing ATSC algorithms do not consider optimizing traffic safety. This is most likely due to the lack of tools to evaluate safety in real time. However, recent research has developed various real-time safety models for signalized intersections. These models can be used to evaluate safety in real time using dynamic traffic parameters, such as traffic volume, shock wave characteristics, and platoon ratio. Evaluating safety in real time can enable developing ATSC strategies for real-time safety optimization. In this paper, we present a novel self-learning ATSC algorithm to optimize the safety of signalized intersections. The algorithm was developed using the Reinforcement Learning (RL) approach and was trained using the simulation platform VISSIM. The trained algorithm was then validated using real-world traffic data obtained from two signalized intersections in the city of Surrey, British Columbia. Compared to the traditional actuated signal control system, the proposed algorithm reduces traffic conflicts by approximately 40 \%. Moreover, the proposed ATSC algorithm was tested under various market penetration rates (MPRs) of CVs. The results showed that 90 \% and 50 \% of the algorithm’s safety benefits can be achieved at MPR values of 50 \% and 30 \%, respectively. To the best of the authors’ knowledge, this is the first self-learning ATSC algorithm that optimizes traffic safety in real time.},
institution = {U of British Columbia},
annotation = {Reinforcement Learning},
addendum = {},
}

@article{LIAN2020105711,
title = {Review on big data applications in safety research of intelligent transportation systems and connected/automated vehicles},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105711},
year = {2020},
author = {Yanqi Lian and Guoqing Zhang and Jaeyoung Lee and Helai Huang},
keywords = {Big Data, Data mining, Machine learning, Traffic safety, Intelligent transportation systems, Connected and automated vehicles},
abstract = {The era of Big Data has arrived. Recently, under the environment of intelligent transportation systems (ITS) and connected/automated vehicles (CAV), Big Data has been applied in various fields in transportation including traffic safety. In this study, we review recent research studies that employed Big Data to analyze traffic safety under the environment of ITS and CAV. The particular topics include crash detection or prediction, discovery of contributing factors to crashes, driving behavior analysis, crash hotspot identification, etc. From the reviewed studies, employing advanced analytics for Big Data has a great potential for understanding and enhancing traffic safety. Big Data application in traffic safety integrates and processes massive multi-source data, breaks through the limitations of the traditional data analytics, and discovers and solves the problems, which cannot be solved by the traditional safety analytics. Lastly, suggestions are provided for future Big Data safety analytics under the environment of ITS and CAV.},
institution = {Central South U (Changsha)},
annotation = {Not our data.},
addendum = {},
}

@article{SHANGGUAN2021106122,
title = {An integrated methodology for real-time driving risk status prediction using naturalistic driving data},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106122},
year = {2021},
author = {Qiangqiang Shangguan and Ting Fu and Junhua Wang and Tianyang Luo and Shou’en Fang},
keywords = {Driving risk status prediction, Rolling time window approach, Naturalistic driving data, Car-following events, Machine learning algorithms},
abstract = {Real-time driving risk status prediction is critical for developing proactive traffic intervention strategies and enhance driving safety. However, the optimal observation time window length and prediction time window length, which should be the prerequisite for the timeliness and accuracy of real-time driving risk status prediction model, have been rarely explored in previous studies. In this study, a methodology which integrates driving risk status identification, rolling time window-based feature extraction, real-time driving risk status prediction and driving risk influencing factors analysis was proposed to accurately evaluate and predict real-time driving risk status. The methodology was tested based on 1,440 car-following events from Shanghai Naturalistic Driving Study. Results show that four driving risk statuses (safe, low-risk, median-risk and high-risk) are most appropriate to establish risk labelling criteria. In addition, results from driving risk status prediction show that when the observation time window length is 0.5 s, the accuracy rate of predicting medium-risk or high-risk status occurring in the next 0.7 s is higher than 85 \% using multi-layer perceptron model. Meanwhile, the results from the analysis of influencing factors show that the input variables related to the risk status score higher in the ranking of feature importance. A part from that, speed difference, headway distance, speed and acceleration are still important in predicting driving risk status. The proposed methods in this paper can be applied in connected and autonomous vehicle (CAV) to reduce driver cognitive workload and hence improve driving safety fed with naturalistic driving data collected using in-vehicle systems.},
institution = {Tongji U},
annotation = {Real-time driving risk analysis},
addendum = {However, this study still has some limitations. The driving risk prediction
method adopted in this paper only focuses on the car-following
process, and it is not enough to explore the driving risk during lanechanging
or overtaking process. For future work, high-risk lane-changing
events and overtaking events will be collected through NDS or actual
vehicle test to further improve and validate the accuracy of the proposed
driving risk prediction model. In addition, some deep learning algorithms,
such as recurrent neural network, can be applied and compared
with the prediction models proposed in this research. Meanwhile, other
driving risk influencing factors including vehicle characteristics and
road geometry characteristics can be obtained and added to the input
variables to further improve the performance of the prediction model.
For practical applications, the model will be further applied in the smart
vehicle industry fed with real-time naturalistic driving data collected by,
for example, ADAS.},
}

@article{ZHAO2020105783,
title = {How do drivers respond to driving risk during car-following? Risk-response driver model and its application in human-like longitudinal control},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105783},
year = {2020},
author = {Xiaocong Zhao and Ren He and Jianqiang Wang},
keywords = {Intelligent connected vehicle, Road safety, Driver modeling, Risk field theory, Car-following tasks, Human driving strategy},
abstract = {The blooming of intelligent connected vehicle (ICV) has been continuously shaping a hybrid traffic environment in which the road is shared among ICVs and vehicles driven by human drivers. However, due to the insufficient understanding of the human driving strategy and style, the conflicts between ICVs and human drivers have arisen public attention, threatening the road safety and bottlenecking the development of ICV. In order to embed the human driving strategy in the intelligent driving system, researchers have been rolling out efforts on driver modeling. Most driver models, however, still suffer from the limited application scope or poor transparency. Within our finite horizons, a unified and readable driver model for various driving scenarios is generally unobtainable. In this work, we tried to model the human driving strategy from an aspect of human nature, that is, the way human drivers respond to the driving risk. We employed the risk field theory (also known as the safety field theory) to model the environmental risk in a comprehensive manner. By studying the risk-response strategy from the driving data of 24 human drivers, we proposed a unified structure, which we call the risk-response driver model (RRDM), to model the human driving strategy. This model provides access to learning not only the average driving strategy of a group of human drivers but also the specific driving style of a single driver. The explicit and readable driving strategy produced by RRDM can be directly employed to reproduce human-like longitudinal driving control. We verified the performance of our model in car-following tasks and found that its human-like driving performance is recoverable among the human drivers who participated in the tests.},
institution = {Tongji U, Jiangsu U, Tsinghua U},
annotation = {Not ML.  Not our data.  },
addendum = {},
}

@article{SOLEIMANI2021105985,
title = {Applying machine learning, text mining, and spatial analysis techniques to develop a highway-railroad grade crossing consolidation model},
journal = {Accident Analysis \& Prevention},
volume = {152},
number = {nan},
pages = {105985},
year = {2021},
author = {Samira Soleimani and Michael Leitner and Julius Codjoe},
keywords = {Highway-rail grade crossing consolidation, Spatial analysis, Machine learning, Text mining},
abstract = {The consolidation of Highway-Railroad Grade Crossing (HRGC) is one of the effective approaches to decrease the number of crashes between trains and vehicles. From 2015–2019, there were 57 HRGC crashes at crossings in East Baton Rouge Parish (EBRP), resulting in thirteen injuries with \$346,875 cost of vehicle damages. Consolidation programs help to close redundant crossings and thereby decrease the crash risks; however, it is difficult to find the best crossing in a neighborhood for closure. In our previous research working on HRGC consolidation models in 2019, from among four Machine Learning algorithms, eXtreme Gradient Boosting (XGboost) performed better in HRGC prediction models. In continuation of our previous studies on developing a HRGC prediction model, this research employed Text Mining Techniques, and Geospatial Analysis in addition to the XGboost Machine Learning algorithm. The aim was to develop a consolidation model that is customized for local implementation. The results indicated an overall accuracy of 88 \% for the proposed model. The relative importance of the variables input to the model was also reported and offers an in-depth understanding of the model’s behavior. Considering the different correlation threshold, a sensitivity analysis was also performed on different aggregation gain values. Subsequently, it resulted in the development of a simplified model utilizing 14 variables, with aggregated gain values of 95 \% and a correlation threshold of 0.5. Based on this model, 15 \% of current highway-rail grade crossings should be closed.},
institution = {LSU},
annotation = {Interesting.  Continuation of previous paper.},
addendum = {For future studies, it may be worth exploring adding up the records of
several adjoining cities or parishes to develop a consolidation model for
a larger area with more data. However, acquiring spatial attributes for a
bigger geographic area may itself present another challenge. Secondly,
the quality of FRA data along with its temporal and seasonal effect needs
to be further improved.},
}

@article{LYM2021105920,
title = {Influence of built environment on the severity of vehicle crashes caused by distracted driving: A multi-state comparison},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105920},
year = {2021},
author = {Youngbin Lym and Zhenhua Chen},
keywords = {Distracted driving, Crash severity safety, Built environment, Multiple states comparison},
abstract = {With recent increased attention to the consequences of distracted driving (DD), this research provides a comprehensive investigation of the role of the built environment on the severity of vehicle crashes caused by DD. Utilizing crash data collected from fifteen states in the United States for the period 2013–2017, the association between distracted driving crash severity and various built environment indicators was examined by the generalized ordered logit regression model. The results show that at a lower severity level, DD related crashes were found to be less severe at roundabouts or in urban areas, whereas the probability of injuries rather than property damage only (PDO) increases if an accident involves speeding or when occurring at an intersection or a curved road. Comparatively, at a higher severity level, the odds of severe (or fatal) injury involvement compared to minor injuries and PDO was found to be higher in a work-zone, a curved roadway, or when excessive speed was involved. Conversely, roundabouts and urban areas affected negatively in severe DD crash, which is consistent with the lower-level case. The study also reveals a state-specific variability of the influence of the built environment on the severity of DD related crashes. These findings provide a comprehensive understanding of the severity of DD related crashes for transportation safety planners or policymakers to develop customized policy recommendations, such as designing policies or roadway safety treatments, to curb the negative consequences of distracted driving.},
institution = {Ohio State U},
annotation = {Not ML.  Not our data.},
addendum = {One should note that this study has several limitations that should be
further improved in future research. Different from Oviedo-Trespalacios
et al. (2020), our assessment was based on the GOL model, which only
allowed us to capture the heterogeneity among various states and the
heterogeneous influences of built environments on the severity of DD
crashes. Hence, the results should be read with a caution, given that the
study only presents the influence of the fixed effects (mean structure),
whereas we did not consider the unobserved heterogeneity and/or
random fluctuation from missing covariates. Therefore, future research
could be expanded by adopting more advanced modeling frameworks,
such as the generalized additive model and generalized linear mixed
model to address non-linear relationships by smoothing functions and
random effects such as unobserved heterogeneity (Faraway, 2016). In
addition, a latent segmentation-based ordered logit (LSOL) model may
also be adopted to capture heterogeneity or variation in crash severity
levels (Fatmi and Habib, 2019).
Last but not least, while the analysis was based on standardized data
of various states for comparison, it is worth noting that distracted
driving behavior tends to be underreported. Therefore, the pattern
revealed in this study may not fully capture the actual DD related
crashes. Future research should also focus on the utilization of different
data sources, such as the telematics data with integration of crash data in
order to provide a more comprehensive understanding of the DD driving
behavior.},
}

@article{REZAPOUR2020105795,
title = {Application of Quantile Mixed Model for modeling Traffic Barrier Crash Cost},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105795},
year = {2020},
author = {Mahdi Rezapour and Khaled Ksaibati and Milhan Moomen},
keywords = {crash cost, quantile mixed model, sparse data, non-parametric modeling, hierarchical model},
abstract = {Run-off the road crashes account for a significant proportion of severe injuries to vehicle occupants. Traffic barriers have been installed with an objective to keep vehicles on the roadway, and prevent them from hitting natural obstacles like trees or boulders. However, still injuries and fatalities of barrier crashes account for high proportion of fatalities on roadway. Due to challenging geometrics characteristics of Wyoming’s roadway, a high mileage of barriers has been installed in the state. The high mileages of barriers result in a high number of barrier crashes in terms of crash frequency and severity due to high exposure. Previous studies mainly focused on crash frequency or individual crash severity. However, it has been recognized the importance of accounting for both aspects of crash severity, and crash frequency. So, in this study, crashes are aggregated across different barriers, and those crashes were converted into costs by considering the impacts of both crash severity and frequency. However, one of the main challenges of this type of dataset is highly skewness of crash data due to its sparseness nature. An improper use of model distribution of crash cost would result in biased estimations of the covariates, and erroneous results. Thus, in order to address this issue, a semi-parametric method of quantile regression technique was implemented to account for the skewness of the response by relaxing model distribution parameters. Also, to account for the heterogeneity in the dataset due to barriers' types, a random intercept model accounting for the structure of the data was implemented. In addition, interaction terms between significant predictors were considered. Understanding what factors with which magnitude contribute to the barrier crash costs is crucial for the future barriers’ optimization process. Thus, contributory factors to barriers crash cost with high, medium, and low values, corresponding to 95th, 70th, and 60th percentiles were considered, and a comparison was made across these models. It was found, for instance, that although factors such as rollover, driving under the influence, and presence of heavy truck all have contributory impacts on the cost of crashes, their impacts are greater on higher quantiles, or higher barriers’ costs. These models were compared from various perspectives such as intra class correlation (ICC), and standard error of coefficients. This study highlights the changes in coefficient estimates while modeling crash costs.},
institution = {U of Wyoming},
annotation = {Not ML},
addendum = {For this study we just considered barriers with crashes as barriers
with no crashes did not have drivers’ characteristic such as alcohol
involvement, or citation record as a crash has not been occurred. Inclusion
of barriers with no crashes is important in the state as much of
the barriers are not based on recommended designs, and much of them
have not experienced any crash. To achieve the aforementioned criteria
the following analysis could be considered in the future studies to
incorporate barriers with no crashes as follows:
1 It is possible to only consider variables that are similar across barriers
with crashes and with no crashes. Those included predictors such as
barriers’ types, geometric characteristics, traffic, and barrier length.
That model could be implemented on both barriers with and without
crashes.
2 Instead of using cost as response, EPDO could be used. For this type
of response various model such as negative binomial could be conducted
on both barriers with and without crashes.
3 As negative binomial might not perform optimally for excess number
of zeroes, two component models, hurdle or zero-inflated models, are
expected to perform better. Those two-component models would
have two layers: one model for barriers with zero count crashes and
one model for barriers with crashes. In order to account for grouping
factor that we considered in this study; hierarchical model could be a
closest model to the implemented model in those studies.
As discussed, after identification of factors to barriers ‘crashes, the
final objective is to conduct cost-benefit analysis. This would be
implemented through quantile machine learning technique. The algorithm
would be trained over the original dataset. Then, variables especially
barriers geometric characteristics, such as barriers’ height would
be optimized to their optimal values. The trained model would be
implemented again over a new dataset and cost-benefit output would be
estimated.
For instance, barriers’ optimum height is 27 inches for box-beam. In
many places, the barriers’ height is less than that value. Thus, first the
cost would be predicted based on the barrier current height. Then, the
barrier’s height would be changed to 27 inches. The trained algorithm
would be conducted again, and cost would be predicted. The difference
would be the cost/benefit output.},
}

@article{LUO2021105968,
title = {A workload adaptive haptic shared control scheme for semi-autonomous driving},
journal = {Accident Analysis \& Prevention},
volume = {152},
number = {nan},
pages = {105968},
year = {2021},
author = {Ruikun Luo and Yifan Weng and Yifan Wang and Paramsothy Jayakumar and Mark J. Brudnak and Victor Paul and Vishnu R. Desaraju and Jeffrey L. Stein and Tulga Ersal and X. Jessie Yang},
keywords = {None},
abstract = {Haptic shared control is used to manage the control authority allocation between a human and an autonomous agent in semi-autonomous driving. Existing haptic shared control schemes, however, do not take full consideration of the human agent. To fill this research gap, this study presents a haptic shared control scheme that adapts to a human operator's workload, eyes on road and input torque in real time. We conducted human-in-the-loop experiments with 24 participants. In the experiment, a human operator and an autonomy module for navigation shared the control of a simulated notional High Mobility Multipurpose Wheeled Vehicle (HMMWV) at a fixed speed. At the same time, the human operator performed a target detection task. The autonomy could be either adaptive or non-adaptive to the above-mentioned human factors. Results indicate that the adaptive haptic control scheme resulted in significantly lower workload, higher trust in autonomy, better driving task performance and smaller control effort.},
institution = {U of Michigan},
annotation = {Not ML},
addendum = {this study focuses on only a single-vehicle scenario with fixed
speed. Further research should extend to a mixed-traffic scenario with
varying speeds. When other vehicles are present in the environment, the
impact from interactions with them will be important and can be
captured with various control schemes (Kerner, 2021, 2018b,a). In
addition, the impact of various surveillance tasks can also affect the
performance when mixed-traffic is considered. Studying these combined
effects is subject to future research.},
}

@article{HAGHANI2021106093,
title = {Applications of brain imaging methods in driving behaviour research},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106093},
year = {2021},
author = {Milad Haghani and Michiel C.J. Bliemer and Bilal Farooq and Inhi Kim and Zhibin Li and Cheol Oh and Zahra Shahhoseini and Hamish MacDougall},
keywords = {Driver brain activity, Simulated driving, Alcohol and cannabis, Secondary task, Driver decision-making, Fatigue and drowsiness, Neuroimaging, Functional Magnetic Resonance Imaging (fMRI), Electroencephalography (EEG), Functional Near-Infrared Spectroscopy (fNIRS), Magnetoencephalography (MEG)},
abstract = {Applications of neuroimaging methods have substantially contributed to the scientific understanding of human factors during driving by providing a deeper insight into the neuro-cognitive aspects of driver brain. This has been achieved by conducting simulated (and occasionally, field) driving experiments while collecting driver brain signals of various types. Here, this sector of studies is comprehensively reviewed at both macro and micro scales. At the macro scale, bibliometric aspects of these studies are analysed. At the micro scale, different themes of neuroimaging driving behaviour research are identified and the findings within each theme are synthesised. The surveyed literature has reported on applications of four major brain imaging methods. These include Functional Magnetic Resonance Imaging (fMRI), Electroencephalography (EEG), Functional Near-Infrared Spectroscopy (fNIRS) and Magnetoencephalography (MEG), with the first two being the most common methods in this domain. While collecting driver fMRI signal has been particularly instrumental in studying neural correlates of intoxicated driving (e.g. alcohol or cannabis) or distracted driving, the EEG method has been predominantly utilised in relation to the efforts aiming at development of automatic fatigue/drowsiness detection systems, a topic to which the literature on neuro-ergonomics of driving particularly has shown a spike of interest within the last few years. The survey also reveals that topics such as driver brain activity in semi-automated settings or neural activity of drivers with brain injuries or chronic neurological conditions have by contrast been investigated to a very limited extent. Potential topics in driving behaviour research are identified that could benefit from the adoption of neuroimaging methods in future studies. In terms of practicality, while fMRI and MEG experiments have proven rather invasive and technologically challenging for adoption in driving behaviour research, EEG and fNIRS applications have been more diverse. They have even been tested beyond simulated driving settings, in field driving experiments. Advantages and limitations of each of these four neuroimaging methods in the context of driving behaviour experiments are outlined in the paper.},
institution = {},
annotation = {Not ML},
addendum = {},
}

@article{KWAYU2021105899,
title = {Discovering latent themes in traffic fatal crash narratives using text mining analytics and network topology},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105899},
year = {2021},
author = {Keneth Morgan Kwayu and Valerian Kwigizile and Kevin Lee and Jun-Seok Oh},
keywords = {Structural topic modeling, Network topology, Network centrality measures, Traffic crashes},
abstract = {The proliferation of digital textual archives in the transportation safety domain makes it imperative for the inventions of efficient ways of extracting information from the textual data sources. The present study aims at utilizing crash narratives complemented by crash metadata to discern the prevalence and co-occurrence of themes that contribute to crash incidents. Ten years (2009–2018) of Michigan traffic fatal crash narratives were used as a case study. The structural topic modeling (STM) and network topology analysis were used to generate and examine the prevalence and interaction of themes from the crash narratives that were mainly categorized into pre-crash events, crash locations and involved parties in the traffic crashes. The main advantage of the STM over the other topic modeling approaches is that it allows the researchers to discover themes from documents and estimate how the topic relates to the document metadata. Topics with the highest prevalence for the angle, head-on, rear-end, sideswipe and single motor vehicle crashes were crash at stop-sign, crossing the centerline, unable to stop, lane change maneuver and run-off-road crash, respectively. Eigenvector centrality measure in network topology showed that event-related topics were consistently central in articulating the crash occurrence. The centrality and association between topics varied across crash types. The efficacy of generated topics in classifying crashes by type was tested using a machine learning algorithm, Random Forest. The classification accuracy in the held-out sample ranged between 89.3 \% for sideswipe crashes to 99.2 \% for single motor vehicle crashes. High classification accuracy suggests that automation of crash typing and consistency checks can be accomplished effectively by using extracted latent themes from the crash narratives.},
institution = {Western Michigan U},
annotation = {Not our data.  Text analysis of crash reports.},
addendum = {},
}

@article{LIU2020105742,
title = {An integrated spatio-temporal approach to examine the consequences of driving under the influence (DUI) in crashes},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105742},
year = {2020},
author = {Jun Liu and Xiaobing Li and Asad J. Khattak},
keywords = {Geographically and temporally weighted regression, Driving under the influence, Crash severity, Spatio-temporal variation},
abstract = {Driving under the influence (DUI) is illegal in the United States because a driver’s mental and motor skills can be seriously impaired by alcohol or drugs. Consequently, DUI violators’ involvement in severe crashes is high. Motivated by the spatial and temporal nature of traffic crashes, this study introduces an integrated spatio-temporal approach to analyzing highway safety data. Specifically, this study estimates Geographically and Temporally Weighted Regression (GTWR) models to understand the consequences of DUI in crashes. GTWR can theoretically outperform traditional regression methods by accounting for unobserved heterogeneity that may be related to the location and time of a crash. Using Southeast Michigan crash data, this study finds that DUI is associated with a 25\% higher likelihood of injury in a crash. The association between injury severity and DUI varies significantly across space and time. From the spatial aspect, DUI crashes in rural or small-town areas are more likely to cause injuries than urban crashes. From the temporal aspect, different times are associated with varying relationships between injury severity and DUI. If focusing on DUI crashes in late nights and early mornings, on Fridays, the entire northeast part from Clinton Charter Township to Port Huron is associated with severer injuries than other regions including Detroit’s urban area and its south. On Mondays, the DUI crashes in the northwest are also more likely to cause severe injuries. The methodology introduced in this study takes advantage of modern computational tools and localized crash/inventory data. This method offers researchers and practitioners an opportunity to understand highway safety outcomes in great spatial and temporal details and customize safety countermeasures for specific locations and times such as saturation patrols.},
institution = {U of Alabama},
annotation = {Not ML},
addendum = {},
}

@article{KHAN2020105521,
title = {Trajectory-level fog detection based on in-vehicle video camera with TensorFlow deep learning utilizing SHRP2 naturalistic driving data},
journal = {Accident Analysis \& Prevention},
volume = {142},
number = {nan},
pages = {105521},
year = {2020},
author = {Md Nasim Khan and Mohamed M. Ahmed},
keywords = {Foggy weather, Machine Learning, Deep Learning, Image Classification, TensorFlow, Deep Neural Network, Recurrent Neural Network, Long Short-Term Memory, Convolutional Neural Network, Advanced Driver Assistance Systems, Advanced Travel Information Systems, Variable Speed Limit, Mobile Weather Sensors},
abstract = {Providing drivers with real-time weather information and driving assistance during adverse weather, including fog, is crucial for safe driving. The primary focus of this study was to develop an affordable in-vehicle fog detection method, which will provide accurate trajectory-level weather information in real-time. The study used the SHRP2 Naturalistic Driving Study (NDS) video data and utilized several promising Deep Learning techniques, including Deep Neural Network (DNN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Convolutional Neural Network (CNN). Python programming on the TensorFlow Machine Learning library has been used for training the Deep Learning models. The analysis was done on a dataset consisted of three weather conditions, including clear, distant fog and near fog. During the training process, two optimizers, including Adam and Gradient Descent, have been used. While the overall prediction accuracy of the DNN, RNN, LSTM, and CNN using the Gradient Descent optimizer were found to be around 85 \%, 77 \%, 84 \%, and 97 \%, respectively; much improved overall prediction accuracy of 88 \%, 91 \%, 93 \%, and 98 \% for the DNN, RNN, LSTM, and CNN, respectively, were observed considering the Adam optimizer. The proposed fog detection method requires only a single video camera to detect weather conditions, and therefore, can be an inexpensive option to be fitted in maintenance vehicles to collect trajectory-level weather information in real-time for expanding as well as updating weather-based Variable Speed Limit (VSL) systems and Advanced Traveler Information Systems (ATIS).},
institution = {},
annotation = {},
addendum = {},
}

@article{LUAN2020105613,
title = {Effects of built environment on bicycle wrong Way riding behavior: A data-driven approach},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105613},
year = {2020},
author = {Sen Luan and Meng Li and Xin Li and Xiaolei Ma},
keywords = {Bicycle wrong way riding, Bike sharing, Built environment, Decision tree},
abstract = {Bicycle wrong way riding (WWR) is a dangerous and often neglected behavior that engenders threats to traffic safety. Owing to the lack of exposure data, the detection of WWR and its relationship with the built environment (BE) factors remain unclear. Accordingly, this study fills the research gaps by proposing a WWR detection framework based on bike-sharing trajectories collected from Chengdu, China. Moreover, this study adopts Negative Binomial-based Additive Decision Tree to investigate the impacts of built environment on WWR frequencies. Results reveal that (1) WWR distribution is unaffected by different periods in a day; (2) road length is more influential than road level and road direction in WWR occurrence; (3) company, bus stop, subway station, residence, and catering facility are primary contributors affecting WWR behavior during peak hours, whereas education becomes an emerging influential variable during nonpeak hours; and most importantly, (4) these variables clearly present non-linear effects on the WWR frequencies. Therefore, geographically differentiated policies should be adopted for bicycle safety improvement.},
institution = {Tsinghua U, Dalian Maritime U, Beihang U},
annotation = {Interesting for clear description of method.  Homework.  Not our data},
addendum = {},
}

@article{HU2020105665,
title = {Efficient mapping of crash risk at intersections with connected vehicle data and deep learning models},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105665},
year = {2020},
author = {Jiajie Hu and Ming-Chun Huang and Xiong Yu},
keywords = {Connected vehicles, Multi-layer perceptron, Convolutional neural network, Crash-prone intersection, Basic safety messages, Surrogate measures of safety},
abstract = {Traditional methods for identifying crash-prone roadways are mainly based on historical crash data. It usually requires more than three years to collect a sufficient amount of dataset for road safety assessment. However, the emerging connected vehicles (CVs) technology generates rich instantaneous information, which can be used to identify dangerous road sections proactively. Information about the identified crash-prone intersections can be shared with the surrounding vehicles via CVs communication technology to promote cautious driving behaviors; in the longer term, such information will guide the implementation of countermeasures to prevent potential crashes. This study proposed a deep-learning based method to predict the risk level at intersections based on CVs data from the Michigan Safety Pilot program and historical traffic and intersection crash data in areas around Ann Arbor, Michigan, USA. One month of data by CVs at intersections were used for analyses, which accounts for about 3\%–12\% of overall trips. The risk levels of 774 intersections (i.e., low, medium and high risk) are determined by the annual crash rates. Feature extraction process is applied to both CV’s data and traffic data at each intersection and 24 features are extracted. Two black-box deep-learning models, multi-layer perceptron (MLP) and convolutional neural network (CNN) are trained with the extracted features. A number of hyperparameters that affect prediction performance are fine-tuned using Bayesian optimization algorithm for each model. The performance of the two deep learning models, which are black-box models, were also compared with a decision tree model, a white-box type of simple machine learning model. The results showed that the accuracies of deep learning (DL) models were slightly better (both over 90 \%) than the decision tree model (about 87 \%). This indicated that the DL models were capable of uncover the inherent complexity from the dataset and therefore provided higher accuracy than the traditional machine learning model. CNN model achieves slightly higher accuracy (93.8 \%) and is recommended as the classifier to predict the risk level at intersections in practice. The interpretability analysis of the CNN model is conducted to confirm the validity of the model. This study shows that combination of CVs data (V2V and V2I) and deep learning networks (i.e. MLP and CNN used in this paper) is promising to determine crash risks at intersections with high time efficiency and at low CV penetration rates, which help to deploy countermeasures to reduce the crash rates and resolve traffic safety problems.},
institution = {Case Western Reserve U},
annotation = {Not our data.  Connected vehicle data.  Interesting for clear description of method.},
addendum = {},
}

@article{ALI2020105643,
title = {The impact of the connected environment on driving behavior and safety: A driving simulator study},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105643},
year = {2020},
author = {Yasir Ali and Anshuman Sharma and Md. Mazharul Haque and Zuduo Zheng and Mohammad Saifuzzaman},
keywords = {Connected environment, Advanced driving simulator, Car-following, Lane-changing, Driving behavior, Safety},
abstract = {The connected environment provides surrounding traffic information to drivers via different driving aids that are expected to improve driving behavior and assist in avoiding safety-critical events. These driving aids include speed advisory, car-following assistance, lane-changing support, and advanced information about possible unseen hazards, among many others. While various studies have attempted to examine the effectiveness of different driving aids discretely, it is still vague how drivers perform when they are exposed to a connected environment with vehicle-to-vehicle and vehicle-to-infrastructure communication capabilities. As such, the objective of this study is to examine the effects of the connected environment on driving behavior and safety. To achieve this aim, an innovative driving simulator experiment was designed to mimic a connected environment using the CARRS-Q Advanced Driving Simulator. Two types of driving aids were disseminated in the connected environment: continuous and event-based information. Seventy-eight participants with diverse backgrounds drove the simulator in four driving conditions: baseline (without driving aids), perfect communication (uninterrupted supply of driving aids), communication delay (driving aids are delayed), and communication loss (intermittent loss of driving aids). Various key driving behavior indicators were analyzed and compared across various routine driving tasks such as car-following, lane-changing, interactions with traffic lights, and giving way to pedestrians at pedestrian crossings. Results suggest that drivers in the perfect communication scenario maintain a longer time-to-collision during car-following, a longer time-to-collision to pedestrian, a lower deceleration to avoid a crash during lane-changing, and a lower propensity of yellow light running. Overall, drivers in the connected environment are found to make informed (thus better) decisions towards safe driving.},
institution = {U of Queensland, Queensland U of Technology},
annotation = {Not our data. Driving simulator.  Not ML},
addendum = {},
}

@article{GULINO2021105864,
title = {Injury risk assessment based on pre-crash variables: The role of closing velocity and impact eccentricity},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105864},
year = {2021},
author = {Michelangelo-Santo Gulino and Leonardo Di Gangi and Alessio Sortino and Dario Vangi},
keywords = {Velocity change (), Crash Momentum Index (CMI), A priori analysis, Feature ranking, Predictive models, Machine learning},
abstract = {Thorough evaluations on injury risk (IR) are fundamental for guiding interventions toward the enhancement of both the road infrastructure and the active/passive safety of vehicles. Well-established estimates are currently based on IR functions modeled on post-crash variables, such as velocity change sustained by the vehicle ($\Delta$V); thence, these analyses do not directly suggest how pre-crash conditions can be modified to allow for IR reduction. Nevertheless, $\Delta$V can be disaggregated into two contributions which enable its a priori calculation, based only on the information available at the impact instant: the Crash Momentum Index (CMI), representing impact eccentricity at collision, and the closing velocity at collision (Vr). By extensively employing the CMI indicator, this work assesses the overall influence of impact eccentricity and closing velocity on the risk for occupants to sustain a serious injury. As CMI synthesizes indications regarding $\Delta$V, its use can be disjointed from the $\Delta$V itself for the derivation of high-quality IR models. This feature distinguishes CMI from the other eccentricity indicators available at the state-of-the-art, allowing for the contribution of eccentricity on IR to be completely isolated. Because of this element of originality, special attention is given to the CMI variable throughout the present work. Based on data extracted from the NASS/CDS database, the influence of the CMI and Vr variables on IR is specifically highlighted and analyzed from several perspectives. The feature ranking algorithm ReliefF, whose use is unprecedented in the accident analysis field, is first employed to assess importance of such impact-related variables in determining the injury outcome: if compared to vehicle-related and occupant-related variables (as category and age, respectively), the higher influence of CMI and Vr is initially highlighted. Secondly, the relevance of CMI and Vr is confirmed by fitting different predictive models: the fitted models which include the CMI predictor perform better than models which neglect the CMI, in terms of classical evaluation metrics. As a whole, considering the high predictive power of the proposed CMI-based models, this work provides valuable tools for the a priori assessment of IR.},
institution = {U degli Studi di Firenze},
annotation = {Not our data.  Interesting for thorough analysis.},
addendum = {Notwithstanding the interesting highlights obtained, it is worth
evidencing that the analysis is focused on the determination of IR by the
MAIS 3+ index (serious injuries). The soundness of the results in terms
of Vr and CMI influence on the injury outcome can be extended by
studies focused on:
• a higher number of injury degrees (different MAIS);
• different injury severity indexes (e.g., ISS);
• an injury index which refers to single body segments (AIS).
This would additionally allow for a broader-spectrum study, employing
the models classified as most promising by the performed analysis.
The IR models which have been derived are valid for all collision
types, because the value of Vr and CMI is based on a posteriori data (by
$\Delta$V value and Eq. (3)); conversely, calculation of $\Delta$V by Eq. (2) may be
inappropriate if sliding occurs during the collision. However, in this
latter case, only a limited part of Vr is converted into $\Delta$V (low VrPDOF): a
low IR value associated with the collision is obtained and, as a consequence,
a lower relevance of sliding impacts in a priori analyses can be
highlighted if compared to full impacts.
It must be mentioned that the check applied to increase the quality of
the analysis (Eq. (6)) exerts a significant effect on the remaining number
of cases to be processed; however, this check can be modified or
excluded to include a higher number of accidents: even if more cases can
improve the fitting quality in practice, the use of partially incorrect data
can significantly affect the quality of the resulting model (Vangi et al.,
2019a). For what specifically concerns the derived models, it is worth
noting that they are obtained using American data only; given the differences
between distinct countries in terms of both data collection (in
procedure and accuracy (Fildes et al., 2013)) and crashworthiness of
vehicles (Flannagan et al., 2018), the proposed IR models need to be
modified and contextualized based on the specific scope. The
type-approval year of the vehicle model also affects the passive safety
datum: the registration year is considered as an indicator of the vehicle
generation (and crashworthiness) in the derived IR models because it is
the sole element available from the NASS/CDS database; considering the
type-approval year, rather than the registration year, could be beneficial
to enhance the overall fitting quality.},
}

@article{TAMAKLOE2020105736,
title = {A copula-based approach for jointly modeling crash severity and number of vehicles involved in express bus crashes on expressways considering temporal stability of data},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105736},
year = {2020},
author = {Reuben Tamakloe and Jungyeol Hong and Dongjoo Park},
keywords = {Copula, Ordered probit model, Temporal stability, Crash severity, Expressway, Bus-involved crashes},
abstract = {The consequences of crashes, including injury, loss of lives, and damage to properties, are further worsened when buses plying expressways are involved in the crash. Previous studies have separately analyzed crash severity in terms of monetary cost, injuries and loss of lives, and the size of crashes in terms of the number of vehicles involved. However, as both outcome variables are correlated, it is imperative to perform a combined analysis using an appropriate econometric model to achieve a better model fit. This study contributes to the literature by jointly exploring the factors influencing the severity and size of express bus-involved crashes that occur on expressways and characterizes the dependence between both outcome variables by employing a more plausible copula regression framework. Likelihood ratio tests were also conducted to investigate the temporal stability of the factors that affect both crash severity and size. Based on the goodness-of-fit statistics, the Frank copula model proved superior to the independent ordered probit model. The estimate of the underlying dependence between the outcome variables provided a better comprehension of the correlation between them. Temporal instability was detected for the individual parameters in the models and is attributed to the changing driving behavior due to the heightened road safety campaigns. The results suggest that traffic exposure measures are significantly associated with a higher propensity of observing increased bus crash severity and size. Insights into the factors influencing the size and severity of express bus crashes are discussed, and appropriate engineering, enforcement, and education-related countermeasures are proposed.},
institution = {U of Seoul},
annotation = {Not ML},
addendum = {In the future, it would
be interesting to identify which subsets of crash populations that show
temporal stability/instability. It would also be worthwhile to employ
machine learning algorithms to identify important rules that show a set
of factors leading to bus-involved crashes, especially at mainline sections
where crashes are usually severe.},
}

@article{YAN2021106034,
title = {Single-vehicle crash severity outcome prediction and determinant extraction using tree-based and other non-parametric models},
journal = {Accident Analysis \& Prevention},
volume = {153},
number = {nan},
pages = {106034},
year = {2021},
author = {Xintong Yan and Jie He and Changjian Zhang and Ziyang Liu and Boshuai Qiao and Hao Zhang},
keywords = {Single-vehicle accident analysis, Accident severity, Severity prediction, Non-parametric model, Tree-based models},
abstract = {Single-vehicle crashes are more fatality-concentrated and have posed increasing challenges in traffic safety, which is of great research necessity. Tremendous previous studies have conducted relevant analysis with econometric modeling approaches, whereas the ability of non-parametric methods to predict crash severity is still smattering of knowledge. Consequently, the main objective of this paper is to conduct single-vehicle crash severity prediction with different tree-based and non-parameter models. An alternate aim is to identify the intrinsic mechanism of how contributing factors determine single-vehicle crash severity. By virtue of Grid-Search method, this paper conducted fine-tuning of different models to obtain the best performances based on five crash severity sub-datasets. For model evaluation, the accuracy indicators were calculated in training, validation and test sets, respectively. Besides, feature importance extraction was undertaken based on the results of model comparison. The finding indicated that these models didn’t exhibit a huge performance difference for crash severity prediction in the same severity level; however, the performances of the models did vary among different datasets, with an average training accuracy of 99.27 \%, 96.4 \%, 86.98 \%, 86.84 \%, 71.76 \% in fatal injury, severe injury, visible injury, complaint of pain, PDO crash datasets, respectively. Additionally, it was found that in each severity dataset, the indicator urban freeways is a determinant factor that leads to the occurrence of crashes while rural freeways is more related to more severe crashes (i.e., fatal and severe crashes). This paper can provide valuable information for model selection and tuning in accident severity prediction. Future research could consider the influences that temporal instability of contributing features has on the model performances.},
institution = {Southeast U (Nanjing)},
annotation = {Here, 'determinant' means 'determining factor.'  Interesting for being similar to our work.  Data from HSIS},
addendum = {However, it should be noted that this paper is not free of limitations,
more research could be implemented from these two aspects: (1) to
further consider the influences that temporal instability of contributing
features has on the model performances with more input sample
distributed in different years; and (2) to explore the availability of deep
learning (DL) models such as CNN, RNN, LSTM in crash severity prediction
and compare their performance difference with traditional ML
methods.},
}

@article{JAZAYERI2021106010,
title = {The Impact of driver distraction and secondary tasks with and without other co-occurring driving behaviors on the level of road traffic crashes},
journal = {Accident Analysis \& Prevention},
volume = {153},
number = {nan},
pages = {106010},
year = {2021},
author = {Ali Jazayeri and John Ray B. Martinez and Helen S. Loeb and Christopher C. Yang},
keywords = {Distracted driving, Secondary tasks, Co-occurring behaviors, Driving behaviors},
abstract = {Driving safety is typically affected by concurrent non-driving tasks. These activities might negatively impact the trips’ outcome and cause near-crash or crash incidents and accidents. The crashes impose a tremendous social and economic cost to society and might affect the involving individuals’ quality of life. As it stands, road injuries are ranked among top-ten leading causes of death by the World Health Organization. Distracted driving is defined as an attention diversion of the driver toward a competing activity. It was shown in numerous studies that distracted driving increase the probability of near-crash or crash events. By leveraging the statistical power of the large SHRP2 naturalistic data, we are able to quantify the preponderance of specific distractions during daily trips and confirm the causality factor of an ubiquitous non-driving task in the crash event. We show that, except for phone usage which happens more frequently in near-crash and crash categories than in baseline trips, both distracted driving and secondary tasks occur almost uniformly in different types of trips. In this study, we investigate the impact of the co-occurrence of distracted driving with other driving behaviors and secondary tasks. It is found that the co-occurrence of distracted driving with other driving behaviors or secondary tasks increase the chance of near-crash and crash events. This study's findings can inform the design and development of more precise and reliable driving assistance and warning systems.},
institution = {Drexel U},
annotation = {Not ML},
addendum = {},
}

@article{ALVER2021106127,
title = {Evaluation of pedestrian critical gap and crossing speed at midblock crossing using image processing},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106127},
year = {2021},
author = {Y. Alver and P. Onelcin and A. Cicekli and M. Abdel-Aty},
keywords = {Midblock crossing, Crossing speed, Critical gap, Image processing},
abstract = {Pedestrians confront risky situations at midblock sections due to the unyielding behavior of drivers. Thus, pedestrians have to wait for an appropriate gap to cross. This research investigates pedestrians’ gap acceptance and crossing speed for midblock crossings by image processing methods in Izmir, Turkey. A total of 498 pedestrians have been tracked at two midblock crossings. The data were collected for one hour at each midblock crossing during the evening peak hour between 5.00–6.00 p.m. Three synchronized cameras were used to record pedestrian crossings. Then, by using image processing, vehicle and pedestrian trajectories have been obtained. Two cameras were mounted on telescopic tripods reaching up to 9 m, and the third camera was used to identify pedestrians’ gender better. The parameters extracted from the recordings are; pedestrians’ gender, group size, whether they carried items or not, and their accepted/rejected gaps. Pedestrian and item detection has been performed by YOLOv3 and YOLACT models. The accepted and rejected time gaps were extracted for pedestrians, excluding the pedestrians who crossed between stopped vehicles and crossed when an approaching vehicle did not exist within 100 m from the midblock crossing. Raff’s method was used to estimate the critical gap using accepted/rejected gaps. The critical gaps ranged between 4.1 s and 6.2 s. The 15th percentile crossing speeds were found to be similar, ranging between 0.78 m/s and 0.80 m/s.},
institution = {Ege U, U of Central Florida},
annotation = {Not our data.  Image processing},
addendum = {},
}

@article{MONTELLA2021106119,
title = {Rule discovery to identify patterns contributing to overrepresentation and severity of run-off-the-road crashes},
journal = {Accident Analysis \& Prevention},
volume = {155},
number = {nan},
pages = {106119},
year = {2021},
author = {Alfonso Montella and Filomena Mauriello and Mariano Pernetti and Maria {Rella Riccardi}},
keywords = {ROR crashes, Severe and fatal crashes, Association rules, Data mining, Safety countermeasures},
abstract = {The main objective of this paper was to analyse the roadway, environmental, and driver-related factors associated with an overrepresentation of frequency and severity of run-off-the-road (ROR) crashes. The data used in this study refer to the 6167 crashes occurred in the section Naples–Candela of A16 motorway, Italy in the period from 2001 to 2011. The analysis was carried out using the rule discovery technique due to its ability of extracting knowledge from large amounts of data previously unknown and indistinguishable by investigating patterns that occur together in a given event. The rules were filtered by support, confidence, lift, and validated by the lift increase criterion. A two-step analysis was carried out. In the first step, rules discovering factors contributing to ROR crashes were identified. In the second step, studying only ROR crashes, rules discovering factors contributing to severe and fatal injury (KSI) crashes were identified. As a result, 94 significant rules for ROR crashes and 129 significant rules for KSI crashes were identified. These rules represent several combinations of geometric design, roadside, barrier performance, crash dynamic, vehicle, environmental and drivers’ characteristics associated with an overrepresentation of frequency and severity of ROR crashes. From the methodological point of view, study results show that the a priori algorithm was effective in providing new information which was previously hidden in the data. Finally, several countermeasures to solve or mitigate the safety issues identified in this study were discussed. It is worthwhile to observe that the study showed a combination of factors contributing to the overrepresentation of frequency and severity of ROR crashes. Consequently, the implementation of a combination of countermeasures is recommended.},
institution = {U of Naples Federico II, U of Campania Luigi Vanvitelli},
annotation = {Not ML},
addendum = {},
}

@article{YU2020105779,
title = {A Bayesian Tobit quantile regression approach for naturalistic longitudinal driving capability assessment},
journal = {Accident Analysis \& Prevention},
volume = {147},
number = {nan},
pages = {105779},
year = {2020},
author = {Rongjie Yu and Xiaojie Long and Mohammed Quddus and Junhua Wang},
keywords = {Driving capability assessment, Longitudinal driving safety, Responsibility-sensitive safety, Bayesian Tobit quantile regression model, Naturalistic driving data},
abstract = {Given the severe traffic safety issue, tremendous efforts have been devoted to identify the crash contributing factors for developing and implementing safety improvement countermeasures. According to the study findings, driving behaviors have attributed to the majority crash occurrence, among which inadequate driving capability is a key factor. Therefore, a number of studies have been conducted for developing techniques associated with the driving capability assessment and its various improvement. However, the conventional assessment approaches, such as driving license exams and vehicle insurance quotes, have only focused on basic driving skill evaluations or aggregated driving style classifications, which failed to quantify driving capability from the safety perspective with respect to the complex driving scenarios. In this study, a novel longitudinal driving capacity assessment and ranking approach was developed with naturalistic driving data. Two Responsibility-Sensitive Safety (RSS) based driving capability indicators from the perspectives of risk exposure and severity were first proposed. Then, Bayesian Tobit quantile regression (BTQR) models were introduced to explore the relationships between driving capability indicators with trip level characteristics from the aspects of travel features, operational conditions, and roadway characteristics. The modeling results concluded that nighttime driving and higher average speed would lead to higher longitudinal collision risk and its severity. Besides, the BTQR models have provided varying factors significances among different quantile levels, for instance, driving duration is only significant at high quantiles for the driving capability indicators, implying that duration only affects drivers with large longitudinal risk exposures and strong close following tendencies. Furthermore, the case studies provided how to deploy the developed model to obtain the relative longitudinal driving capability rankings. Finally, the model applications from the aspects of commercial fleet safety management and comparing the autonomous vehicles’ longitudinal driving behaviors with human drivers have been discussed.},
institution = {Tongji U},
annotation = {Not ML},
addendum = {},
}

@article{WU2021105910,
title = {Mid-term prediction of at-fault crash driver frequency using fusion deep learning with city-level traffic violation data},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105910},
year = {2021},
author = {Yuan-Wei Wu and Tien-Pen Hsu},
keywords = {At-fault crash driver, Traffic violation, Traffic enforcement, Deep learning},
abstract = {Traffic violations and improper driving are behaviors that primarily contribute to traffic crashes. This study aimed to develop effective approaches for predicting at-fault crash driver frequency using only city-level traffic enforcement predictors. A fusion deep learning approach combining a convolution neural network (CNN) and gated recurrent units (GRU) was developed to compare predictive performance with one econometric approach, two machine learning approaches, and another deep learning approach. The performance comparison was conducted for (1) at-fault crash driver frequency prediction tasks and (2) city-level crash risk prediction tasks. The proposed CNN-GRU achieved remarkable prediction accuracy and outperformed other approaches, while the other approaches also exhibited excellent performances. The results suggest that effective prediction approaches and appropriate traffic safety measures can be developed by considering both crash frequency and crash risk prediction tasks. In addition, the accumulated local effects (ALE) plot was utilized to investigate the contribution of each traffic enforcement activity on traffic safety in a scenario of multicollinearity among predictors. The ALE plot illustrated a complex nonlinear relationship between traffic enforcement predictors and the response variable. These findings can facilitate the development of traffic safety measures and serve as a good foundation for further investigations and utilization of traffic violation data.},
institution = {National Taiwan U},
annotation = {Not our data.  Correlations between traffic violations and crashes.},
addendum = {},
}

@article{LI2020105744,
title = {Ranking contributors to traffic crashes on mountainous freeways from an incomplete dataset: A sequential approach of multivariate imputation by chained equations and random forest classifier},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105744},
year = {2020},
author = {Linchao Li and Carlo G. Prato and Yonggang Wang},
keywords = {Missing values, Multiple imputation, Machine learning, Traffic safety, Mountainous roads},
abstract = {The estimation of the effect of contributors to crash injury severity and the prediction of crash injury severity outcomes suffer often from biases related to missing data in crash datasets that contain incomplete records. As both estimation and prediction would greatly improve if the missing values were recovered, this study proposes a sequential approach to handle incomplete crash datasets and rank contributors to the injury severity of crashes on mountainous freeways in China. The sequential approach consists of two parts: (i) multivariate imputation by chained equations imputes the missing values of independent variables; (ii) a random forest classifier analyses the correlation between the dependent and the independent variables. The first part considers different imputation methods in light of the independent variables being either binary, categorical or continuous, whereas the second part classifies the correlations according to the random forest classifier. The proposed method was applied to the case-study about mountainous freeways in China and compared to the analysis of the raw dataset to evaluate its effectiveness, and the results illustrate that the method improves significantly the classification accuracy when compared with existing methods. Moreover, the classifier ranked the contributors to the injury severity of traffic crashes on mountainous freeways: in order of importance vehicle type, crash type, road longitudinal gradient, crash cause, curve radius, and deflection angles. Interestingly, a lower importance was found for environmental factors.},
institution = {Shenzhen U, U of Queensland, Chang'an U},
annotation = {Interesting.  How to impute missing data.  },
addendum = {},
}

@article{SAGAR2020105582,
title = {Identifying high-risk commercial vehicle drivers using sociodemographic characteristics},
journal = {Accident Analysis \& Prevention},
volume = {143},
number = {nan},
pages = {105582},
year = {2020},
author = {Shraddha Sagar and Nikiforos Stamatiadis and Samantha Wright and Aaron Cambron},
keywords = {Highway safety, Socioeconomic factors, Commercial motor vehicles, Quasi-induced exposure technique},
abstract = {Crash data, from the state of Kentucky, for the 2015-2016 period, show that per capita crash rates and increases in crash-related fatalities were higher than the national average. In an effort to explain why the U.S. Southeast experiences higher crash rates than other regions of the country, previous research has argued the regions unique socioeconomic conditions provide a compelling explanation. Taking this observation as a starting point, this study examines the relationship between highway safety and socioeconomic and demographic characteristics, using an extensive crash dataset from Kentucky. Its focus is single- and two-unit crashes that involve commercial motor vehicles (CMVs) and automobiles. Using binary logistic regression and the quasi-induced exposure technique to analyze data on the socioeconomic and demographic attributes of the zip codes in which drivers reside, factors are identified which can serve as indicators of crash occurrence. Variables such as income, education level, poverty level, employment, age, gender, and rurality of the driver’s zip code influence the likelihood of a driver being at fault in a crash. Socioeconomic factors exert a similar influence on CMV and automobile crashes, irrespective of the number of vehicles involved. Research findings can be used to identify groups of drivers most likely to be involved in crashes and develop targeted and efficient safety programs.},
institution = {U of Kentucky},
annotation = {Not ML.  Not our data},
addendum = {},
}

@article{YANG2020105714,
title = {An Integrated Microsimulation Approach for Safety Performance Assessment of the Wyoming Connected Vehicle Pilot Deployment Program},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105714},
year = {2020},
author = {Guangchuan Yang and Mohamed Ahmed and Eric Adomah},
keywords = {Wyoming Connected Vehicle Pilot, Microsimulation Modeling, Adverse Weather, Model Calibration, Surrogate Measures of Safety (SMoS)},
abstract = {The 402-mile of Interstate 80 in Wyoming was selected by the U.S. Department of Transportation to develop, test, and deploy a suite of Connected Vehicle (CV) applications (WYDOT CV Pilot). It is expected that after full deployment of CV technology, the pilot will improve safety and mobility under adverse weather conditions by creating new ways to communicate road and travel information to both drivers and fleet managers. In this regard, this research employed an integrated microsimulation modeling approach to assess the safety performance of the WYDOT CV Pilot. A 23-mile representative I-80 corridor was selected for developing the microsimulation models. Traffic flow and driving behavior data under winter snowy weather condition were collected to calibrate the baseline microsimulation model. A driving simulator experiment was conducted to quantitatively investigate the impacts of CV technology on driving behavior; accordingly, the driving behavior data under CV environment were employed to properly update the calibrated CV microsimulation models. The safety effectiveness of the WYDOT CV Pilot were assessed for various demand levels and CV penetration rates. It was concluded that WYDOT CV applications increased drivers’ situation awareness under adverse weather conditions, and thus reduced the crash risk. The reductions in conflicts displayed a decreasing trend with the increase of CV penetration rates, but the reduction was not significant when CV penetration was lower than 10 percent. The maximum reduction in conflicts was 85 percent when all trucks were equipped with CV technology.},
institution = {U of Wyoming},
annotation = {Simulation, Not ML},
addendum = {Future works
should also further investigate the safety benefits of the pilot’s CV applications
under different weather and traffic events, such as a freeway
work zone under low visibility condition, and road closure and rerouting
due to traffic crashes.},
}

@article{WORLE2021105918,
title = {Sleep inertia in automated driving: Post-sleep take-over and driving performance},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105918},
year = {2021},
author = {Johanna Wörle and Barbara Metz and Martin Baumann},
keywords = {Automated driving, Take-over performance, Driving performance, Sleep, Sleep inertia, Driver state},
abstract = {Sleep is emerging as a new driver state in automated driving. Post-sleep performance impairments due to sleep inertia, the transitional phase from sleep to wakefulness that can take up to 30 min, are a potential safety issue. Take-over performance immediately after sleep is impaired and drivers perceive the take-over as critical. The aim of the presented study was to assess take-over behavior immediately after sleep and driving behavior during the 10 min after sleep. A study with N = 31 drivers was conducted in a high-fidelity driving simulator. Take-over performance and driving performance were assessed a) under alert baseline conditions and b) after awakening from electroencephalography-confirmed stable sleep. Take-over performance 15 s after awakening was impaired resulting in more driving errors compared to the alert baseline. Lane keeping was dramatically impaired in the first 3 min after sleep and recovered rapidly. Drivers drove slower after sleep and speed keeping was less stable for at least 10 min. The results suggest that human-machine interaction design should account for the drivers’ impaired post-sleep driving performance.},
institution = {Würzburg Institute for Traffic Sciences, U of Ulm},
annotation = {Not our data},
addendum = {},
}

@article{HONG2020105497,
title = {Application of association rules mining algorithm for hazardous materials transportation crashes on expressway},
journal = {Accident Analysis \& Prevention},
volume = {142},
number = {nan},
pages = {105497},
year = {2020},
author = {Jungyeol Hong and Reuben Tamakloe and Dongjoo Park},
keywords = {hazardous material, association rules mining, Apriori algorithm, data mining, expressways},
abstract = {Although crashes involving hazardous material (HAZMAT) vehicles on expressways do not occur frequently compared with other types of vehicles, the number of lives lost and social damage is very high when a HAZMAT vehicle-involved crash occurs. Therefore, it is essential to identify the leading causes of crashes involving HAZMAT vehicles and make specific countermeasures to improve the safety of expressways. This study aims to employ the association rules mining (ARM) approach to discover the contributory crash-risk factors of HAZMAT vehicle-involved crashes on expressways. A case study is conducted using crash data obtained from the Korea Expressway Corporation crash database from 2008 to 2017. ARM was conducted using the Apriori algorithm, and a total of 855 interesting rules were generated. With appropriate support, confidence, and lift values, we found hidden patterns in the HAZMAT crash characteristics. The results indicate that HAZMAT vehicle-involved crashes are highly associated with male drivers, single vehicle-involved crashes, clear weather conditions, daytime, and mainline segments. Also, we found that HAZMAT tank-lorry and cargo truck crashes, single vehicle-involved crashes, and crashes on mainline segments of expressways had independent and unique association rules. The finding from this study demonstrates that ARM is a plausible data mining technique that can be employed to draw relationships between HAZMAT vehicle-involved crashes and significant crash-risk factors, and has the potential of providing more easy-to-understand results and relevant insights for the safety improvement of expressways.},
institution = {U of Seoul},
annotation = {Interesting?},
addendum = {},
}

@article{JIN2021106156,
title = {Modeling takeover behavior in level 3 automated driving via a structural equation model: Considering the mediating role of trust},
journal = {Accident Analysis \& Prevention},
volume = {157},
number = {nan},
pages = {106156},
year = {2021},
author = {Mengxia Jin and Guangquan Lu and Facheng Chen and Xi Shi and Haitian Tan and Junda Zhai},
keywords = {Level 3 automation, Simulator experiment, Takeover behavior variation, Trust, Structural equation modeling},
abstract = {The takeover process in level 3 automated driving determines the controllability of the functions of automated vehicles and thereby traffic safety. In this study, we attempted to explain drivers’ takeover performance variation in a level 3 automated vehicle in consideration of the effects of trust, system characteristics, environmental characteristics, and driver characteristics with a structural equation model. The model was built by incorporating drivers’ takeover time and quality as endogenous variables. A theoretical framework of the model was hypothesized on the basis of the ACT-R cognitive architecture and relevant research results. The validity of the model was confirmed using data collected from 136 driving simulator samples under the condition of voluntary non-driving-related tasks. Results revealed that takeover time budget was the most critical factor in promoting the safety and stability of takeover process, which, together with traffic density, drivers’ age and manual driving experience, determined drivers’ takeover quality directly. In addition, the pre-existing experience with an automated system or a similar technology and self-confidence of the driver, as well as takeover time budget, strongly influenced the takeover time directly. Apart from the direct effects mentioned above, trust, as an intermediary variable, explained a major portion of the variance in takeover time. Theoretically, these findings suggest that takeover behavior could be comprehensively evaluated from the two dimensions of takeover time and quality through the combination of trust, driver characteristics, environmental characteristics, and vehicle characteristics. The influence mechanism of the above factors is complex and multidimensional. In addition to the form of direct influence, trust, as an intermediary variable, could reflect the internal mechanism of the takeover behavior variation. Practically, the findings emphasize the crucial role of trust in the change in takeover behavior through the dimensions of subjective trust level and monitoring strategy, which may provide new insights into the function design of takeover process.},
institution = {Beihang U},
annotation = {Not our data.  Not ML},
addendum = {},
}

@article{KATRAKAZAS2021106007,
title = {Prediction of rear-end conflict frequency using multiple-location traffic parameters},
journal = {Accident Analysis \& Prevention},
volume = {152},
number = {nan},
pages = {106007},
year = {2021},
author = {Christos Katrakazas and Athanasios Theofilatos and Md Ashraful Islam and Eleonora Papadimitriou and Loukas Dimitriou and Constantinos Antoniou},
keywords = {Traffic conflicts, Safety, Surrogate safety measures, Count data modelling},
abstract = {Traffic conflicts are heavily correlated with traffic collisions and may provide insightful information on the failure mechanism and factors that contribute more towards a collision. Although proactive traffic management systems have been supported heavily in the research community, and autonomous vehicles (AVs) are soon to become a reality, analyses are concentrated on very specific environments using aggregated data. This study aims at investigating –for the first time- rear-end conflict frequency in an urban network level using vehicle-to-vehicle interactions and at correlating frequency with the corresponding network traffic state. The Time-To-Collision (TTC) and Deceleration Rate to Avoid Crash (DRAC) metrics are utilized to estimate conflict frequency on the current network situation, as well as on scenarios including AV characteristics. Three critical conflict points are defined, according to TTC and DRAC thresholds. After extracting conflicts, data are fitted into Zero-inflated and also traditional Negative Binomial models, as well as quasi-Poisson models, while controlling for endogeneity, in order to investigate contributory factors of conflict frequency. Results demonstrate that conflict counts are significantly higher in congested traffic and that high variations in speed increase conflicts. Nevertheless, a comparison with simulated AV traffic and the use of more surrogate safety indicators could provide more insight into the relationship between traffic state and traffic conflicts in the near future.},
institution = {National Technical U of Athens, Loughborough U, Technical U of Munich, Technical U of Deft, U of Nicosia},
annotation = {Not ML},
addendum = {},
}

@article{KWON2020105716,
title = {An examination of the intersection environment associated with perceived crash risk among school-aged children: using street-level imagery and computer vision},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105716},
year = {2020},
author = {Jae-Hong Kwon and Gi-Hyoug Cho},
keywords = {None},
abstract = {While computer vision techniques and big data of street-level imagery are getting increasing attention, a “black-box” model of deep learning hinders the active application of these techniques to the field of traffic safety research. To address this issue, we presented a semantic scene labeling approach that leverages wide-coverage street-level imagery for the purpose of exploring the association between built environment characteristics and perceived crash risk at 533 intersections. The environmental attributes were measured at eye-level using scene segmentation and object detection algorithms, and they were classified as one of four intersection typologies using the k-means clustering method. Data on perceived crash risk were collected from a questionnaire conducted on 799 children 10 to 12 years old. Our results showed that environmental features derived from deep learning algorithms were significantly associated with perceived crash risk among school-aged children. The results have revealed that some of the intersection characteristics including the proportional area of sky and roadway were significantly associated with the perceived crash risk among school-aged children. In particular, road width had dominant influence on risk perception. The findings provide information useful to providing appropriate and proactive interventions that may reduce the risk of crashes at intersections.},
institution = {Ulsan National Institute of Science and Technology},
annotation = {Children's perception of crash risk.  Odd.},
addendum = {},
}

@article{GONG2020105655,
title = {Multi-Objective reinforcement learning approach for improving safety at intersections with adaptive traffic signal control},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105655},
year = {2020},
author = {Yaobang Gong and Mohamed Abdel-Aty and Jinghui Yuan and Qing Cai},
keywords = {Traffic safety, Adaptive Signal control, Multi-objective reinforcement learning, Deep learning},
abstract = {Adaptive traffic signal control (ATSC) systems improve traffic efficiency, but their impacts on traffic safety vary among different implementations. To improve the traffic safety pro-actively, this study proposes a safety-oriented ATSC algorithm to optimize traffic efficiency and safety simultaneously. A multi-objective deep reinforcement learning framework is utilized as the backend algorithm. The proposed algorithm was trained and evaluated on a simulated isolated intersection built based on real-world traffic data. A real-time crash prediction model was calibrated to provide the safety measure. The performance of the algorithm was evaluated by the real-world signal timing provided by the local jurisdiction. The results showed that the algorithm improves both traffic efficiency and safety compared with the benchmark. A control policy analysis of the proposed ATSC revealed that the abstracted control rules could help the traditional signal controllers to improve traffic safety, which might be beneficial if the infrastructure is not ready to adopt ATSCs. A hybrid controller is also proposed to provide further traffic safety improvement if necessary. To the best of the authors’ knowledge, the proposed algorithm is the first successful attempt in developing adaptive traffic signal system optimizing traffic safety.},
institution = {U of Central Florida},
annotation = {Multi-Objective Deep Reinforcement Learning.  Adaptive traffic signal control.  Not our data.  Interesting for Dr. Jin?},
addendum = {Admittedly, there are several limitations. As the weighted sum approach
is not guaranteed to be Pareto-optimal, the study could be improved
by calculating the Pareto-front using more computationally efficient
algorithms. Meanwhile, other kinds of safety measures such as
traffic conflicts could be tested as the safety objective using the proposed
algorithm. Moreover, as vehicles’ operation speeds are correlated
with both efficiency and safety, controlling vehicles’ speed directly may
provide additional safety and operational benefits (Li et al., 2018; Ma
et al., 2017; Qu et al., 2020; Zhou et al., 2020). With the rapid development
of the connected and automated vehicles (CAV), a safety-oriented
control system that jointly controls of traffic signals and CAV
would be a valuable future research direction.},
}

@article{TARKO2020105536,
title = {Analyzing road near departures as failure-caused events},
journal = {Accident Analysis \& Prevention},
volume = {142},
number = {nan},
pages = {105536},
year = {2020},
author = {Andrew P. Tarko},
keywords = {Safety analysis, Surrogate measures of safety, Traffic conflicts, Crash frequency, Lomax distribution, Road near-departures},
abstract = {Surrogate measures of safety attract revived interest thanks to the advancements in traffic observations techniques and the growing need for rapid safety evaluation. A new method of safety analysis based on failure-caused traffic conflicts and the Lomax distribution was recently proposed to estimate crash frequency more efficiently than with crash data. This paper has two objectives: (1) demonstrate the method applicability to near-departure data collected in a driving simulator, and (2) provide initial evidence of the method validity. Traffic failures and road users’ delayed responses to these failures is considered as the primary cause of both conflicts and crashes. Unlike early postulated exceedance distributions the proposed Lomax distribution of response delays was derived from the causal mechanism. From this perspective, the proposed method may use the entire range of the underlying distribution as long as the observed conflicts are failure-related. The fundamentals of the method are briefly explained with the emphasis on certain behavior of crash frequency estimates implied by the proposed theory. Then, an example application of the method to analyze the risk of road departures in a driving simulator is presented. The results are then inspected and the trend in the estimates derived from the theory is confirmed. This finding points to the method validity. Additional applications of the method are expected to further increase the confidence towards the method and to encourage its introduction to the safety engineering practice.},
institution = {Purdue U},
annotation = {Not ML.  Not applicable to our data.},
addendum = {More studies are needed to build further confidence towards the
proposed failure-based traffic conflicts method. One of the available
opportunities is provided by naturalistic driving studies that deliver
traffic conflicts and collisions for the same observation period. The already
mentioned opportunity provided by emerging autonomous vehicles
is quite a realistic expectation which emphasizes the importance
of collecting and sharing such data for improving safety on public roads
with presence of new generation vehicles.},
}

@article{KHAN2020105837,
title = {Cyber-attacks in the next-generation cars, mitigation techniques, anticipated readiness and future directions},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105837},
year = {2020},
author = {Shah Khalid Khan and Nirajan Shiwakoti and Peter Stasinopoulos and Yilun Chen},
keywords = {Connected and autonomous vehicles (CAVs), Electronic control units (ECUs), Cybersecurity, CAVs communication framework, Driverless cars},
abstract = {Modern-day Connected and Autonomous Vehicles (CAVs) with more than 100 million code lines, running up-to a hundred Electronic Control Units (ECUs) will create and exchange digital information with other vehicles and intelligent transport networks. Consequently, ubiquitous internal and external communication (controls, commands, and data) within all CAV-related nodes is inevitably the gatekeeper for the smooth operation. Therefore, it is a primary vulnerable area for cyber-attacks that entails stringent and efficient measures in the form of "cybersecurity". There is a lack of systematic and comprehensive review of the literature on cyber-attacks on the CAVs, respective mitigation strategies, anticipated readiness, and research directions for the future. This study aims to analyse, synthesise, and interpret critical areas for the roll-out and progression of CAVs in combating cyber-attacks. Specifically, we described in a structured way a holistic view of potentially critical avenues, which lies at the heart of CAV cybersecurity research. We synthesise their scope with a particular focus on ensuring effective CAVs deployment and reducing the probability of cyber-attack failures. We present the CAVs communication framework in an integrated form, i.e., from In-Vehicle (IV) communication to Vehicle-to-Vehicle (V2X) communication with a visual flowchart to provide a transparent picture of all the interfaces for potential cyber-attacks. The vulnerability of CAVs by proximity (or physical) access to cyber-attacks is outlined with future recommendations. There is a detailed description of why the orthodox cybersecurity approaches in Cyber-Physical System (CPS) are not adequate to counter cyber-attacks on the CAVs. Further, we synthesised a table with consolidated details of the cyber-attacks on the CAVs, the respective CAV communication system, its impact, and the corresponding mitigation strategies. It is believed that the literature discussed, and the findings reached in this paper are of great value to CAV researchers, technology developers, and decision-makers in shaping and developing a robust CAV-cybersecurity framework.},
institution = {RMIT U},
annotation = {Not ML},
addendum = {},
}

@article{LI2020105756,
title = {Exploring drivers’ mental workload and visual demand while using an in-vehicle HMI for eco-safe driving},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105756},
year = {2020},
author = {Xiaomeng Li and Atiyeh Vaezipour and Andry Rakotonirainy and Sébastien Demmel and Oscar Oviedo-Trespalacios},
keywords = {Driving simulator, Eco-Safe driving, Mental workload, Visual demand, Driver assistance system},
abstract = {Eco-safe driving is a promising approach to improve road safety while reducing transport emissions. The application of an eco-safe driving system is feasible with the support of vehicle-to-vehicle/infrastructure technologies. To guarantee system usability and safety appropriateness, a key precondition is to ensure that driver mental workload and visual demands required for using the system are reasonable. This study explored how drivers’ mental workload and visual demands were affected when driving with an eco-safe driving HMI (human-machine-interface). Four in-vehicle eco-safe HMI information conditions were evaluated, including baseline, advice only, feedback only, and advice \& feedback. Two traffic scenarios (stop-sign intersection with traffic vs. stop-sign intersection without traffic) were simulated using an advanced driving simulator. Behavioural variables (e.g. brake force, acceleration), visual variables (e.g. blink metrics, pupil size) and subjective workload scores were collected from 36 licensed Australian drivers. The experiment results showed that the HMI prompted drivers to apply a smooth and stable brake force when they approached the intersection and a smooth acceleration when they left the intersection. Drivers’ mental workload indicated by visual measurements were consistent with their subjective reported workload levels. Drivers had a higher mental workload when they received and processed additional eco-safe information in the advice \& feedback condition. An increase in mental workload induced by the in-vehicle cognitive task initiated more blink activities while the increase in visual demand caused by a complex road situation led to blink inhibition. The study shows the HMI could significantly promote eco-safe driving behaivours without causing excessive mental and visual workload of drivers.},
institution = {U of Queensland},
annotation = {Not ML},
addendum = {},
}

@article{ISLAM2021105950,
title = {Crash data augmentation using variational autoencoder},
journal = {Accident Analysis \& Prevention},
volume = {151},
number = {nan},
pages = {105950},
year = {2021},
author = {Zubayer Islam and Mohamed Abdel-Aty and Qing Cai and Jinghui Yuan},
keywords = {Variational autoencoder, Data augmentation, Crash prediction},
abstract = {In this paper, we present a data augmentation technique to reproduce crash data. The dataset comprising crash and non-crash events are extremely imbalanced. For instance, the dataset used in this paper consists of only 625 crash events for over 6.5 million non-crash events. Thus, learning algorithms tend to perform poorly on these datasets. We have used variational autoencoder to encode all the events into a latent space. After training, the model could successfully separate crash and non-crash events. To generate data, we sampled from the latent space containing crash data. The generated data was compared with the real data from different statistical aspects. t-Test, Levene-test and Kolmogrove Smirnov test showed that the generated data was statistically similar to the real data. It was also compared to some of the minority oversampling techniques like SMOTE and ADASYN as well as the GAN framework for generating data. Crash prediction models based on Logistic Regression (LR), Support Vector Machine (SVM) and Artificial Neural Network (ANN) were used to compare the generated data from the different oversampling techniques. Overall, variational autoencoder (VAE) showed excellent results compared to the other data augmentation methods. Specificity is improved by 8\% and 4\% for VAE-LR and VAE-SVM respectively when compared to SMOTE while the sensitivity is improved by 6\% and 5\% when compared to ADASYN. Moreover, VAE generated data also helps to overcome the overfitting problem in SMOTE and ADASYN since there is flexibility in choosing the decision boundary.},
institution = {U of Central Florida},
annotation = {Interesting.  Data augmentation.},
addendum = {Future studies can train crash prediction models on more complex
and non-linear algorithms that do not perform well on small datasets.
Using VAE as a data generation tool in the pipeline would definitely aid
in generating substantial data to train on non-linear models. Furthermore,
there could be more work relating VAE that could have one more
class in between crash and non-crash: crash-prone. The training data of
this region could be derived from the false positives from our VAE
model.},
}

@article{YU2021106085,
title = {Trajectory data based freeway high-risk events prediction and its influencing factors analyses},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106085},
year = {2021},
author = {Rongjie Yu and Lei Han and Hui Zhang},
keywords = {Freeway operation and management, Vehicle trajectory data, High-crash risk, Random-effects logistic regression model, Traffic safety pre-warning},
abstract = {The frequent crash occurrences have caused massive loss of lives and properties all over the world. In order to improve traffic safety, it is vital to understand the relationships between traffic operation conditions and crash risk, and further implement safety countermeasures. Emerging studies have conducted the crash risk analyses using discrete and aggregated traffic data (e.g., loop detector data, probe vehicle data), where crash events were selected as the prediction target. However, traditional traffic sensing data obtained at segment level cannot describe the detailed operation conditions for the vehicle platoons near crash locations. Thus, more microscopic and high-resolution traffic sensing data are needed. In addition, considering the random occurrence feature of crashes, high-risk events should be paid more attentions given their higher occurrence probability and consistent causations with crashes, which could proactively reduce crash likelihood. In this study, HighD Dataset from German highways was utilized for the empirical analyses. First, high-risk events were obtained using safety surrogate measures with Modified Time to Collision (MTTC) less than 2 s. Traffic operation characteristics within 5 s prior to event occurrence were extracted based on vehicle trajectory data. Then, a total of three different logistic regression models were established, which are standard logistic regression model, random-effects logistic regression (RELR) model, and random-parameter logistic regression (RPLR) model. Among which, the RPLR model was showed to have the best fitness and prediction accuracy. The results showed that the disturbed traffic flows in both longitudinal and lateral directions have positive impacts on high-risk events occurrence. Besides, too close following distance between vehicles would lead to high-risk events. Moreover, RPLR models could provide a high prediction accuracy of 97 \% for 2 s ahead of the high-risk events. Finally, potential safety improvement countermeasures and future application scenarios were also discussed.},
institution = {},
annotation = {},
addendum = {},
}

@article{SILVA2020105694,
title = {Traffic campaigns and overconfidence: An experimental approach},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105694},
year = {2020},
author = {Thiago Christiano Silva and Marcela T. Laiz and Benjamin Miranda Tabak},
keywords = {Traffic campaigns, Overconfidence, Video, Machine learning, Econometrics},
abstract = {We use a controlled experiment to analyze the impact of watching different types of educational traffic campaign videos on overconfidence of undergraduate university students in Brazil. The videos have the same underlying traffic educational content but differ in the form of exhibition. We find that videos with shocking content (Australian school) are more effective in reducing drivers’ overconfidence, followed by those with punitive content (American school). We do not find empirical evidence that videos with technical content (European school) change overconfidence. Since several works point to a strong association between overconfidence and road safety, our study can support the conduit of driving safety measures by identifying efficient ways of reducing drivers’ overconfidence. Finally, this paper also introduces how to use machine learning techniques to mitigate the usual subjectivity in the design of the econometric specification that is commonly faced in many researches in experimental economics.},
institution = {},
annotation = {},
addendum = {},
}

@article{JI2020105730,
title = {An energy loss-based vehicular injury severity model},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105730},
year = {2020},
author = {Ang Ji and David Levinson},
keywords = {Injury severity, Regression model, Vehicle crashes, Energy absorption, Random Forest},
abstract = {How crashes translate into physical injuries remains controversial. Previous studies recommended a predictor, Delta-V, to describe the crash consequences in terms of mass and impact speed of vehicles in crashes. This study adopts a new factor, energy loss-based vehicular injury severity (ELVIS), to explain the effects of the energy absorption of two vehicles in a collision. This calibrated variable, which is fitted with regression-based and machine learning models, is compared with the widely-used Delta-V predictor. A multivariate ordered logistic regression with multiple classes is then estimated. The results align with the observation that heavy vehicles are more likely to have inherent protection and rigid structures, especially in the side direction, and so suffer less impact.},
institution = {U of Sydney},
annotation = {Predicting injury based on relative masses of vehicles.},
addendum = {Future research could extend the model by studying more crashes
with different collision angles and establishing the relationships between
crash types and their respective $\alpha$ values. It may also depend on
whether fragile or weak structures of vehicles receive the crash impact.
Other factors that significantly influence the energy absorption by vehicles
are also expected to improve estimation outcomes. Extensions to
consider elastic collisions and restitution coefficients may provide additional
useful insights for realistic crash studies.},
}

@article{JETTO2020105507,
title = {Cognitive anticipation cellular automata model: An attempt to understand the relation between the traffic states and rear-end collisions},
journal = {Accident Analysis \& Prevention},
volume = {142},
number = {nan},
pages = {105507},
year = {2020},
author = {Kamal Jetto and Zineb Tahiri and Abdelilah Benyoussef and Abdallah {El Kenz}},
keywords = {Rear-end collisions, Cognitive psychology, Cellular automaton model, Anticipation, Conservative driver, Aggressive driver, Simulation},
abstract = {We have investigated the accident’s statistics of Europe and North America that are provided by the UN. This investigation has shown that accidents due to the traffic represent around 50 \% of the total number of accidents every year. Among them, rear-end collisions hold a 20 \% share. These numbers display the fact that the interaction between drivers can be held responsible of those incidents. In this respect, we have explored the reasons behind the conflict situations that may be responsible of the occurrence of rear-end collisions by the mean of a cognitive psychology based cellular automata model. Indeed, through field experiments performed by an embedded camera, we have extricated a psychological cognitive process of anticipation. We have defined the latter as the tendency of drivers to accelerate based on the history of their predecessor. Then, we have exploited the tools of the physics of traffic by which we have developed a CA-model that take into consideration this process. As a result, we were able to generate those incidents’ situations. By considering two types of drivers: conservative who respect the learned information about the safe manoeuvres but make mistakes or aggressive who violate those secure processes, we have proved the complexity of the relationship between the states of the traffic flow and the drivers’ behaviours. In fact, we have shown that rear-end collisions are a result of the anticipation as a response of the drivers to the traffic conditions: the congestion. Moreover, we have also highlighted an improvement of the flow in the congested state up to 11 \% due to the anticipation, but that can only be achieved through vehicle-to-vehicle communication. Finally, we have investigated the hot spots. We have found that the traffic perturbations, that generate those hot spots and can be responsible of collisions, are more likely to be located away in the downstream direction. The distance between the two locations depends on the traffic density. This difference between the positions of the traffic perturbation and the hot spot has showcased the complexity, in time and space, of the transmission and the reception of deceleration information by the drivers.},
institution = {Ecole Hassania des Travaux Publics, University Mohammed V, Hassan II Academy of Science and Technology},
annotation = {Not ML, Not our data},
addendum = {},
}

@article{LI2020105658,
title = {This paper has been handled by associate editor Tony Sze.The application of novel connected vehicles emulated data on real-time crash potential prediction for arterials},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105658},
year = {2020},
author = {Pei Li and Mohamed Abdel-Aty and Qing Cai and Cheng Yuan},
keywords = {Real-time crash potential prediction, Connected vehicle emulated data, Urban arterials, Deep learning},
abstract = {Real-time crash potential prediction could provide valuable information for Active Traffic Management Systems. Fixed infrastructure-based vehicle detection devices were widely used in the previous studies to obtain different types of data for crash potential prediction. However, it was difficult to obtain data in large range through these devices due to the costs of installation and maintenance. This paper introduced a novel connected vehicle (CV) emulated data for real-time crash potential prediction. Different from the fixed devices’ data, CV emulated data have high flexibility and can be obtained continuously with relatively low cost. Crash and CV emulated data were collected from two urban arterials in Orlando, USA. Crash data were archived by the Signal for Analytics system (S4A), while the CV emulated data were obtained through the data collection API with a high frequency. Different data cleaning and preparation techniques were implemented, while various speed-related variables were generated from the CV emulated data. A Long Short-term Memory (LSTM) neural network was trained to predict the crash potential in the next 5−10 min. The results from the model illustrated the feasibility of using a novel CV emulated data to predict real-time crash potential. The average and 50th percentile speed were the two most important variables for the crash potential prediction. In addition, the proposed LSTM outperformed Bayesian logistics regression and XGBoost in terms of sensitivity, Area under Curve (AUC), and false alarm rate. With the rapid development of the connected vehicle systems, the results from this paper can be extended to other types of vehicles and data, which can significantly enhance traffic safety.},
institution = {U of Central Florida},
annotation = {Predict crash potential in the next 5-10 minutes using GPS data.},
addendum = {There are still several improvements that can be done in the future.
First, buses are one type of vehicles. It is very promising to explore the
fusion with other types vehicles, such as taxis, private vehicles, trucks,
etc. Second, the impact of the different variables on crash potential
prediction also needs further investigation, a proper variables generation
and selection process could possibly improve the performance of
the model. Forth, different deep learning architectures can be explored
in the future to improve the results of the current model. Finally, it
would be promising to combine the results from this paper with other
similar studies. For example, Wiseman and Grinberg (2016) proposed a
real-time crash potential damages assessment approach for autonomous
vehicles. If an autonomous vehicle can receive the crash potential
prediction results through CV as suggested in our paper, the information
may help it to avoid certain crashes. For the case of inevitable
crash, the crash potential damages assessment can help the vehicle
achieve the least damages.},
}

@article{THAPA2021106125,
title = {Using worker's naturalistic response to determine and analyze work zone crashes in the presence of work zone intrusion alert systems},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106125},
year = {2021},
author = {Diwas Thapa and Sabyasachee Mishra},
keywords = {Work zone, Transportation, Survival analysis, Highway crashes, Intrusion alert},
abstract = {Work zone Intrusion Alert Systems (WZIAS) are alert mechanisms that detect and alert workers of vehicles intruding into a work zone. These systems pre-dominantly employ two components-sensors placed near the work zone perimeter that detect intrusions, and alarms placed closed to or carried by the workers that alerts them. This study investigates the association between layout of these components for three WZIAS on work zone crashes based on worker reaction. Also, the key determinants of work zone crashes in presence of the WZIAS is identified using survival analysis. The ideal deployment strategy and use case scenarios for the three WZIAS is presented based on the findings of the study. The systems were subjected to rigorous testing that emulated intrusions to record worker reaction and determine occurrence of crashes. Analysis of results indicate that the key determinants of work zone crashes are speed of the intruding vehicle, distance between the sensor and worker, and accuracy of a system in detecting intrusions and alerting workers. Results from field experiments suggest that identification of appropriate use cases for WZIAS is necessary to ensure they work effectively. Based on the findings from this study it is suggested that current guidelines on work zones be modified to standardize WZIAS setup.},
institution = {},
annotation = {},
addendum = {},
}

@article{LIN2020105628,
title = {Automated traffic incident detection with a smaller dataset based on generative adversarial networks},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105628},
year = {2020},
author = {Yi Lin and Linchao Li and Hailong Jing and Bin Ran and Dongye Sun},
keywords = {GANs, Imbalance training samples, Incident detection, Spatial and temporal rules},
abstract = {An imbalanced and small training sample can cause an incident detection model to have a low detection rate and a high false alarm rate. To solve the scarcity of incident samples, a novel incident detection framework is proposed based on generative adversarial networks (GANs). First, spatial and temporal rules are presented to extract variables from traffic data, which is followed by the random forest algorithm to rank the importance of variables. Then, some new incident samples are generated using GANs. Finally, the support vector machine algorithm is applied as the incident detection model. Real traffic data, which were collected from a 69.5-mile section of the I-80 highway, are used to validate the proposed approach. A total of 140 detectors are installed on the section enabling traffic flow to be measured every 30s. During 14 days, 139 incident samples and 946 nonincident samples were extracted from the raw data. Five categories of experiments are designed to evaluate whether the proposed framework can solve the small sample size problem, imbalanced sample problem, and timeliness problem in the current incident detection system. The experimental results show that our proposed framework can considerably improve the detection rate and reduce the false alarm rate of traffic incident detection. The balance of the dataset can improve the detection rate from 87.48\% to 90.68\% and reduce the false alarm rate from 12.76\% to 7.11\%. This paper lends support to further studies on combining GANs with the machine learning model to address the imbalance and small sample size problems related to intelligent transportation systems.},
institution = {Sichuan U, Shenzhen U, U of Wisconsin Madison},
annotation = {Very Interesting.  Small dataset, imbalanced data, Real-time incident detection},
addendum = {Notably, only the SVM was applied as the incident detection model
to evaluate the proposed method in this paper. In the future, more incident
detection models should be implemented to test the proposed
method. Moreover, the traffic flow of urban roads is more complex. The
application of our proposed method in this area needs to be discussed in
the future.},
}

@article{ARUN2021106016,
title = {A systematic mapping review of surrogate safety assessment using traffic conflict techniques},
journal = {Accident Analysis \& Prevention},
volume = {153},
number = {nan},
pages = {106016},
year = {2021},
author = {Ashutosh Arun and Md Mazharul Haque and Ashish Bhaskar and Simon Washington and Tarek Sayed},
keywords = {Traffic conflicts, Surrogate safety framework, Crash-conflict relationship, Crash surrogates, Surrogate based crash severity},
abstract = {Safety assessment of road sections and networks have historically relied on police-reported crash data. These data have several noteworthy and significant shortcomings, including under-reporting, subjectivism, post hoc assessment of crash causes and contributing factors, limited behavioural information, and omitted potential important crash-related factors resulting in an omitted variable bias. Moreover, crashes are relatively rare events and require long observation periods to justify expenditures. The rarity of crashes leads to a moral dilemma—we must wait for sufficient crashes to accrue at a site—some involving injuries and even death—to then justify improvements to prevent crashes. The more quickly the profession can end its reliance on crashes to assess road safety, the better. Surrogate safety assessment methodologies, in contrast, are proactive in design, do not rely on crashes, and require shorter observation timeframes in which to formulate reliable safety assessments. Although surrogate safety assessment methodologies have been developed and assessed over the past 50 years, an overarching and unifying framework does not exist to date. A unifying framework will help to contextualize the role of various methodological developments and begin a productive discussion in the literature about how the various pieces do or should fit together to understand road user risk better. This paper aims to fill this gap by thoroughly mapping traffic conflicts and surrogate safety methodologies. A total of 549 studies were meticulously reviewed to achieve this aim of developing a unifying framework. The resulting framework provides a consolidated and up-to-date summary of surrogate safety assessment methodologies and conflict measures and metrics. Further work is needed to advance surrogate safety methodologies. Critical research needs to include identifying a comprehensive and reliable set of surrogate measures for risk assessment, establishing rigorous relationships between conflicts and crashes, developing ways to capture road user behaviours into surrogate-based safety assessment, and integrating crash severity measures into risk estimation.},
institution = {Queensland U of Technology, U of Queensland, U of British Columbia},
annotation = {Interesting for overview.  "Surrogate Safety" is looking for dangerous road conditions without waiting for crashes to occur.},
addendum = {the isolated view of surrogate safety assessment as an objective
unto itself has given rise to a lop-sided amount of research into the
development of novel surrogate measures that at the most provide incremental
benefits over traditional ones and less research into critical
issues like the development and validation of crash-conflict relationships.
The latter, along with the need for surrogate-based crash severity
estimation, constitute the most significant lacunae in surrogate assessment
and are critical for maturing this approach. Given insights gained
into the surrogate framework, it is hoped that future efforts shall focus
on focussed research into the specific gaps identified in this study.},
}

@article{ZHANG2021105911,
title = {A crash risk identification method for freeway segments with horizontal curvature based on real-time vehicle kinetic response},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105911},
year = {2021},
author = {Changjian Zhang and Jie He and Mark King and Ziyang Liu and Yikai Chen and Xintong Yan and Lu Xing and Hao Zhang},
keywords = {Freeway safety, Segments with horizontal curvature, Vehicle kinetic response, Negative binomial regression model, Random effects negative binomial regression model},
abstract = {With the development and maturation of vehicle-based data acquisition technology, in-vehicle data is increasingly being used to explore road safety. This paper reports on research that analyzed the real-time tire force data (kinetic response) obtained from vehicle kinetic experiments, and constructed a new approach for identifying the high-risk of crashes on freeway segments with horizontal curvature. First, the road was divided into 1km units. Then, taking into account the characteristics of freeway alignment, each segment with horizontal curve was selected as the object of subsequent analysis. Automotive instrumentation was used to obtain a measure of tire force in the course of normal driving. The entire data set was preprocessed according to rate of change and the density of the data was reduced. By defining the outliers of the kinetic data and conducting factor analysis, two representative crash risk indicators of longitudinal and lateral stability were obtained. Negative binomial regression model (NBR model) and random effects negative binomial regression model (RENBR model) were constructed and jointly applied based on the new indicators to predict the risk value of horizontal curve segments. The method showed good prediction performance (71.8 \%) for high-risk road segments with design flaws, but the predicted effect for low-risk road segments was not ideal. This study not only illustrated the effectiveness of in-vehicle data in assessing road crash risk by coupling multiple kinetic parameters, but also provided support for freeway safety research using surrogate measures of risk when there is a lack of crash statistics.},
institution = {Southeast U (Nanjing), Queensland U of Technology, Hefei U of Technology, Changsha U of Technology},
annotation = {Not ML},
addendum = {More Data},
}

@article{WATLING2021105900,
title = {Sensitivity and specificity of the driver sleepiness detection methods using physiological signals: A systematic review},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105900},
year = {2021},
author = {Christopher N. Watling and Md {Mahmudul Hasan} and Grégoire S. Larue},
keywords = {Fatigue, Drowsiness, Driving, Features, Machine learning, Ground truth, Physiological sleepiness},
abstract = {Driver sleepiness is a major contributor to road crashes. A system that monitors and warns the driver at a certain, critical level of arousal, could aid in reducing sleep-related crashes. To determine how driver sleepiness detection systems perform, a systematic review of the sensitivity and specificity outcomes was performed. In total, 21 studies were located that met inclusion criteria for the review. The range of sensitivity outcomes was between 39.0–98.8 \% and between 73.0–98.9 \% for specificity outcomes. There was considerable variation in the outcomes of the studies employing only one physiological measure (mono-signal approach), whereas, a poly-signal approach with multiple physiological signals resulted in more consistency with higher outcomes on both sensitivity and specificity metrics. Only six of the 21 studies had both sensitivity and specificity outcomes above 90.0 \%, which included mono- and poly-signal approaches. Moreover, increases in the number of features used in the sleepiness detection system did not result in higher sensitivity and specificity outcomes. Overall, there was considerable variability between the studies reviewed, including measures of ground truth, the features employed and the machine learning approach of the systems. A critical need for progressing any system is a revalidation of the system on a new sample of users. These aspects indicate considerable progress is needed with physiological-based driver sleepiness systems before they are at a sufficient standard to be deployed on-road.},
institution = {Queensland U of Technology},
annotation = {Not our data.},
addendum = {},
}

@article{KHATTAK2021106086,
title = {Investigating the relation between instantaneous driving decisions and safety critical events in naturalistic driving environment},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106086},
year = {2021},
author = {Zulqarnain H. Khattak and Michael D. Fontaine and Wan Li and Asad J. Khattak and Thomas Karnowski},
keywords = {Safety critical events, Naturalistic driving, Driving volatility, Bollinger bands, Vehicle kinematics, Mixed logit, Driving instability},
abstract = {The availability of large-scale naturalistic driving data provides enormous opportunities for studying relationships between instantaneous driving decisions prior to involvement in safety critical events (SCEs). This study investigates the role of driving instability prior to involvement in SCEs. While past research has studied crash types and their contributing factors, the role of pre-crash behavior in such events has not been explored as extensively. The research demonstrates how measures and analysis of driving volatility can be leading indicators of crashes and contribute to enhancing safety. Highly detailed microscopic data from naturalistic driving are used to provide the analytic framework to rigorously analyze the behavioral dimensions and driving instability that can lead to different types of SCEs such as roadway departures, rear end collisions, and sideswipes. Modeling results reveal a positive association between volatility and involvement in SCEs. Specifically, increases in both lateral and longitudinal volatilities represented by Bollinger bands and vehicular jerk lead to higher likelihoods of involvement in SCEs. Further, driver behavior related factors such as aggressive driving and lane changing also increases the likelihood of involvement in SCEs. Driver distraction, as represented by the duration of secondary tasks, also increases the risk of SCEs. Likewise, traffic flow parameters play a critical role in safety risk. The risk of involvement in SCEs decreases under free flow traffic conditions and increases under unstable traffic flow. Further, the model shows prediction accuracy of 88.1 \% and 85.7 \% for training and validation data. These results have implications for proactive safety and providing in-vehicle warnings and alerts to prevent the occurrence of such SCEs.},
institution = {UVA, U of Tennessee, Oak Ridge},
annotation = {Not ML},
addendum = {},
}

@article{ZOU2020105568,
title = {Fifty Years of Accident Analysis \& Prevention: A Bibliometric and Scientometric Overview},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105568},
year = {2020},
author = {Xin Zou and Hai L. Vu and Helai Huang},
keywords = {Accident Analysis \& Prevention, Road safety, Bibliometrics, Scientometrics, Journal analysis, Revised Haddon matrix},
abstract = {Accident Analysis \& Prevention (AA\&P) is a leading academic journal established in 1969 that serves as an important scientific communication platform for road safety studies. To celebrate its 50th anniversary of publishing outstanding and insightful studies, a multi-dimensional statistical and visualized analysis of the AA\&P publications between 1969 and 2018 was performed using the Web of Science (WoS) Core Collection database, bibliometrics and mapping-knowledge-domain (MKD) analytical methods, and scientometric tools. It was shown that the annual number of AA\&P’s publications has grown exponentially and that over the course of its development, AA\&P has been a leader in the field of road safety, both in terms of innovation and dissemination. By determining its key source countries and organizations, core authors, highly co-cited published documents, and high burst-strength publications, we showed that AA\&P’s areas of focus include the “effects of hazard and risk perception on driving behavior”, “crash frequency modeling analysis”, “intentional driving violations and aberrant driving behavior”, “epidemiology, assessment and prevention of road traffic injuries”, and “crash-injury severity modeling analysis”. Furthermore, the key burst papers that have played an important role in advancing research and guiding AA\&P in new directions – particularly those in the fields of crash frequency and crash-injury severity modeling analyses were identified. Finally, a modified Haddon matrix in the era of intelligent, connected and autonomous transportation systems is proposed to provide new insights into the emerging generation of road safety studies.},
institution = {Monash U, Central South U (Changsha)},
annotation = {Journal Metadata Analysis.  Curious.  },
addendum = {},
}

@article{CHEN2021106061,
title = {A data-driven feature learning approach based on Copula-Bayesian Network and its application in comparative investigation on risky lane-changing and car-following maneuvers},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106061},
year = {2021},
author = {Tianyi Chen and Yiik Diew Wong and Xiupeng Shi and Yaoyao Yang},
keywords = {Crash causal inference, Feature learning, Copula-Bayesian Network, Risky driving maneuver, Lane-changing, Car-following},
abstract = {The era of ‘Big Data’ provides opportunities for researchers to have deep insights into traffic safety. By taking advantages of ‘Big Data’, this study proposes a data-driven method to develop a Copula-Bayesian Network (Copula-BN) using a large-scale naturalistic driving dataset with multiple features. The Copula-BN is able to explain the causality of a risky driving maneuver. As compared with conventional BNs, the Copula-BN developed in this study has the following advantages: the Copula-BN 1. Has a more rational and explainable structure; 2. Is less likely to be over-fitting and can attain more satisfactory prediction performance; and 3. Can handle not only discrete but also continuous features. In terms of technical innovations, Shapley Additive Explanation (SHAP) is used for feature selection, while Gaussian Copula function is employed to build the dependency structure of the Copula-BN. As for applications, the Copula-BNs are used to investigate the causality of risky lane-changing (LC) and car-following (CF) maneuvers, upon which the comparisons are made between the two essential but risky driving maneuvers. In this study, the Copula-BNs are developed based on the Second Highway Research Program (SHRP2) Naturalistic Driving Study (NDS) database. Upon network evaluation, the Copula-BNs for both risky LC and CF maneuvers demonstrate satisfactory structure performance and promising prediction performance. Feature inferences are conducted based on the Copula-BNs to respectively illustrate the causation of the two risky maneuvers. Several interesting findings related to features’ contribution are discussed in this paper. To a certain extent, the Copula-BN developed using the data-driven method makes a trade-off between prediction and causality within the ‘Big Data’. The comparison between risky LC and CF maneuvers also provides a valuable reference for crash risk evaluation, road safety policy-making, etc. In the future, the achievements of this study could be applied in Advanced Driver-Assistance System (ADAS) and accident diagnosis system to enhance road traffic safety.},
institution = {Nanyang Technological U},
annotation = {Used Random Forest in feature selection},
addendum = {Need advanced data cleaning methods},
}

@article{ZHANG2020105799,
title = {Prediction of pedestrian-vehicle conflicts at signalized intersections based on long short-term memory neural network},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105799},
year = {2020},
author = {Shile Zhang and Mohamed Abdel-Aty and Qing Cai and Pei Li and Jorge Ugan},
keywords = {Pedestrian-vehicle conflicts, LSTM, Neural network, Connected vehicles},
abstract = {Pedestrian protection is an important component of road safety. Intersections are dangerous locations for pedestrians with mixed traffic. This paper aims to predict potential traffic conflicts between pedestrians and vehicles at signalized intersections. Using detection and tracking techniques in computer vision, pedestrians’ and vehicles’ features are extracted from video data. An LSTM (Long Short-term Memory) neural network is proposed to predict the pedestrian-vehicle conflicts 2 s ahead. The established model reaches an accuracy of 88.5 \% at one signalized intersection. It is further tested at a new intersection, reaching the accuracy of 84.9 \%, while the new data merely takes up 30 \% of the training data set. This indicates that the proposed model is promising to be implemented at different locations. Moreover, the proposed model can also be applied to develop collision warning systems under the Connected Vehicles’ environment.},
institution = {U of Central Florida},
annotation = {Not our data.  Video data. I think this is ``detection,'' not ``prediction.''},
addendum = {},
}

@article{MERCADER2020105703,
title = {Automatic incident detection on freeways based on Bluetooth traffic monitoring},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105703},
year = {2020},
author = {Pedro Mercader and Jack Haddad},
keywords = {Road safety, Automatic incident detection, Bluetooth sensors},
abstract = {A novel automatic incident detection (AID) method for freeways, based on the use of data provided by Bluetooth sensors and an unsupervised anomaly detection approach, is presented. The two main advantages of the proposed AID system are: (i) the use of Bluetooth sensors offers several practical advantages over inductive loop detectors (ILD), which is one of the preferred sensing technology for traffic flow; and (ii) the unsupervised anomaly detection approach builds a model without the need of incident information. A common problem when designing an AID system is that incident information, i.e., ground-truth data, with enough accuracy is seldom available. Isolation forest is the unsupervised anomaly detection approach adopted in this work. This method is based on characterizing anomalous traffic conditions by exploiting the fact that anomalies tend to be isolated. The most remarkable feature of this anomaly detection method is its high detection performance while having a very simple tuning procedure and an extremely low computational demand. Finally, the effectiveness of the presented AID method is demonstrated using real traffic data collected by a network of Bluetooth sensors installed in Ayalon Highway, Tel Aviv.},
institution = {Technion-Israel Institute of Technology},
annotation = {Primarily about sensors.  Not our data set.},
addendum = {It is also expected that other advanced methods like unsupervised
deep learning, see Chalapathy and Chawla (2019), Kwon et al. (2019),
may achieve the same or higher detection performance than the proposed
method. However, this is at the expense of using a more complex
model (large number of parameters) than the proposed in this work.
Finally, a caveat of the proposed AID method is that it is able to
identify anomalous traffic conditions, but it is not able to distinguish
the mechanism that generated these conditions, e.g., traffic accidents,
maintenance works, or anomalous traffic patterns. Future works could
explore the process of identification of anomalies and posterior classification
on data streams by applying novel techniques based on semisupervised
learning (Mu et al., 2017; Zhu et al., 2018b).},
}

@article{WORLE2020105617,
title = {Sleep in highly automated driving: Takeover performance after waking up},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105617},
year = {2020},
author = {Johanna Wörle and Barbara Metz and Ina Othersen and Martin Baumann},
keywords = {Takeover performance, Driver state, Sleep, Highly automated driving},
abstract = {Takeover performance in automated driving is subject to investigation in the context of a variety of driver states such as distraction or drowsiness. New driver states will emerge with increasing automation level with drivers potentially being allowed to sleep while driving a highly automated vehicle. Still at some point during a drive, drivers will be required to or voluntarily take back control of the vehicle. A simulator study was conducted to investigate drivers’ ability to take over the vehicle control after sleeping. In a within-subjects study design N = 25 test drivers completed a drive using a highly automated driving system a) during day time after a full night of sleep and b) early in the morning after a night of partial sleep deprivation. During the second drive, sleep was measured in drivers according to the American Academy of Sleep Medicine (AASM) standard using electroencephalography (EEG). In total, the participants had to handle four takeover requests (TORs) from the system, two while being awake (day drive) and two when being awakened from sleep stage N2 (morning drive). The objective criticality of the situations was assessed performing the Takeover Controllability rating (TOC-rating). The results indicate that the applied takeover time of 60 s was sufficient for drivers to reengage in driving after sleeping. Reaction times were extended by about 3 s after sleep compared to the wake condition. Takeover performance assessed with the TOC-rating however was clearly worse after sleep than after wakefulness which was also reflected in the drivers’ subjective perception of the criticality of the situation. Further research is needed on how to deal with performance impairments after waking up from sleep during automated driving.},
institution = {Würzburger Institut für Verkehrswissenschaften GmbH, Volkswagen, U of Ulm},
annotation = {Not our data.},
addendum = {},
}

@article{ZAFIAN2021106141,
title = {Using SHRP2 NDS data to examine infrastructure and other factors contributing to older driver crashes during left turns at signalized intersections},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106141},
year = {2021},
author = {Tracy Zafian and Alyssa Ryan and Ravi Agrawal and Siby Samuel and Michael Knodler},
keywords = {SHRP2, Naturalistic driving, Older drivers, Signalized intersection, Left turns},
abstract = {Drivers age 65 and over have higher rates of crashes and crash-related fatalities than other adult drivers and are especially over-represented in crashes during left turns at intersections. This research investigated the use of SHRP2 Naturalistic Driving Study (NDS) data to assess infrastructure and other factors contributing to left turn crashes at signalized intersections, and how to improve older driver safety during such turns. NDS data for trips involving signalized intersections and crash or near-crash events were obtained for two driver age groups: drivers age 65 and over (older drivers) and a sample of drivers age 30−49, along with NDS pre-screening and questionnaire data. Video scoring of all trips was performed to collect additional information on intersection and trip conditions. To identify the most influential factors of crash risk during left turns at signalized intersections, machine learning and regression models were used. The results found that in the obtained NDS dataset, there was a relatively small volume of crashes during left turns at signalized intersections. Further, model results found the statistically significant variables of crash risk for older drivers were associated more with health and cognitive factors rather than the infrastructure or design of the intersections. The results suggest that a study using only SHRP2 NDS data will not lead to definitive findings or recommendations for infrastructure changes to increase safety for older drivers at signalized intersections and during left turns. Moreover, the findings of this study indicates the need to consider other data sources and data collection methods to address this critical literature gap in older driver safety.},
institution = {},
annotation = {},
addendum = {},
}

@article{PETRAKI2020105657,
title = {Combined impact of road and traffic characteristic on driver behavior using smartphone sensor data},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105657},
year = {2020},
author = {Virginia Petraki and Apostolos Ziakopoulos and George Yannis},
keywords = {Driver behavior, Harsh events, Geometric characteristics, Traffic characteristics, Smartphone data},
abstract = {The objective of this research is to exploit high resolution driving behavior data collected via sensors of smartphones from 303 drivers in order to examine driver behavior at road segment and junction level. These sensor data are combined with traffic and road geometry characteristics and subsequently depicted spatially using Geographical Information System software. Events of harsh driver behavior (8592 harsh accelerations and 3946 harsh brakings) were mapped to delimited segments and junctions of two urban expressways in Athens, Greece. For the analysis, two multiple linear regression models and two log-linear regression models were developed. Results indicate that in road segments there is an increase in the number of harsh events if average traffic flow per lane increases in the respective areas. Furthermore, as the average occupancy increases in junctions, there is an increase in harsh accelerations, and as the average speed increases, more harsh deceleration events occur. It is evident that traffic characteristics (traffic flow \& speed) have the most statistically significant impact on the frequency of harsh events compared to factors related to road geometry and driver behavior.},
institution = {National Technical U of Athens},
annotation = {Not ML, Smartphone Data},
addendum = {The results of this study may be transferred to similar areas outside
the research area. However, prior to any generalization, necessary adjustments
should be made for possible variations in the road environment
and traffic. For instance, an analogous study should be conducted
for motorways or rural roads that have fundamentally different characteristics
than urban expressways in order to obtain more accurate
results for these road environments. Alternative count models such as
GLMs with known merits for similar research or machine learning
methods should also be investigated. Initial Poisson loglinear model
applications have shown that the discovered relationships are retained
in significance and sign (positive or negative influences). Intuitively,
several crash frequency methods found in the rich road safety literature
have the potential to be applied in harsh event investigation, and the
respective findings will augment and expand the knowledge obtained
from strictly analyzing crashes.
Furthermore, a very promising direction for future research would
be the investigation of crash numbers and locations in the same research
areas. It would be fruitful to test correlations of crash frequencies
with some of the variables that have been identified in the
present study, and to explore any correlations between harsh event
frequencies and crash frequencies as well. However, it is worth noting
that this endeavor requires significant updates in crash data collection
procedures in Greece, as crash locations tend to be very imprecise
compared to high-resolution smartphone data. A similar conundrum
rises when weather data are brought into consideration. The inclusion
of weather data in the present context would be quite interesting, as
there can be considered to be related to crashes from research
(Theofilatos and Yannis, 2014), and to harsh events from observation
and experience. However, the high resolution smartphone data utilized
in the study would be best paired with comparably high resolution
weather data, which are at present not readily available. Therefore,
further research is needed to create a proper smartphone naturalistic
driving data and weather data merging scheme, which will yield usable
results towards this direction.},
}

@article{KUSKAPAN2021106098,
title = {Speed violation analysis of heavy vehicles on highways using spatial analysis and machine learning algorithms},
journal = {Accident Analysis \& Prevention},
volume = {155},
number = {nan},
pages = {106098},
year = {2021},
author = {Emre Kuşkapan and M. Yasin Çodur and Ahmet Atalay},
keywords = {Heavy vehicles, Speed violation, Machine learning, Spatial analysis},
abstract = {With the development of technology in the world, vehicles that reach high speeds are produced. In addition, with the increase of road width and quality, faster and more comfortable transportation can be provided. These developments also increase the speed violation rates of road vehicles. Drivers who violate speed limits can endanger both their own lives and the lives of others. Speed violations, of especially heavy vehicles, involve much greater risks than that of light vehicles. Heavy vehicles can cause more serious losses of lives and property in accidents, compared to the ones caused by light vehicles, as they can carry much more freight or passengers than light vehicles. In this study, data regarding the speed violations committed by heavy vehicles in Turkey, were used. Speed violations were divided into 10 classes according to the intensity of speed violation rates. After this process, all provinces were classified according to support vector machines (SVM), naive bayes (NB) and k-nearest neighbors (KNN) algorithms. When the accuracy values and error scales of all three algorithms are examined, it has been determined that the algorithm that gives the most accurate results is the NB algorithm. Based on the classification of this algorithm, speed violation density maps of types of heavy vehicles in Turkey were created by using spatial analysis. According to the density maps, the provinces with the highest speed violations were identified. In the results, it was determined that the rate of heavy vehicle speed violation was highest in the cities such as Erzurum, Konya, and Muğla. Later, these cities were examined in terms of heavy vehicle mobility. At the end of this study, measures were proposed to reduce these violations in cities where speeding violations are intense. Material and moral damages can be prevented, to a great extent, with the implementation of recommendations of policymakers which can reduce speed violations.},
institution = {Erzurum Technical U, Ataturk U},
annotation = {Identifying provinces of Turkey with the worst speed violations by heavy vehicles.  },
addendum = {},
}

@article{YAHAYA2021105936,
title = {Bayesian networks for imbalance data to investigate the contributing factors to fatal injury crashes on the Ghanaian highways},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105936},
year = {2021},
author = {Mahama Yahaya and Runhua Guo and Wenbo Fan and Kamal Bashir and Yingfei Fan and Shiwei Xu and Xinguo Jiang},
keywords = {Crash injury severity, Imbalance data, Oversampling techniques, Bayesian networks, Classification},
abstract = {The crash data are often predominantly imbalanced, among which the fatal injury (or minority) crashes are significantly underrepresented relative to the non-fatal injury (or majority) ones. This unbalanced phenomenon poses a huge challenge to most of the statistical learning methods and needs to be addressed in the data preprocessing. To this end, we comparatively apply three data balance methods, i.e., the Synthetic Minority Oversampling Technique (SMOTE), the Borderline SMOTE (BL-SMOTE), and the Majority Weighted Minority Oversampling (MWMOTE). Then, we examine different Bayesian networks (BNs) to explore the contributing factors of fatal injury crashes. The 2016 highway crash data of Ghana are retrieved for the case study. The results show that the accuracy of the injury severity classification is improved by using the preprocessed data. Highest improvement is observed on the data preprocessed by the MWMOTE technique. Statistical verification is done by the Wilcoxon signed-rank test. The inference results of the best BNs show the significant factors of fatal crashes which include off-peak time, non-intersection area, pedestrian involved collisions, rural road environment, good tarred road, roads without shoulders, and multiple vehicles involved crash.},
institution = {},
annotation = {See same article by same authors.},
addendum = {},
}

@article{BRIDGELALL2021106126,
title = {Railroad accident analysis using extreme gradient boosting},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106126},
year = {2021},
author = {Raj Bridgelall and Denver D. Tolliver},
keywords = {Data cleaning, Feature engineering, Financial loss, Machine learning, Principle component analysis, Risk management},
abstract = {Railroads are critical to the economic health of a nation. Unfortunately, railroads lose hundreds of millions of dollars from accidents each year. Trends reveal that derailments consistently account for more than 70 \% of the U.S. railroad industry’s average annual accident cost. Hence, knowledge of explanatory factors that distinguish derailments from other accident types can inform more cost-effective and impactful railroad risk management strategies. Five feature scoring methods, including ANOVA and Gini, agreed that the top four explanatory factors in accident type prediction were track class, type of movement authority, excess speed, and territory signalization. Among 11 different types of machine learning algorithms, the extreme gradient boosting method was most effective at predicting the accident type with an area under the receiver operating curve (AUC) metric of 89 \%. Principle component analysis revealed that relative to other accident types, derailments were more strongly associated with lower track classes, non-signalized territories, and movement authorizations within restricted limits. On average, derailments occurred at 16 kph below the speed limit for the track class whereas other accident types occurred at 32 kph below the speed limit. Railroads can use the integrated data preparation, machine learning, and feature ranking framework presented to gain additional insights for managing risk, based on their unique operating environments.},
institution = {North Dakota State U},
annotation = {Interesting.  Similar to our data and approach, but with train derailments.  },
addendum = {},
}

@article{PENG2020105610,
title = {Examining imbalanced classification algorithms in predicting real-time traffic crash risk},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105610},
year = {2020},
author = {Yichuan Peng and Chongyi Li and Ke Wang and Zhen Gao and Rongjie Yu},
keywords = {Continuous data environment, Real-time crash risk prediction models, Imbalanced data classification, RCSMLP, Rusboost model},
abstract = {The Active Traffic Management (ATM) system has been widely used in the United States and the European countries to improve the traffic safety of urban expressways. The accurate real-time crash risk prediction is fundamental to the system running well. Crash data are characterized by small probability, which poses a typical Imbalanced Data Classification problem. Most previous studies mainly improved the prediction methods only in data level or algorithm level, which may be inadequate to predict the crash risk accurately especially in a continuous real-time traffic data environment. The comprehensive imbalanced classification algorithm was examined in this research to build more accurate real-time traffic crash risk prediction model. At the output level, the Youden index method has been proved to be of the best ability to divide the prediction results and Probability Calibration Method was proposed to optimize the prediction results in further. At the data level, Under-sampling and Synthetic Minority Oversampling Technique(SMOTE) methods were compared to solve the imbalanced data classification problem by changing the data distribution. At the algorithm level, the cost-sensitive MLP algorithm and Adaboost algorithm were examined and finally the random sampling cost-sensitive MLP model(RCSMLP) and Rusboost model were constructed by synthesizing the optimization methods from three levels. The sensitivity of the RCSMLP model reached 78.10 \% and the specificity of the model reached 81.44 \%. The AUC and sensitivity of the Rusboost model reached 0.892 and 0.842 while the specificity of the model reached 0.816, which shows the better performance in dealing with the imbalanced traffic crash risk prediction problem compared to existed prediction models. The proposed method of improving prediction accuracy in this study is universal and can be applied to many other prediction models to predict real-time traffic crash risk.},
institution = {Tongji U},
annotation = {Interesting for comparing algorithms.},
addendum = {},
}

@article{RAHIM2021106090,
title = {A deep learning based traffic crash severity prediction framework},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106090},
year = {2021},
author = {Md Adilur Rahim and Hany M. Hassan},
keywords = {Traffic collision/accident severity, Deep learning, Transfer learning, Numeric to image transformation, Customized loss function},
abstract = {Highway work zones are most vulnerable roadway segments for congestion and traffic collisions. Hence, providing accurate and timely prediction of the severity of traffic collisions at work zones is vital to reduce the response time for emergency units (e.g., medical aid), accordingly improve traffic safety and reduce congestion. In predicting the severity of traffic collisions, previous studies used different statistical and machine learning models with accuracy as the main evaluating factor. However, the performance of these models was generally not good, especially on fatal and injury crashes. Also, looking into the prediction accuracy only is misleading. This paper aims to propose a novel deep learning-based approach with a customized f1-loss function to predict the severity of traffic crashes. Underlying this objective is to compare the results of deep learning models with machine learning model considering two performance indicators, namely precision, and recall. The data used in the analysis include a sample of traffic crashes that occurred at work zones in Louisiana from 2014 to 2018. This dataset includes valuable information (features) related to road, vehicle, and human factors affecting the occurrence and severity of those crashes. The proposed methodology is based on transforming these features/variables into images. Image transformation is conducted using a nonlinear dimensionality reduction technique t-SNE and convex hull algorithm. A CNN based deep learning algorithm with a customized loss function was used to directly optimize the model for precision and recall. The results showed improved performance in predicting the crash severity of fatal and injury crashes using the deep learning approach, which can help to improve traffic safety as well as traffic congestion at work zones and possibly other roadways segments.},
institution = {LSU},
annotation = {Interesting

\vskip 12pt


Starts off seeming like it's going to be about real-time crash prediction, but then only uses old data, 2014-2018.  

\vskip 12pt

Crash severity prediction model.  

\vskip 12pt

Talks about different metrics:  Precision, Recall, Accuracy, Cross-entropy loss.  In an imbalanced dataset, accuracy places more weight on the common classes than in the rare classes.  Precision and recall penalize a model for ignoring the minority classes.  

\vskip 12pt

This paper's method emphasizes the recall value of the fatal crashes, because we can allow false positives (non-fatal crashes predicted as fatal) but not false negatives (fatal crashes predicted as non-fatal).  

\vskip 12pt

Transformed numerical data to images, then used CNN, which usually (a) extracts features from the images and (b) classifies the images.  They used transfer learning to do the feature extraction.  

\vskip 12pt

Compared CNN with the weird image transformation to SVN.  

\vskip 12pt

Statistical Learning and ML models compared in lit review:

\vskip 12pt
(SVM) Support Vector Machine,
\vskip 0pt
(OP) Ordered Probit,
\vskip 0pt
Logistic Regression,
\vskip 0pt
(CART) Classification and Regression Tree
\vskip 0pt
Abdel-Aty used a variable selection procedure prior to model estimation (?)
\vskip 0pt
(BLR) Bayesian Logistic Regression,
\vskip 0pt
(ROC) Receiver Operating Characteristic Metric,
\vskip 0pt
(AUC) Area Under Curve, especially under ROC curve,
\vskip 0pt
SVM with Radial-basis kernel function, 
\vskip 0pt
SVM with the polynomial kernel outperformed the Gaussian radial basis kernel,
\vskip 0pt
(ANN) Artificial Neural Network compared to Ordered Probit, 
\vskip 0pt
$k$-means algorithm clustered the dataset into three clusters to improve ANN's performance,
\vskip 0pt
Random Forest outperformed Logistic Regression, Naive Bayes, and AdaBoost, 
\vskip 0pt
(LSTM) Long Short-Term Memory beat (MLP) Multilayer Perceptron and (BLR) Bayesian Logistic Regression.
\vskip 12pt
Zheng (2019)
\vskip 0pt
(CNN) Convolutional Neural Network used (FM2GI) Feature Matrix to Gray Image algorithm to convert traffic accident data to gray images to be input for the image classification model.  
\vskip 0pt
Cross-entropy loss used with Adam optimizer to optimize the model.
\vskip 0pt
(SMOTE) Synthetic Minority Oversampling Technique used to deal with an imbalanced dataset.
\vskip 0pt
(STCL-Net) Spatiotemporal Convolutional Long Short-term Memory Network beat benchmark models in (MSE) Mean Squared Error, (MAE) Mean Absolute Error, and (MAPE) Mean Absolute Percentage Error metrics.
\vskip 0pt
CNN with dropout operation (What is that?) performed better than shallow models (what are those?)
\vskip 0pt
(LSTM-CNN) Long Short-Term Memory Convolutional Neural Network outperformed LSTM, CNN, XGBoost, BLR in terms of sensitivity and false alarm rate.
\vskip 0pt
(R-CNN) Region-based Convolutional Neural Networks
\vskip 0pt
(DNN) Deep Neural Network predicted traffic conflicts in real time with high prediction accuracy and sensitivity, and low false alarm rate.
\vskip 0pt
(LSTMDTR) LSTM models for (DTR) Different Temporal Resolutions.  Number of neurons in the model affected performance and computation time.
\vskip 0pt
CNN and (GRU) Gated Recurrent Units combined to make a fusion model.

\vskip 12pt
{\bf Data}
\vskip 0pt
Louisiana DOTD data, 2014-2018, 10,048 crashes with 98 variables.  Why so few crashes?
\vskip 0pt
42 fatal, 2699 injury, 7307 (PDO) Property Damage Only

\vskip 12pt
{\bf Data Cleaning}
\vskip 0pt
Long section on how the authors cleaned the data.
\vskip 0pt
Took out records with missing or inconsistent data, rather than fixing them.
\vskip 0pt
Long list of types of records they considered inconsistent.
\vskip 0pt
Final dataset had 33 fatal, 1806 injury, and 4497 PDO, total 6336.
\vskip 0pt
Removed $(42-33)/42 =  9/42 = 21\%$ of fatal, $(2699-1806)/2699 =  893/2699 = 33\%$ of injury, $(7307 - 4497)/7307 =  2810/7307 = 38\%$ of PDO, and $(10048 - 6336)/10048 = 3712/10048 = 37\%$ total.  

\vskip 12pt
{\bf Variable Selection}

Use (CART) Classification and Regression Tree and (MARS) Multivariate Adaptive Regression Spline to select the variables that have significant associations with the dependent variable (crash severity).  

CART returned ten significant variables; MARS, twelve.  

\vskip 12pt
{\bf Transfer Learning}


},
addendum = {Future studies may further tune the weight parameter ($\beta$) of the loss
function and the threshold value for classifiers to get more optimized
precision and recall values suitable for real-life applications.},
}

@article{SUAREZDELFUEYO2021105787,
title = {Cluster analysis of seriously injured occupants in motor vehicle crashes},
journal = {Accident Analysis \& Prevention},
volume = {151},
number = {nan},
pages = {105787},
year = {2021},
author = {Rocio {Suarez-del Fueyo} and Mirko Junge and Francisco Lopez-Valdes and H. Clay Gabler and Lucas Woerner and Stefan Hiermaier},
keywords = {None},
abstract = {Permanent monitoring of real-world crashes is important to identify injury patterns and injury mechanisms that still occur in the field despite existing regulations and consumer testing programs. This study investigates current injury patterns at the MAIS 3+ level in the accident environment without limiting the impact direction. The approach consisted of applying unsupervised clustering algorithms to NASS-CDS crash data in order to classify seriously injured, belted occupants into clusters based on injured body regions, biomechanical characteristics and crash severity. Injury patterns in each cluster were analyzed and associated with other characteristics of the crash, such as the collision configuration. The groups of seriously injured occupants found in this research contain a large amount of information and research possibilities. The resulting clusters represent new opportunities for vehicle safety, which have been highlighted in this study.},
institution = {U Pontifica, Virginia Tech, Albert-Ludwigs U, Porche, Volkswagen},
annotation = {Not our data set, Unsupervised Clustering, Interesting for clustering algorithm and suggestions for future work.},
addendum = {The use of the reconstruction delta-v in NASS-CDS is a limitation of
this study. Also the assumption of 10,000 kg as the weight of the rigid
objects for the calculation of the mass ratio in the cluster analysis has to
be considered as a limitation. This assumption produces outliers in the
distribution of the MR variable (Fig. 1). The cases considered in this
study were not weighted with the NASS-CDS weights. This research
focuses on the injury patterns of seriously injured occupants and the
collision configurations in which they were involved. Since this study
makes no comparison to lower severity crashes, the use of the NASS-CDS
weighting factors is not necessary. However, it might be interesting for
further research to estimate the contribution of the clusters to the total
number of seriously injured occupants in the US.
It is important to note that the clusters found in this study contain a
large amount of information and research possibilities. The aim of this
publication is to present the methodology and to provide insight into the
current issues in severe real-world crashes without limiting the impact
direction. Further work is planned on the validation of the clusters with
a different accident database. Specific injuries and injury mechanisms
related to the clusters are currently being investigated.},
}

@article{QIAO2020105775,
title = {Effects of state-led suburbanization on traffic crash density in China: Evidence from the Chengdu City Proper},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105775},
year = {2020},
author = {Si Qiao and Anthony {Gar-On Yeh} and Mengzhu Zhang and Xiang Yan},
keywords = {Built environment, State-led suburbanization, Neighborhood-level automobile-involved crash density, Safe urban form},
abstract = {Road crashes have become a leading cause of death in China. Although enormous efforts have been exerted to determine the factors that affect individual crash incidents, neighborhood-level crash incidence in Chinese cities has not been sufficiently analyzed. This study fills this gap by quantifying the effects of built environment factors on neighborhood-level automobile-involved crash density (NACD) in urban China and identifying its mediators and mediating effects. In American suburbs, urban sprawl is widely recognized to render neighborhoods unsafe for residence, thus leading to a high crash incidence. This study compares the characteristics of built environments between inner-city neighborhoods and the new neighborhoods that have been developed through China’s state-led suburbanization since 2008 to reveal how this suburbanization provides a safer neighborhood environment. A structural equation model is used to examine the relationships among suburbanization, built environment factors, and NACD in the city proper of Chengdu, the largest metropolis in southwest China. Thus, this study contributes new empirical evidence to the debates over urban designs that are safest for traffic. Moreover, this study enriches our understanding of different sociospatial consequences between American-style urban sprawl and China’s state-led suburbanization.},
institution = {U of Hong Kong},
annotation = {Not ML},
addendum = {},
}

@article{KRUEGER2020105623,
title = {A new spatial count data model with Bayesian additive regression trees for accident hot spot identification},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105623},
year = {2020},
author = {Rico Krueger and Prateek Bansal and Prasad Buddhavarapu},
keywords = {Accident analysis, Site ranking, Spatial count data modelling, Negative binomial model, Bayesian additive regression trees, Pólya-Gamma data augmentation},
abstract = {The identification of accident hot spots is a central task of road safety management. Bayesian count data models have emerged as the workhorse method for producing probabilistic rankings of hazardous sites in road networks. Typically, these methods assume simple linear link function specifications, which, however, limit the predictive power of a model. Furthermore, extensive specification searches are precluded by complex model structures arising from the need to account for unobserved heterogeneity and spatial correlations. Modern machine learning (ML) methods offer ways to automate the specification of the link function. However, these methods do not capture estimation uncertainty, and it is also difficult to incorporate spatial correlations. In light of these gaps in the literature, this paper proposes a new spatial negative binomial model which uses Bayesian additive regression trees to endogenously select the specification of the link function. Posterior inference in the proposed model is made feasible with the help of the Pólya-Gamma data augmentation technique. We test the performance of this new model on a crash count data set from a metropolitan highway network. The empirical results show that the proposed model performs at least as well as a baseline spatial count data model with random parameters in terms of goodness of fit and site ranking ability.},
institution = {Ecole Polytechnique Fédérale de Lausanne, Imperial College London, UT Austin},
annotation = {Not ML},
addendum = {None ML-related},
}

@article{DU2020105804,
title = {Psychophysiological responses to takeover requests in conditionally automated driving},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105804},
year = {2020},
author = {Na Du and X. Jessie Yang and Feng Zhou},
keywords = {Human–automation interaction, Automated driving, Transition of control, Psychophysiological measures},
abstract = {In SAE Level 3 automated driving, taking over control from automation raises significant safety concerns because drivers out of the vehicle control loop have difficulty negotiating takeover transitions. Existing studies on takeover transitions have focused on drivers’ behavioral responses to takeover requests (TORs). As a complement, this exploratory study aimed to examine drivers’ psychophysiological responses to TORs as a result of varying non-driving-related tasks (NDRTs), traffic density and TOR lead time. A total number of 102 drivers were recruited and each of them experienced 8 takeover events in a high fidelity fixed-base driving simulator. Drivers’ gaze behaviors, heart rate (HR) activities, galvanic skin responses (GSRs), and facial expressions were recorded and analyzed during two stages. First, during the automated driving stage, we found that drivers had lower heart rate variability, narrower horizontal gaze dispersion, and shorter eyes-on-road time when they had a high level of cognitive load relative to a low level of cognitive load. Second, during the takeover transition stage, 4 s lead time led to inhibited blink numbers and larger maximum and mean GSR phasic activation compared to 7 s lead time, whilst heavy traffic density resulted in increased HR acceleration patterns than light traffic density. Our results showed that psychophysiological measures can indicate specific internal states of drivers, including their workload, emotions, attention, and situation awareness in a continuous, non-invasive and real-time manner. The findings provide additional support for the value of using psychophysiological measures in automated driving and for future applications in driver monitoring systems and adaptive alert systems.},
institution = {U of Michigan},
annotation = {Not our data.},
addendum = {},
}

@article{SHIRANIBIDABADI2020105735,
title = {Developing Bicycle-Vehicle Crash-Specific Safety Performance Functions in Alabama Using Different Techniques},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105735},
year = {2020},
author = {Niloufar Shirani-bidabadi and Naveen Mallipaddi and Kirolos Haleem and Michael Anderson},
keywords = {Bicycle-Vehicle Crashes, Multivariate Adaptive Regression Splines, MARS, Safety Performance Functions, Conway-Maxwell-Poisson, COM-Poisson},
abstract = {This study develops bicycle-vehicle safety performance functions (SPFs) for five facilities in the Highway Safety Manual (HSM). These are urban two-lane undivided segments (U2U), urban four-lane divided/undivided segments (U4DU), rural two-lane undivided segments (R2U), urban four-leg and three-leg signalized intersections (USG), and urban four-leg and three-leg stop-controlled intersections (UST). Two modeling techniques were explored, the Conway-Maxwell-Poisson (COM-Poisson) model (to accommodate bicycle-vehicle crash under-dispersion) and a machine learning technique, the multivariate adaptive regression splines (MARS). MARS is a non-black-box model and can effectively handle non-linear crash predictors and interactions. A total of 1,311 bicycle-vehicle crashes from 2011 through 2015 in Alabama were collected and their respective police reports were reviewed in details. Results from the SPFs for roadway segments using COM-Poisson showed that bicycle-vehicle crash frequencies were reduced along curved and downgrade/upgrade stretches and when having heavy traffic flow (along U2U segments). For urban signalized (USG) intersections, the absence of right-turn lanes on minor roads, the presence of bus stops, and the increase in the major road annual average daily traffic (AADT) were significant factors contributing to the increase in the number of bicycle-vehicle crashes. However, the presence of divided medians on major approaches was found to reduce bicycle-vehicle crashes at USG and UST intersections. MARS outperformed the corresponding COM-Poisson models for all five facilities based on mean absolute deviance (MAD), mean square prediction error (MSPE), and generalized R-square. MARS is recommended as a promising technique for effectively predicting bicycle-vehicle crashes on segments and intersections.},
institution = {U of Alabama Huntsville, Western Kentucky U},
annotation = {Small data set.  Homework assignment},
addendum = {Further research could compare the findings of this study with other
bicycle safety studies in other states to see how bicycle-vehicle crash
predictions using the MARS technique would concur or differ. The
comparison can also pinpoint any differences in the significant predictors
of bicycle-vehicle crashes at both segments and intersections in
the analyzed states. Another research venue is to compare the MARS
technique with other modeling approaches, e.g., the random-parameter
negative binomial model to see how close or far the predictions are.},
}

@article{PAEZ2020105666,
title = {A systematic assessment of the use of opponent variables, data subsetting and hierarchical specification in two-party crash severity analysis},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105666},
year = {2020},
author = {Antonio Paez and Hany Hassan and Mark Ferguson and Saiedeh Razavi},
keywords = {None},
abstract = {Road crashes impose an important burden on health and the economy. Numerous efforts have been undertaken to understand the factors that affect road collisions in general, and the severity of crashes in particular. In this literature several strategies have been proposed to model interactions between parties in a crash, including the use of variables regarding the other party (or parties) in the collision, data subsetting, and estimating models with hierarchical components. Since no systematic assessment has been conducted of the performance of these strategies, they appear to be used in an ad-hoc fashion in the literature. The objective of this paper is to empirically evaluate ways to model party interactions in the context of crashes involving two parties. To this end, a series of models are estimated using data from Canada's National Collision Database. Three levels of crash severity (no injury/injury/fatality) are analyzed using ordered probit models and covariates for the parties in the crash and the conditions of the crash. The models are assessed using predicted shares and classes of outcomes, and the results highlight the importance of considering opponent effects in crash severity analysis. The study also suggests that hierarchical (i.e., multi-level) specifications and subsetting do not necessarily perform better than a relatively simple single-level model with opponent-related factors. The results of this study provide insights regarding the performance of different modelling strategies, and should be informative to researchers in the field of crash severity.},
institution = {McMaster U, LSU},
annotation = {Interesting for solid paper.},
addendum = {The analysis also opens up a few avenues for future research. First,
for reasons discussed in Section 6, we did not consider more sophisticated
modelling approaches, such as models with random components,
partial proportional odds, ranked ordered models, or multinomial
models, to mention just a few possibilities. Secondly, we only considered
the performance of the models when making predictions for the
full sample. That is, the submodels in the ensembles were not compared
in detail, just their aggregate results when predicting the full sample.
However, the goodness-of-fit was not uniformly better for any one
modelling strategy when the data were subset, and it is possible that
individual models perform better for a certain subset than competitors
that are part of a better ensemble, overall. For this reason, we suggest
that additional work with ensemble approaches is warranted. Finally, it
is clear that the models do not generally do well when predicting the
least frequent class of outcome, namely Fatality. It would be worthwhile
to further investigate approaches for so-called imbalanced
learning, a task that has received attention in the machine learning
community (e.g., Haixiang et al., 2017; He and Garcia, 2009), and
where Torrao et al. (2014) have already made some headway in crash
severity analysis.},
}

@article{YANG2020105707,
title = {Connected vehicle real-time traveler information messages for freeway speed harmonization under adverse weather conditions: Trajectory level analysis using driving simulator},
journal = {Accident Analysis \& Prevention},
volume = {146},
number = {nan},
pages = {105707},
year = {2020},
author = {Guangchuan Yang and Mohamed Ahmed and Sherif Gaweesh and Eric Adomah},
keywords = {Wyoming connected vehicle pilot, Adverse weather, Traveler information messages, Speed harmonization, Driving simulator experiment},
abstract = {This paper employed a high-fidelity driving simulator to investigate the impacts of the Wyoming Department of Transportation (WYDOT) Connected Vehicle (CV) Pilot’s Traveler Information Messages (TIMs) on drivers’ speed selection and the safety benefits of their speed harmonization. Three driving simulator experiment scenarios were developed to simulate the typical traffic and weather conditions on the rural Interstate 80 (I-80) in Wyoming. A total of 25 professional drivers from the WYDOT and trucking industry were recruited to participate in the driving simulator experiment. Participants’ instantaneous speeds at various locations were collected to reveal the effects of CV TIMs on their speed selection. The results showed that average speed profiles under CV scenarios were generally lower than under baseline scenarios, particularly for winter conditions (snowy and severe weather). The variance of speed under CV scenarios was found to be significantly lower than the baseline scenarios, indicating that CV TIMs have the potential to harmonize the variations in speed. In addition, for the work zone driving simulator experiment, this research revealed that the mean time-to-collision (TTC) under baseline scenario is approximately 40 \% lower than CV scenario, and the mean deceleration to avoid a crash (DRAC) under baseline scenario is approximately 19.3 \% higher than CV scenario. These findings suggest that CV TIMs can reduce the risk of crashes. Research findings would provide the WYDOT with early insights into the effectiveness of CV TIMs, which could assist with developing more efficient transportation management strategies under adverse weather conditions.},
institution = {U of Wyoming},
annotation = {Not our data, connected vehicles, driving simulator},
addendum = {},
}

@article{ROLAND2021105860,
title = {Modeling and predicting vehicle accident occurrence in Chattanooga, Tennessee},
journal = {Accident Analysis \& Prevention},
volume = {149},
number = {nan},
pages = {105860},
year = {2021},
author = {Jeremiah Roland and Peter D. Way and Connor Firat and Thanh-Nam Doan and Mina Sartipi},
keywords = {Machine learning, Traffic accident prediction, Neural networks},
abstract = {Given the ever present threat of vehicular accident occurrence endangering the lives of most people, preventative measures need to be taken to combat vehicle accident occurrence. From dangerous weather to hazardous roadway conditions, there are a high number of factors to consider when studying accident occurrence. To combat this issue, we propose a method using a multilayer perceptron model to predict where accident hotspots are for any given day in the city of Chattanooga, TN. This model analyzes accidents and their associated weather and roadway geometrics to understand the causes of accident occurrence. The model is offered as a live service to local law enforcement and emergency response services to better allocate resources and reduce response times for accident occurrence. Multiple models were made, each having different variables present, and each yielding varying results.},
institution = {U of Tennessee at Chattanooga},
annotation = {Straightforward.  Live app for local police.
\vskip 12pt
Created negative samples.
\vskip 0pt
Ran feature selection, but it selected some weather variables that correlate to the time of day, like humidity, uvIndex, temperature, dewPoint, pressure, and visibility, and excluded Rain/cloudy/foggy/show/clear, Rain in previous hour, and Precipitation intensity.
\vskip 12pt
Weird argument for having redundant variables.  
\vskip 0pt
``Regarding Test A yielding the most viable results, the inclusion of
potentially redundant variables (e.g., Lat/Long and Grid\_Num or Hour
and DayFrame) is not detrimental to the model’s usability, as those
potentially redundant variables use different scales. For example, latitude
and longitude use the standard GPS coordinate scale, while
Grid\_Num is an integer from 1 to 694. In other words, while some of the
variables may reflect similar information, they are presented in inherently
different ways.''

\vskip 12pt
I'm confused about how you can provide all available variables while applying feature selection.  Aren't those contradictory?

\vskip 0pt
``The best performing accident prediction
model resulted from changing the hour, date, and location values of an
accident entry when creating negative samples, having an even split of
negative to positive data, providing all available variables for analysis,
and applying feature selection, referred to as Total Shift 50–50 FS TA.''},
addendum = {
As the project proceeds, adjustments to the model and its input
features will continue to provide the optimal output. One such future
branch of this study includes further investigation into the creation of a
singular adverse weather variable, as presented by Hebert et al. (2019).
The current individual weather binaries presented within this study
could be complicating the models unnecessarily, although this is subject
to be determined by further testing. Additionally, demographic data as
presented in Dan et al. (2018), Yuan et al. (2017) could be accessed from
Geographical Information System (GIS) and incorporated into future
modelling, providing some of the missing human factors sought by this
team. Lastly, regarding the limitation of a lack of data, any future
implementations of this project in different cities/counties could
potentially benefit from additional roadway or driver specific data
should that city/county have access to said data.},
}

@article{GONCALVES2020105788,
title = {The effect of motor control requirements on drivers’ eye-gaze pattern during automated driving},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105788},
year = {2020},
author = {Rafael C. Goncalves and Tyron L. Louw and Manuela Quaresma and Ruth Madigan and Natasha Merat},
keywords = {Vehicle automation, Gaze patterns, Transition of control, Visual-motor coordination, Lane change},
abstract = {This driving simulator study compared drivers’ eye movements during a series of lane-changes, which required different levels of motor control for their execution. Participants completed 12 lane-changing manoeuvres in three drives, categorised by degree of manual engagement with the driving task: Fully Manual Drive, Manual Intervention Required, Fully Automated Drive (Manual drive, Partial automation, Full automation). For Partial automation, drivers resumed control from the automated system and changed lane manually. For Full automation, the automated system managed the lane change, but participants initiated the manoeuvre by pulling the indicator lever. Results were compared to the Manual drive condition, where drivers controlled the vehicle at all times. For each driving condition, lane changing was initiated by drivers, at their discretion, in response to a slow-moving lead vehicle, which entered their lane. Failure to change lane did not result in a collision. To understand how different motor control requirements affected driver visual attention, eye movements to the road centre, and drivers' vertical and horizontal gaze dispersion were compared during different stages of the lane change manoeuvre, for the three drives. Results showed that drivers' attention to the road centre was generally lower for drives with less motor control requirements, especially when they were not engaged in the lane change process. However, as drivers moved closer to the lead vehicle, and prepared to change lane, the pattern of eye movements to the road centre converged, regardless of whether drivers were responsible for the manual control of the lane change. While there were no significant differences in horizontal gaze dispersion between the three drives, vertical dispersion for the two levels of automation was quite different, with higher dispersion during Partial automation, which was due to a higher reliance on the HMI placed in the centre console.},
institution = {U of Leeds},
annotation = {Not our data},
addendum = {},
}

@article{ZHAO2021105937,
title = {A comparative study of state-of-the-art driving strategies for autonomous vehicles},
journal = {Accident Analysis \& Prevention},
volume = {150},
number = {nan},
pages = {105937},
year = {2021},
author = {Can Zhao and Li Li and Xin Pei and Zhiheng Li and Fei-Yue Wang and Xiangbin Wu},
keywords = {Autonomous vehicles, Driving strategy, Risk appetite, Interaction manner},
abstract = {The autonomous vehicle is regarded as a promising technology with the potential to reshape mobility and solve many traffic issues, such as accessibility, efficiency, convenience, and especially safety. Many previous studies on driving strategies mainly focused on the low-level detailed driving behaviors or specific traffic scenarios but lacked the high-level driving strategy studies. Though researchers showed increasing interest in driving strategies, there still has no comprehensive answer on how to proactively implement safe driving. After analyzing several representative driving strategies, we propose three characteristic dimensions that are important to measure driving strategies: preferred objective, risk appetite, and collaborative manner. According to these three characteristic dimensions, we categorize existing driving strategies of autonomous vehicles into four kinds: defensive driving strategies, competitive driving strategies, negotiated driving strategies, and cooperative driving strategies. This paper provides a timely comparative review of these four strategies and highlights the possible directions for improving the high-level driving strategy design.},
institution = {Tsinghua U},
annotation = {Not ML},
addendum = {We believe that future research should focus on the following valuable
directions:
1) Limited by the level of hardware and algorithm, there is still much
room for improvement in the accuracy and range of the current
perception system. Therefore, as the latter segment of perception, the
driving strategies of AVs need to be designed specifically based on
some limitations and assumptions of perception, and hence cannot
solve all problems in a generic way.
2) The current driving strategies are based on an indispensable
assumption of using identical technical equipment and the same
control strategy for all vehicles (Geiger et al., 2012). However, due to
the inconsistency of interpretation models and preferred objectives,
different AVs may have different understandings and responses to
the same scenarios. When they lack necessary communication or
communication channels are disturbed, their misunderstandings and
misjudgments will become a new trigger to danger. Therefore, how
to formulate a framework to ensure that AVs with different driving
strategies still can reach consensus is an urgent issue for future
researchers.
3) So far, research on risk appetite, the feature closely related to safety,
is still insufficient and deserves further advancement. Especially,
how should the risk appetite of different strategies be tested, evaluated,
and quantified. In consideration of the long-tail problem, how
to design simulation tests to reflect the risk appetite of the strategies
accurately (Li et al., 2016, 2018a; Li et al., 2019a,b).
4) Future research should focus more on communication and collaboration
between vehicles. For collaboration with other AVs, the unification
of communication rules and protocols should be accelerated,
to form a standardized and extensible inter-vehicle communication
mechanism.
5) For collaboration with human-driven vehicles, we should further
construct human driver models from the cognitive level rather than
the behaviors itself (Efrati, 2018; Stewart, 2018; Ma et al., 2010;
Schwarting et al., 2019; Li et al., 2018b; Michon, 1985). It can help
massively to develop a more reasonable collaborative driving strategy
and improve the probability of understanding each other
correctly when AVs interact with human-driven vehicles.
6) In the next step, researchers should pay more attention to TPACC and
explore the possibility of combining it with collaborative driving. It
is a meaningful work to accurately compare the individual benefits
and the overall benefits through theoretical calculations or simulation
tests.
7) The purpose of this paper is to draw attention of researchers towards
these important directions. We expect more exciting results will be
obtained soon.},
}

@article{ARVIN2021105949,
title = {Safety critical event prediction through unified analysis of driver and vehicle volatilities: Application of deep learning methods},
journal = {Accident Analysis \& Prevention},
volume = {151},
number = {nan},
pages = {105949},
year = {2021},
author = {Ramin Arvin and Asad J. Khattak and Hairong Qi},
keywords = {Deep Learning, CNN, LSTM, Volatility, SHRP2, Crash prediction, Naturalistic driving study, Neural Network, Big Data},
abstract = {Transportation safety is highly correlated with driving behavior, especially human error playing a key role in a large portion of crashes. Modern instrumentation and computational resources allow for the monitorization of driver, vehicle, and roadway/environment to extract leading indicators of crashes from multi-dimensional data streams. To quantify variations that are beyond normal in driver behavior and vehicle kinematics, the concept of volatility is applied. The study measures driver-vehicle volatilities using the naturalistic driving data. By integrating and fusing multiple real-time streams of data, i.e., driver distraction, vehicular movements and kinematics, and instability in driving, this study aims to predict occurrence of safety critical events and generate appropriate feedback to drivers and surrounding vehicles. The naturalistic driving data is used which contains 7566 normal driving events, and 1315 severe events (i.e., crash and near-crash), vehicle kinematics, and driver behavior collected from more than 3500 drivers. In order to capture the local dependency and volatility in time-series data 1D-Convolutional Neural Network (1D-CNN), Long Short-Term Memory (LSTM), and 1DCNN-LSTM are applied. Vehicle kinematics, driving volatility, and impaired driving (in terms of distraction) are used as the input parameters. The results reveal that the 1DCNN-LSTM model provides the best performance, with 95.45\% accuracy and prediction of 73.4\% of crashes with a precision of 95.67\%. Additional features are extracted with the CNN layers and temporal dependency between observations is addressed, which helps the network learn driving patterns and volatile behavior. The model can be used to monitor driving behavior in real-time and provide warnings and alerts to drivers in low-level automated vehicles, reducing their crash risk.},
institution = {U of Tennessee},
annotation = {Interesting.  Like our work, but with SHRP-2 data.},
addendum = {In future
research, other streams of data, including roadway condition, traffic
state, and information of the surrounding vehicles can be incorporated
to improve the model performance by providing additional information
regarding the surrounding environment.},
}

@article{ALI2021105973,
title = {Traffic accident detection and condition analysis based on social networking data},
journal = {Accident Analysis \& Prevention},
volume = {151},
number = {nan},
pages = {105973},
year = {2021},
author = {Farman Ali and Amjad Ali and Muhammad Imran and Rizwan Ali Naqvi and Muhammad Hameed Siddiqi and Kyung-Sup Kwak},
keywords = {Traffic accident detection, Traffic accident analysis, Traffic monitoring system, Ontology, Bi-LSTM},
abstract = {Accurate detection of traffic accidents as well as condition analysis are essential to effectively restoring traffic flow and reducing serious injuries and fatalities. This goal can be obtained using an advanced data classification model with a rich source of traffic information. Several systems based on sensors and social networking platforms have been presented recently to detect traffic events and monitor traffic conditions. However, sensor-based systems provide limited information, and may fail owing to the long detection times and high false-alarm rates. In addition, social networking data are unstructured, unpredictable, and contain idioms, jargon, and dynamic topics. The machine learning algorithms utilized for traffic event detection might not extract valuable information from social networking data. In this paper, a social network–based, real-time monitoring framework is proposed for traffic accident detection and condition analysis using ontology and latent Dirichlet allocation (OLDA) and bidirectional long short-term memory (Bi-LSTM). First, the query-based search engine effectively collects traffic information from social networks, and the data preprocessing module transforms it into structured form. Second, the proposed OLDA-based topic modeling method automatically labels each sentence (e.g., traffic or non-traffic) to identify the exact traffic information. In addition, the ontology-based event recognition approach detects traffic events from traffic-related data. Next, the sentiment analysis technique identifies the polarity of traffic events employing user’s opinions, which helps determine accurate conditions of traffic events. Finally, the FastText model and Bi-LSTM with softmax regression are trained for traffic event detection and condition analysis. The proposed framework is evaluated using traffic-related data, comparing OLDA and Bi-LSTM with existing topic modeling methods and traditional classifiers using word embedding models, respectively. Our system outperforms state-of-the-art methods and achieves accuracy of 97 \%. This finding demonstrates that the proposed system is more efficient for traffic event detection and condition analysis, in comparison to other existing systems.},
institution = {},
annotation = {},
addendum = {},
}

@article{KHATTAK2020105544,
title = {A Bayesian modeling framework for crash severity effects of active traffic management systems},
journal = {Accident Analysis \& Prevention},
volume = {145},
number = {nan},
pages = {105544},
year = {2020},
author = {Zulqarnain H. Khattak and Michael D. Fontaine},
keywords = {Active traffic management, Safety, Injury severity, Bayesian modeling, Variable speed limit, Lane control signals},
abstract = {Transportation agencies utilize Active traffic management (ATM) systems to dynamically manage recurrent and non-recurrent congestion based on real-time conditions. While these systems have been shown to have some safety benefits, their impact on injury severity outcomes is currently uncertain. This paper used full Bayesian mixed logit models to quantify the impact that ATM deployment had on crash severities. The estimation results revealed lower severities with ATM deployment. Marginal effects for ATM deployments that featured hard shoulder running (HSR) revealed lower likelihoods for severe and moderate injury crashes of 15.9 \% and for minor injury crashes of 10.1 \%. The likelihood of severe and moderate injury crashes and minor injury crashes reduced by 12.4 \% and 8.33 \% with ATM without HSR. The models were observed to be temporally transferable and had forecast error of 0.301 and 0.304 for the two models, revealing better performance with validation data. These results have implications for improving freeway crash risk at critical locations.},
institution = {Oak Ridge National Laboratory, Virginia Transportation Research Council},
annotation = {Not ML, but interesting for recommending a comparison between econometric models and ML algorithms.},
addendum = {There are several avenues for future research. The crash severity
results from this study can be compared with individual models representing
frequency of crashes and crash types. The insights about the
effects of ATM systems on crash severities can be enhanced with data
from additional deployments across different states. ATM systems are
unique and these deployments are rare across the country, with limited
high-quality data, which makes the current study one of the first to
analyze the severity impact of ATM systems. The current study will
serve as a base for future studies to draw a comparison against performance
of ATM systems as more data becomes available. {\bf Further, a
comparison between econometric models and machine learning algorithms
can be conducted and used to estimate models with high prediction
accuracy.} Finally, the ATMs impact on freeway crash severities
was examined in this research. However, future research could focus on
examining similar severity impacts on freeway interchange influence
areas. The speed of vehicles involved in a crash is an important factor
that could influence the crash severity. However, the only speed estimates
available are those provided on the police report, which are either
estimated by the drivers involved or the responding officer after
the crash. Given the potential inaccuracies in this data, speed estimates
were not used. Future studies could collect these real-time at-fault
speeds (Khattak et al., 2018a) using connected vehicle data, which
could provide useful insights into the impact of this variable on crash
severity prior to involvement in a crash event.},
}

@article{SONG2021106038,
title = {The mediating effect of driver characteristics on risky driving behaviors moderated by gender, and the classification model of driver’s driving risk},
journal = {Accident Analysis \& Prevention},
volume = {153},
number = {nan},
pages = {106038},
year = {2021},
author = {Xiaolin Song and Yangang Yin and Haotian Cao and Song Zhao and Mingjun Li and Binlin Yi},
keywords = {Driver driving risk, Sensation seeking, Risk perception, Risky driving behaviors, Structural equation model, SHRP 2},
abstract = {High-risk drivers are more likely to be involved in traffic accidents, and the driving risk level of drivers could be affected by many potential factors, such as demographics and personality traits. Based on the Structural Equation Model (SEM), this study involves a sample of 3150 drivers from the Strategic Highway Research Program 2 (SHRP 2), to explore the relationships among drivers’ demographic characteristics (gender, age, and cumulative driving years), sensation seeking, risk perception, and risky driving behaviors. More specifically, the mediation model of driver characteristics on risky driving behaviors moderated by gender is constructed by the SEM. The results show that the effects of driving experience on risky driving behaviors are partially mediated by sensation seeking and risk perception for male drivers, while those are completely mediated by sensation seeking and risk perception for female drivers. Moreover, the development trend of risky driving behavior engagements declines greater with the growing of driving experience for female drivers than male drivers. Finally, a classification model of the driver’s driving risk is proposed by the Random Forest classifier, in which the driving risk level of the driver evaluated by the crash and near-crash rate could be classified through the driver’s self-reported demographics, sensation seeking, risk perception, and risky driving behaviors. The classification accuracy achieves up to 90 percent, which offers an alternative approach to identifying potential high-risk drivers to reduce property losses, injuries, and death caused by traffic accidents.},
institution = {Hunan U, U of Waterloo},
annotation = {Risky driving behaviors correlated with gender, age, and cumulative driving years.  },
addendum = {},
}

@article{ZHANG2020105844,
title = {Modeling pedestrians’ near-accident events at signalized intersections using gated recurrent unit (GRU)},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105844},
year = {2020},
author = {Shile Zhang and Mohamed Abdel-Aty and Yina Wu and Ou Zheng},
keywords = {Pedestrian safety, Surrogate safety measures (SSMs), Extreme value theory (EVT), Gated recurrent unit (GRU)},
abstract = {Pedestrian safety plays an important role in the transportation system. Intersections are dangerous locations for pedestrians with mixed traffic. This paper aims to predict the near-accident events between pedestrians and vehicles at signalized intersections using PET (Post Encroachment Time) and TTC (Time to Collision). With automated computer vision techniques, mobility features of pedestrians and vehicles are generated. Extreme Value Theory (EVT) is used to model PET and minimum TTC values to select the most appropriate threshold values to label pedestrians’ near-accident events. A Gated Recurrent Unit (GRU) neural network is further used to predict these events. The established model reaches an AUC (Area Under the Curve) value of 0.865 on the test data set. Moreover, the proposed model can also be applied to develop collision warning systems under the Connected Vehicle environment.},
institution = {U of Central Florida},
annotation = {Gated Recurrent Unit (GRU) is like Long Short-term Memory (LSTM), but a little simpler.  
\vskip 0pt
Used video data of pedestrians at intersections to find near-accident events.  
\vskip 0pt
Not our data.  },
addendum = {},
}

@article{KATANALP2020105590,
title = {The novel approaches to classify cyclist accident injury-severity: Hybrid fuzzy decision mechanisms},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105590},
year = {2020},
author = {Burak Yiğit Katanalp and Ezgi Eren},
keywords = {Fuzzy logic, Decision tree, Injury-severity, Machine learning, Cyclist safety},
abstract = {In this study, two novel fuzzy decision approaches, where the fuzzy logic (FL) model was revised with the C4.5 decision tree (DT) algorithm, were applied to the classification of cyclist injury-severity in bicycle-vehicle accidents. The study aims to evaluate two main research topics. The first one is investigation of the effect of road infrastructure, road geometry, street, accident, atmospheric and cyclist related parameters on the classification of cyclist injury-severity similarly to other studies in the literature. The second one is examination of the performance of the new fuzzy decision approaches described in detail in this study for the classification of cyclist injury-severity. For this purpose, the data set containing bicycle-vehicle accidents in 2013–2017 was analyzed with the classic C4.5 algorithm and two different hybrid fuzzy decision mechanisms, namely DT-based converted FL (DT-CFL) and novel DT-based revised FL (DT-RFL). The model performances were compared according to their accuracy, precision, recall, and F-measure values. The results indicated that the parameters that have the greatest effect on the injury-severity in bicycle-vehicle accidents are gender, vehicle damage-extent, road-type as well as the highly effective parameters such as pavement type, accident type, and vehicle-movement. The most successful classification performance among the three models was achieved by the DT-RFL model with 72.0 \% F-measure and 69.96 \% Accuracy. With 59.22 \% accuracy and \%57.5 F-measure values, the DT-CFL model, rules of which were created according to the splitting criteria of C4.5 algorithm, gave worse results in the classification of the injury-severity in bicycle-vehicle accidents than the classical C4.5 algorithm. In light of these results, the use of fuzzy decision mechanism models presented in this study on more comprehensive datasets is recommended for further studies.},
institution = {Adana Alparslan Turkes Science and Technology U},
annotation = {Bicycles and fuzzy logic.},
addendum = {},
}

@article{DUNN2021106152,
title = {Investigating the impact of driving automation systems on distracted driving behaviors},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106152},
year = {2021},
author = {Naomi J. Dunn and Thomas A. Dingus and Susan Soccolich and William J. Horrey},
keywords = {Driving automation systems, Distracted driving, Naturalistic driving, Driver behavior},
abstract = {Driving automation systems (e.g., SAE Level 2) ultimately aim to enhance the comfort and safety of drivers. At present, these systems are able to control some portions of the driving task (e.g., braking, steering) for extended time periods, giving drivers the opportunity to disengage from the responsibilities associated with driving. In this study, data derived from two naturalistic driving studies involving automation-equipped vehicles were analyzed to evaluate driver behaviors with respect to driving automation system use, specifically distraction-related factors (i.e., secondary task engagement, eye-glance behavior, and drowsiness). The results indicate that when drivers had prior experience using driving automation systems, they were almost two times as likely to participate in distracted driving behaviors when the systems were active than during manual driving. Drivers with less experience and familiarity with driving automation systems were less likely to drive distracted when the systems were active; however, these drivers tended to be somewhat drowsy when driving with systems activated. The results provide important insights into different operational phases of driving automation system use (i.e., learning/unfamiliar vs experienced users), whereby experience results in overtrust and overreliance on the advanced technologies, which subsequently may negate some of the safety benefits of these systems. Thus, while the safety benefits of driving automation systems are evident, it is imperative to better understand the impact these advanced technologies may have on driver behavior and performance in order to evaluate and address any unintended consequences associated with system use.},
institution = {Virginia Tech},
annotation = {Not our data.  When do drivers engage their automated driving systems?},
addendum = {While this study presents a relatively large-scale study of naturalistic
driving data relative to driving automation use in comparison with other
such studies, the sample size is not indicative of the U.S. population.
Future studies should consider increasing the sample size. It should also
be noted that driving automation system use was dependent upon the
driver, not on an experimenter or other external prompt; thus, system
use may have been dependent upon individual driver factors.
Drivers in the VCC NDS had an app on their smart phone that provided
safety-related driving information, such as weather, traffic, and
driving conditions. The data reduction process did not (and could not)
distinguish between study-related app use and personal phone use.
Thus, the eye glance analyses focused on eyes-off-road glances rather
than non-driving-related task glances.
While NDSs allow the objective observation of driver performance
and behavior, the nature of such studies precludes the use of intrusive
instrumentation. As such, cognitive distraction could only be inferred
from the study data and not directly measured. Refining the process of
machine learning would be beneficial for future studies. For example,
dash layout and automation icon appearance and location are vital to
the machine-learning process; thus, vehicles with status icons that are
not easy to distinguish were excluded from the current study. Finally,
NDSs are dependent upon volunteer drivers. As such, a self-selection
bias may exist.},
}

@article{SARKAR2021106055,
title = {Steering or braking avoidance response in SHRP2 rear-end crashes and near-crashes: A decision tree approach},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106055},
year = {2021},
author = {Abhijit Sarkar and Jeffrey S. Hickman and Anthony D. McDonald and Wenyan Huang and Tobias Vogelpohl and Gustav Markkula},
keywords = {Avoidance response, Gaze eccentricity, SHRP 2 naturalistic driving, Random forest, Driver maneuver, Rear-end events},
abstract = {Objective
The paper presents a systematic analysis of drivers’ crash avoidance response during crashes and near-crashes and developed a machine learning-based predictive model that can determine driver maneuver using pre-incident driver behavior and driving context.
Methods
We analyzed 286 naturalistic rear-end crashes and near-crashes from the SHRP2 naturalistic driving study. All the events were manually reduced using face video (face and forward) and kinematic responses. In this paper, we developed new reduction variables that enhanced the understanding of drivers’ gaze behavior and roadway attention behavior during these events. These features reflected how the event criticality, measured using time to collision, related to drivers’ pre-incident behavior (secondary behavior, gaze behavior), and drivers’ perception of the event (physical reaction and maneuver). The imperative understanding of such relations was validated using a random forest- (RF) based classifier, which efficiently predicted if a driver was going to brake or change the lane as an avoidance maneuver.
Results
The RF presented in this paper effectively explored the nonlinear patterns in the data and was highly accurate (∼96 \%) in its prediction. A further analysis of the RF model showed that six features played a pivotal role in the decision logic. These included the drivers’ last glance duration before the event, last glance eccentricity, duration of ‘eyes on road’ immediately before the event, the time instance and criticality when the driver perceives the threat as well as acknowledge the threat, and possibility of an escape path in the adjacent lane. Using partial dependency plots, we also showed how different thresholds of these feature variables determined the drivers’ maneuver intention.
Conclusions
In this paper we analyzed driving context, drivers’ behavior, event criticality, and drivers’ response in a unified structure to predict their avoidance response. To the best of our knowledge, this is the first such effort where large-scale naturalistic data (crashes and near crashes) was analyzed for prediction of drivers’ maneuver and determined key behavioral and contextual factors that contribute to this avoidance maneuver.},
institution = {Virginia Tech, Texas A\&M, Technische Universit¨at Braunschweig, U of Leeds},
annotation = {Not our data.  Video data.  },
addendum = {},
}

@article{SOHRABI2021106003,
title = {Quantifying the automated vehicle safety performance: A scoping review of the literature, evaluation of methods, and directions for future research},
journal = {Accident Analysis \& Prevention},
volume = {152},
number = {nan},
pages = {106003},
year = {2021},
author = {Soheil Sohrabi and Ali Khodadadi and Seyedeh Maryam Mousavi and Bahar Dadashova and Dominique Lord},
keywords = {Automated vehicle, Safety evaluation, Safety implications, Driving simulator, Traffic simulation, Road test data, Target crash population, Safety effectiveness, Failure risk, Evaluation metric},
abstract = {Vehicle automation safety must be evaluated not only for market success but also for more informed decision-making about Automated Vehicles' (AVs) deployment and supporting policies and regulations to govern AVs’ unintended consequences. This study is designed to identify the AV safety quantification studies, evaluate the quantification approaches used in the literature, and uncover the gaps and challenges in AV safety evaluation. We employed a scoping review methodology to identify the approaches used in the literature to quantify AV safety. After screening and reviewing the literature, six approaches were identified: target crash population, traffic simulation, driving simulator, road test data analysis, system failure risk assessment, and safety effectiveness estimation. We ran two evaluations on the identified approaches. First, we investigated each approach in terms of its input (required data, assumptions, etc.), output (safety evaluation metrics), and application (to estimate AVs' safety implications at the vehicle, transportation system, and society levels). Second, we qualitatively compared them in terms of three criteria: availability of input data, suitability for evaluating different automation levels, and reliability of estimations. This review identifies four challenges in AV safety evaluation: (a) shortcomings in AV safety evaluation approaches, (b) uncertainties in AV implementations and their impacts on AV safety, (c) potential riskier behavior of AV passengers as well as other road users, and (d) emerging safety issues related to AV implementations. This review is expected to help researchers and rulemakers to choose the most appropriate quantification method based on their goals and study limitations. Future research is required to address the identified challenges in AV safety evaluation.},
institution = {Texas A\&M},
annotation = {Not our data, not ML},
addendum = {},
}

@article{PRAMANIK2021106019,
title = {A real-time video surveillance system for traffic pre-events detection},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106019},
year = {2021},
author = {Anima Pramanik and Sobhan Sarkar and J. Maiti},
keywords = {Pre-event analysis, Anomaly detection, Video surveillance system, Road safety, CamSeq01, ISLab-PVD},
abstract = {In this study, a conceptual framework is proposed for the development of a video surveillance-based system for improving road safety. Based on the framework, a set of algorithms are developed which are capable of detecting various traffic pre-events from traffic videos, such as speed violation, one-way traffic, overtaking, illegal parking, and wrong drop-off location of passengers. After detecting the pre-events, an alarm will be automatically generated in the control room which helps to take precautionary measures to avoid any potential mishap on road, thereby, improving the road safety. In previous studies, a single system can handle either one or two pre-events. Whereas, in our present study, five anomalies can be detected in a single system using five different algorithms. Our study further contributes to the detection of “wrong drop-off location of passengers”. The effectiveness of the developed algorithms is demonstrated over 132 traffic videos acquired from an integrated plant in India. Some additional comparative studies for overtaking and illegal parking are done using two benchmark datasets, namely ‘CamSeq01’ and ‘ISLab-PVD’. Through an extensive study, it can be concluded that our developed algorithms are superior to some state-of-the-art algorithms in the detection of pre-events on road.},
institution = {Indian Institute of Technology Kharagpur, University of Edinburgh},
annotation = {Video detection of pre-events, especially wrong drop-off location of passengers.  Used ML to analyze videos.},
addendum = {As a future scope, a framework can be
developed which can address both monocular and stereo vision in traffic
pre-event detection.},
}

@article{KIDANDO2021105869,
title = {Prediction of vehicle occupants injury at signalized intersections using real-time traffic and signal data},
journal = {Accident Analysis \& Prevention},
volume = {149},
number = {nan},
pages = {105869},
year = {2021},
author = {Emmanuel Kidando and Angela E. Kitali and Boniphace Kutela and Mahyar Ghorbanzadeh and Alican Karaer and Mohammadreza Koloushani and Ren Moses and Eren E. Ozguven and Thobias Sando},
keywords = {Vehicle occupant injury, Real-time data, High-resolution, Event-based data, Random Forest, XGBoost classifiers},
abstract = {Intersections are among the most dangerous roadway facilities due to the existence of complex movements of traffic. Most of the previous intersection safety studies are conducted based on static and highly aggregated data such as average daily traffic and crash frequency. The aggregated data may result in unreliable findings because they are based on averages and might not necessarily represent the actual conditions at the time of the crash. This study uses real-time event-based detection records, and crash data to develop predictive models for the vehicle occupants' injury severity. The three-year (2017–2019) data were acquired from the arterial highways in the City of Tallahassee, Florida. Random Forest (RF) and eXtreme Gradient Boosting (XGBoost) classifiers were used to identify the important factors on the vehicle occupants' injury severity prediction. The performance comparison of the two classifiers revealed that the XGBoost has a higher balanced accuracy score than RF. Using the XGBoost classifier, five topmost influential factors on injury prediction were identified. The factors are the manner of the collision, through and right-turn traffic volume, arrival on red for through and right-turn traffic, split failure for through traffic, and delays for through and right-turn traffic. Moreover, the partial dependency plots of the influential variables are presented to reveal their impact on vehicle occupant injury prediction. The knowledge gained from this study will be useful in developing effective proactive countermeasures to mitigate intersection-related crash injuries in real-time.},
institution = {Mercer U, Florida International U, Texas A\&M, Florida State U, U of North Florida},
annotation = {Interesting.  Really poor sensitivity:  46\% for XGBoost and half that for Random Forest.  },
addendum = {It is important to note that though this study substantiated the influence
of real-time data on the severity of occupants involved in
signalized intersection crashes, there are some limitations. It is well
established that the approaching speed of vehicles involved in a crash
plays a significant role in the outcome of the occupant injury. However,
it was not possible to derive this parameter from the detector data. Thus,
future research can investigate the role of approaching real-time speed
together with other risk factors on the occupant injury. It will be an
opportunity for future work to investigate the impact of time intervals
such as 2, 5, and 15 min in the real-time safety analysis. Also, the current
study investigated the influence of a downstream traffic signal only on
the occupant injury. The analysis did not consider the effects of the
upstream intersection. Further study can incorporate the nearby upstream
intersection as well in the analysis.
Several classification metrics are known to address the issue of
imbalanced data. The current study only adopted the balanced accuracy
metric. It will be an opportunity for future work to evaluate other
metrics such as F-score, class-weighted evaluation metrics in the analysis
of an imbalanced dataset.
It merits referencing that the underreporting of crashes, particularly
for least severe crashes is one of the attributes that may bias the results of
models developed using historical crash data. Future work may consider
variables that relate to vehicle occupants including seating position and
occupant status. Besides, pedestrian compliance particularly at signalized
intersections is normally impacted by the prevailing traffic and
signal characteristics. Thus, it will be an opportunity for future research
to investigate factors affecting pedestrian compliance at signalized intersections
based on high-resolution event-based data.},
}

@article{DU2020105748,
title = {Predicting driver takeover performance in conditionally automated driving},
journal = {Accident Analysis \& Prevention},
volume = {148},
number = {nan},
pages = {105748},
year = {2020},
author = {Na Du and Feng Zhou and Elizabeth M. Pulver and Dawn M. Tilbury and Lionel P. Robert and Anuj K. Pradhan and X. Jessie Yang},
keywords = {Transition of control, Predictive modeling, Human–automation interaction, Human–autonomy interaction, Human–robot interaction},
abstract = {In conditionally automated driving, drivers have difficulty taking over control when requested. To address this challenge, we aimed to predict drivers’ takeover performance before the issue of a takeover request (TOR) by analyzing drivers’ physiological data and external environment data. We used data sets from two human-in-the-loop experiments, wherein drivers engaged in non-driving-related tasks (NDRTs) were requested to take over control from automated driving in various situations. Drivers’ physiological data included heart rate indices, galvanic skin response indices, and eye-tracking metrics. Driving environment data included scenario type, traffic density, and TOR lead time. Drivers’ takeover performance was categorized as good or bad according to their driving behaviors during the transition period and was treated as the ground truth. Using six machine learning methods, we found that the random forest classifier performed the best and was able to predict drivers’ takeover performance when they were engaged in NDRTs with different levels of cognitive load. We recommended 3 s as the optimal time window to predict takeover performance using the random forest classifier, with an accuracy of 84.3\% and an F1-score of 64.0\%. Our findings have implications for the algorithm development of driver state detection and the design of adaptive in-vehicle alert systems in conditionally automated driving.},
institution = {U of Michigan, U of Massachusetts Amherst},
annotation = {Not our data.  },
addendum = {},
}

@article{KONG2020105620,
title = {Understanding speeding behavior from naturalistic driving data: Applying classification based association rule mining},
journal = {Accident Analysis \& Prevention},
volume = {144},
number = {nan},
pages = {105620},
year = {2020},
author = {Xiaoqiang Kong and Subasish Das and Kartikeya Jha and Yunlong Zhang},
keywords = {Trip features, Driving characteristics, Geometric features, Speeding duration, Speeding pattern, Association rules},
abstract = {Speeding is considered as one of the most significant contributing factors to severe traffic crashes. Understanding the associations between trip/driving/roadways features and speeding behavior is crucial for both researchers and practitioners. This research utilized naturalistic driving data collected by the Safety Pilot Model Deployment (SPMD) program and roadway features from a road inventory dataset - Highway Performance Monitoring System (HPMS), provided by the United States Department of Transportation (USDOT), to investigate the hidden rules that associated trip/driving/roadway features with speeding behavior. A classification-based association (CBA) algorithm was adopted to explore the hidden rules from two perspectives of speeding: speeding duration and speeding pattern. Results indicate that the combinations of longer trips (more than 60 min), driving on the roadways with a relatively higher functional class are highly associated with longer speeding events (speeding longer than 2 min). The moderate speeding events (speeding longer than 2 min and longer than 30 s) are found highly associated with the combination of driving on roadways with lower functional class, absence of a median and relatively short trip time (less than 30 min). The research also found the combinations of driving on roadways with relatively lower functional class, experienced congestion before a speeding event, and the presence of a median is a leading cause that triggers a higher speeding pattern (speeding more than 5mph above the speed limit). Furthermore, the moderate speeding pattern (speeding more than 1mph above the speed limit and less than 5mph of the speed limit) is associated with the combinations of factors like experiencing congestion before a speed event, driving on roadways with higher functional class and a relatively shorter trip (less than 30 min). The findings can help practitioners understand the composite effect of these factors more comprehensively and provide corresponding countermeasures to mitigate the negative consequences of speeding wherever possible. These can also help in calibrating driver behavior parameters for transportation-related simulation tools.},
institution = {},
annotation = {},
addendum = {},
}

@article{MA2021106096,
title = {Driving style recognition and comparisons among driving tasks based on driver behavior in the online car-hailing industry},
journal = {Accident Analysis \& Prevention},
volume = {154},
number = {nan},
pages = {106096},
year = {2021},
author = {Yongfeng Ma and Wenlu Li and Kun Tang and Ziyu Zhang and Shuyan Chen},
keywords = {Driver behavior, Driving style, Driving maneuver detection, Driving tasks, -means clustering, Principal component analysis (PCA)},
abstract = {As a product of the shared economy, online car-hailing platforms can be used effectively to help maximize resources and alleviate traffic congestion. The driver’s behavior is characterized by his or her driving style and plays an important role in traffic safety. This paper proposes a novel framework to classify driving styles (defined as aggressive, normal, and cautious) based on online car-hailing data to investigate the distinct characteristics of drivers when performing various driving tasks (defined as cruising, ride requests, and drop-off) and undergoing certain maneuvers (defined as turning, acceleration, and deceleration). The proposed model is constructed based on the detection and classification of driving maneuvers using a threshold-based endpoint detection approach, principal component analysis, and k-means clustering. The driving styles that the driver exhibits for the different driving tasks are compared and analyzed based on the classified maneuvers. The empirical results for Nanjing, China demonstrate that the proposed framework can detect driving maneuvers and classify driving styles accurately. Moreover, according to this framework, driving tasks lead to variations in driving style, and the variations in driving style during the different driving tasks differ significantly for turning, acceleration, and deceleration maneuvers.},
institution = {Southeast U (Nanjing), Nanjing U of Science and Technology},
annotation = {Not our data.},
addendum = {},
}

@article{LIN2020105696,
title = {Real-time traffic accidents post-impact prediction: Based on crowdsourcing data},
journal = {Accident Analysis \& Prevention},
volume = {145},
number = {nan},
pages = {105696},
year = {2020},
author = {Yunduan Lin and Ruimin Li},
keywords = {Crowdsourcing data, Traffic accidents post-impact, Machine learning, Sequential prediction},
abstract = {Traffic accident management is a critical issue for advanced intelligent traffic management. The increasingly abundant crowdsourcing data and floating car data provide new support for improving traffic accident management. This paper investigates the methods to predict the complicated behavior of traffic flow evolution after traffic accidents using crowdsourcing data. Based on the available data source, the traffic condition is divided into four levels by congestion delay index: severely congested, congested, slow moving and uncongested. Four types of accidents are consequently defined based on the occurrence of each level. A hierarchical scheme is designed for identifying the most congested level and sequentially predicting duration of each level. The proposed model is validated using traffic accident data in 2017 from an anonymous source in Beijing, China by embedding three machine learning algorithms, random forest (RF), support vector machine (SVM) and neural network (NN), in the scheme. The results show NN outperforms the other two models when the assessment is conducted in absolute differences. Meanwhile, RF has a slightly better performance than SVM, especially when predicting the short-period congestion of severely congested level at the first time. By continuously updating the traffic condition information, significant improvement in accuracy can be acquired regardless of the exact model used. This study shows that emerging crowdsourcing data can be used in a real-time analysis of traffic accidents and the proposed model is effective to analyze such data.},
institution = {Tsinghua U, U of California Berkeley},
annotation = {Not our data.},
addendum = {},
}

@article{DAS2020105578,
title = {Detecting lane change maneuvers using SHRP2 naturalistic driving data: A comparative study machine learning techniques},
journal = {Accident Analysis \& Prevention},
volume = {142},
number = {nan},
pages = {105578},
year = {2020},
author = {Anik Das and Md Nasim Khan and Mohamed M. Ahmed},
keywords = {Lane change detection, Naturalistic driving study, Random Forest, Support vector machine, Artificial neural network, eXtrem gradient boosting, Connected vehicle},
abstract = {Lane change has been recognized as a challenging driving maneuver and a significant component of traffic safety research. Developing a real-time continuous lane change detection system can assist drivers to perform and deal with complex driving tasks or provide assistance when it is needed the most. This study proposed trajectory-level lane change detection models based on features from vehicle kinematics, machine vision, roadway characteristics, and driver demographics under different weather conditions. To develop the models, the SHRP2 Naturalistic Driving Study (NDS) and Roadway Information Database (RID) datasets were utilized. Initially, descriptive statistics were utilized to investigate the lane change behavior, which revealed significant differences among different weather conditions for most of the parameters. Six data fusion categories were introduced for the first time, considering different data availability. In order to select relevant features in each category, Boruta, a wrapper-based algorithm was employed. The lane change detection models were trained, validated, and comparatively evaluated using four Machine Learning algorithms including Random Forest (RF), Support Vector Machine (SVM), Artificial Neural Network (ANN), and eXtrem Gradient Boosting (XGBoost). The results revealed that the highest overall detection accuracy was found to be 95.9 \% using the XGBoost model when all the features were included in the model. Moreover, the highest overall detection accuracy of 81.9 \% using the RF model was achieved considering only vehicle kinematics-based features, indicating that the proposed model could be utilized when other data are not available. Furthermore, the analysis of the impact of weather conditions on lane change detection suggested that incorporating weather could improve the accuracy of lane change detection. In addition, the analysis of early lane change detection indicated that the proposed algorithm could predict the lane changes within 5 s before the vehicles cross the lane line. The developed detection models could be used to monitor and control driver behavior in a Cooperative Automated Vehicle environment.},
institution = {U of Wyoming},
annotation = {Interesting.  Basic homework assignment.},
addendum = {While the study exhibited the capability of Machine Learning algorithms
to detect lane change maneuvers from the SHRP2 NDS and
RID datasets, some limitations should be mentioned. The first limitation
is related to the data segmentation approach. The study considered a
dynamic segmentation approach to select non-lane change segments.
This approach is appropriate and necessary when machine vision-based
features (e.g., lane position offset in this study) are included in the
dataset. Therefore, the study recommends to use fixed time window
approach in the absence of machine vision data in the future. The
second limitation is related to the steering wheel angle variable, which
was not considered for detecting lane change behavior due to excessive
missing values in most of the trips. In addition, data from all surrounding
vehicles were not available as front-mounted radar of NDS
vehicle cannot detect the presence of vehicles behind the NDS vehicle’s
lane. Consequently, the lane change was considered as a single behavior
of the subject vehicle. Future studies can focus on incorporating data
from all surrounding vehicles as the input of the detection algorithm
using similar trajectory-level data with information from all surrounding
vehicles. Moreover, the study is only limited to trips on
freeways. Lane change detection models using the SHRP2 NDS data on
urban roadways could be considered in future studies.
Furthermore, the continuation of this study is important to include
other driver behavioral features in addition to driver demographics in
the developed detection algorithm. To be specific, drivers’ aggressiveness
could be considered in future studies. The lane change events
database developed in this study contained a number of features that
could be used to classify drivers’ aggressiveness. Features associated
with driving behavior, such as speed, acceleration, yaw rate, speed
differences from speed limit, number of lane changes per mile, etc.
could be obtained, and then cluster analysis could be adopted with
possible features to classify drivers as aggressive or conservative. Once
all drivers are classified, they could be introduced as conservative or
aggressive in the current model. Finally, the expansion of this study
would be to include other relevant features and develop more advanced
lane change detection models using Artificial Intelligence and Deep
Learning for specific lane change types and extend the work to predict
lane changes.},
}

@article{JHA2021106164,
title = {A performance analysis of prediction techniques for impacting vehicles in hit-and-run road accidents},
journal = {Accident Analysis \& Prevention},
volume = {157},
number = {nan},
pages = {106164},
year = {2021},
author = {Alok Nikhil Jha and Niladri Chatterjee and Geetam Tiwari},
keywords = {Hit-and-run, Road accident, Vehicle type prediction, Support vector machine, Linear discriminant analysis, Naïve Bayes, Classification and regression tree, k-Nearest neighbor, Cross validation, Road user safety},
abstract = {Road accidents are globally accepted challenges. They are one of the significant causes of deaths and injuries besides other direct and indirect losses. Countries and international organizations have designed technologies, systems, and policies to prevent accidents. However, hit-and-run accidents remain one of the most dangerous types of road accidents as the information about the vehicle responsible for the accident remain unknown. Therefore, any mechanism which can provide information about the impacting vehicle in hit-and-run accidents will be useful in planning and executing preventive measures to address this road menace. Since there exist several models to predict the impacting unknown vehicle, it becomes important to find which is the most accurate amongst those available. This research applies a process-based approach that identifies the most accurate model out of six supervised learning classification models viz. Logistic Reasoning, Linear Discriminant Analysis, Naïve Bayes, Classification and Regression Trees, k-Nearest Neighbor and Support Vector Machine. These models are implemented using five-fold and ten-fold cross validation, on road accident data collected from five mid-sized Indian cities: Agra, Amritsar, Bhopal, Ludhiana, and Vizag (Vishakhapatnam).This study investigates the possible input factors that may have effect on the performance of applied models. Based on the results of the experiment conducted in this study, Support Vector Machine has been found to have the maximum potentiality to predict unknown impacting vehicle type in hit-and-run accidents for all the cities except Amritsar. The result indicates that, Classification and Regression Trees have maximum accuracy, for Amritsar. Naïve Bayes performed very poorly for the five cities. These recommendations will help in predicting unknown impacting vehicles in hit-and-run accidents. The outcome is useful for transportation authorities and policymakers to implement effective road safety measures for the safety of road users.},
institution = {Indian Institute of Technology},
annotation = {Nothing new.  We did a thing.},
addendum = {The work can be extended by applying other
classification and regression models, such as self-organizing maps,
random forest, neural networks, clustering techniques, rough sets and
deep learning techniques.},
}

@article{QUDDUS2021106107,
title = {Using long short term memory and convolutional neural networks for driver drowsiness detection},
journal = {Accident Analysis \& Prevention},
volume = {156},
number = {nan},
pages = {106107},
year = {2021},
author = {Azhar Quddus and Ali {Shahidi Zandi} and Laura Prest and Felix J.E. Comeau},
keywords = {Driver drowsiness, Fatigue, Long short term memory, LSTM, Convolutional LSTM, Eye detection, Electroencephalogram (EEG), Non-invasive, Random forest (RF), Support vector machine (SVM)},
abstract = {Fatigue negatively affects the safety and performance of drivers on the road. In fact, drowsiness and fatigue are the cause of a substantial number of motor vehicle accidents. Drowsiness among the drivers can be detected using variety of modalities, including electroencephalogram (EEG), eye movement, and vehicle driving dynamics. Among these EEG is highly accurate but very intrusive and cumbersome. On the other hand, vehicle driving dynamics are very easy to acquire but accuracy is not very high. Eye movement based approach is very attractive in terms of balance between these two extremes. However, eye movement based techniques normally require an eye tracking device which consists of high speed camera with sophisticated algorithm to extract eye movement related parameters such as blinking, eye closure, saccades, fixation etc. This makes eye tracking based drowsiness detection difficult to implement as a practical system, especially on an embedded platform. In this paper, authors propose to use eye images from camera directly without the need for expensive eye-tracking system. Here, eye related movements are captured by Recurrent Neural Network (RNN) to detect the drowsiness. Long Short Term Memory (LSTM) is a class of RNN which has several advantages over vanilla RNNs. In this work an array of LSTM cells are utilized to model the eye movements. Two types of LSTMs were employed: 1-D LSTM (R-LSTM) which is used as baseline and the convolutional LSTM (C-LSTM) which facilitates using 2-D images directly. Patches of size 48 × 48 around each eye were extracted from 38 subjects, participating in a simulated driving experiment. The state of vigilance among the subjects were independently assessed by power spectral analysis of multichannel electroencephalogram (EEG) signals, recorded simultaneously, and binary labels of alert and drowsy (baseline) were generated. Results show high efficacy of the proposed system. R-LSTM based approach resulted in accuracy around 82 \% and C-LSTM based approach resulted in accuracy in the range of 95\%–97\%. Comparison is also provided with a recently published eye-tracking based approach, showing the proposed LSTM technique outperform with a wide margin.},
institution = {},
annotation = {},
addendum = {},
}

@article{FARID201985,
title = {Comparative analysis of multiple techniques for developing and transferring safety performance functions},
journal = {Accident Analysis \& Prevention},
volume = {122},
number = {nan},
pages = {85-98},
year = {2019},
author = {Ahmed Farid and Mohamed Abdel-Aty and Jaeyoung Lee},
keywords = {Safety performance functions, Transferability, Negative binomial model, Tobit model, Data mining methods, Highway safety manual},
abstract = {Safety performance functions (SPFs) are crash count prediction models that are used for identifying high crash risk locations, evaluating road safety before and after countermeasure deployment and comparing the safety of alternative site designs. The traditional method of modeling crash counts is negative binomial (NB) regression. Furthermore, the Highway Safety Manual (HSM) provides analytical tools, including NB SPFs, to assess and improve road safety. Even though the HSM’s SPFs are restricted to NB models, the road safety literature is rich with a variety of different modeling techniques. Researchers have calibrated the HSM’s SPFs to local conditions using a calibration method prescribed by the HSM. However, studies in which SPFs are developed and transferred to other localities are uncommon. In this paper, we develop and transfer rural divided multilane highway segment SPFs of Florida, Ohio, Illinois, Minnesota, California, Washington and North Carolina to each state. For every state, NB, zero-inflated NB, Poisson lognormal (PLN), regression tree, random forest (RF), boosting and Tobit models are developed. A hybrid model that coalesces the predictions of both the Tobit and the NB model is proposed and developed as well. All SPFs are transferred to each state and their predictive performances are evaluated to discern which model type is the most transferable. According to the transferability results, there is no single superior model type. However, the Tobit, RF, tree, NB and hybrid models demonstrate better predictive performances than those of the other methods in a considerably large proportion of transferred SPFs.},
institution = {U of Central Florida},
annotation = {Interesting.  Comparison of different models (ML and statistical) on different datasets from different states.},
addendum = {Undoubtedly, this paper’s research is not without limitations. All
SPFs, developed and transferred, suffer from omitted variable bias
(Lord and Mannering, 2010) which results in errors associated with the
estimates of the independent variables’ coefficients. Collecting data
about more variables common to all the seven states is a challenge but
worth the endeavor. Random parameters are also not taken into consideration.
Mannering et al. (2016) assert that omitting random parameters
inhibits the capturing of unobserved heterogeneity effects.
However, incorporating random parameters renders the SPFs to be not
transferable to other settings (Mannering et al., 2016). Incorporating
finite mixture effects and random effects into the SPFs may also deter
SPF transferability (Lord and Mannering, 2010). Furthermore, the
generalized additive model and the hierarchical model structures are
not attempted because they are also difficult to transfer to data of
jurisdictions elsewhere (Lord and Mannering, 2010). Other than the
regression techniques that are difficult to transfer, it should be noted
that there are several viable techniques that could’ve been attempted.
The transferability of Conway-Maxwell Poisson, gamma, negative
multinomial, multivariate and generalized estimating equation SPFs
(Lord and Mannering, 2010) is worth investigating. Another shortcoming
is that the Tobit, RF, tree and hybrid models, recommended, are
not applicable to before-and-after countermeasure deployment analysis
using the empirical Bayes (EB) method prescribed by the HSM. The EB
method depends on weights which are a function of the overdispersion
of the NB model. Yet, Tobit, RF, tree and hybrid structures are applicable
for evaluating the safety of alternative road designs.},
}

@article{HONG2020105460,
title = {A driver behavior assessment and recommendation system for connected vehicles to produce safer driving environments through a “follow the leader” approach},
journal = {Accident Analysis \& Prevention},
volume = {139},
number = {nan},
pages = {105460},
year = {2020},
author = {Zihan Hong and Ying Chen and Yang Wu},
keywords = {Driver behavior, Vehicle trajectories, Connected vehicles, Gaussian mixture model, Data mining, Recommendation system, Assessment system},
abstract = {As part of the emerging world of intelligent transportation, there is considerable interest in developing connected vehicles that are more capable of identifying and guiding individual drivers’ behavior than collecting mileage as a moving cart. The two goals of this study are (a) to build a conceptual framework for driver assessment and (b) develop recommendation systems to evaluate individual driving performance and guide driver behaviors, thus improving the network traffic conditions and individuals’ perceived safety. A safety score is defined relatively by comparing a driver’s individual pattern to a standard “safe driver” pattern. To elaborate, the proposed system adopts advanced data mining techniques to extract, identify, characterize, and display driving behavior patterns. The scoring system provides a basis of assessing individual drivers, who are then recommended to mimic a nearby “safe” driver in a connected environment. To evaluate and implement the proposed conceptual framework, an anonymous trajectory dataset collected from Pittsburgh urban area is applied to build the scoring system, which is then integrated within a virtually simulated environment. The results show that the proposed behavior assessment and recommendation system framework improves the overall performance of a connected traffic system beyond those attained through baseline connectivity principles.},
institution = {Northwestern U},
annotation = {Not ML},
addendum = {Finally, several extensions of this work are proposed. First, different
levels of connectivity for longer tests with more vehicles within other
networks, especially in rural areas, would be worthwhile. Second, the
data library could be improved by introducing more trajectory data in
addition to other types of data describing the driving situations, particularly
weather, road conditions, and the driving culture (i.e. social
norms) in the area/city/country where the driving data is collected.
Third, the proposed system is extendable to an on-line case which can
be updated in real-time. Fourth, as stated in Section 5.2, the importance
of compliance rate could be further explored with a set of more systematically
designed experiments. With additional training data and
more robust simulations, the attractiveness of this system for deploying
a wider range of traffic management interventions and individual driver
guidance is indeed possible.},
}

@article{DAS2019250,
title = {Using trajectory-level SHRP2 naturalistic driving data for investigating driver lane-keeping ability in fog: An association rules mining approach},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {250-262},
year = {2019},
author = {Anik Das and Mohamed M. Ahmed and Ali Ghasemzadeh},
keywords = {Foggy weather conditions, Data mining techniques, Association rules mining, Lane-keeping, Naturalistic driving study, SHRP2, Limited visibility},
abstract = {The presence of fog has a significant adverse impact on driving. Reduced visibility due to fog obscures the driving environment and greatly affects driver behavior and performance. Lane-keeping ability is a lateral driver behavior that can be very crucial in run-off-road crashes under reduced visibility conditions. A number of data mining techniques have been adopted in previous studies to examine driver behavior including lane-keeping ability. This study adopted an association rules mining method, a promising data mining technique, to investigate driver lane-keeping ability in foggy weather conditions using big trajectory-level SHRP2 Naturalistic Driving Study (NDS) datasets. A total of 124 trips in fog with their corresponding 248 trips in clear weather (i.e., 2 clear trips: 1 foggy weather trip) were considered for the study. The results indicated that affected visibility was associated with poor lane-keeping performance in several rules. Furthermore, additional factors including male drivers, a higher number of lanes, the presence of horizontal curves, etc. were found to be significant factors for having a higher proportion of poor lane-keeping performance. Moreover, drivers with more miles driven last year were found to have better lane-keeping performance. The findings of this study could help transportation practitioners to select effective countermeasures for mitigating run-off-road crashes under limited visibility conditions.},
institution = {},
annotation = {},
addendum = {},
}

@article{OSMAN2019274,
title = {A hierarchical machine learning classification approach for secondary task identification from observed driving behavior data},
journal = {Accident Analysis \& Prevention},
volume = {123},
number = {nan},
pages = {274-281},
year = {2019},
author = {Osama A. Osman and Mustafa Hajij and Sogand Karbalaieali and Sherif Ishak},
keywords = {Distracted driving, Secondary tasks, Detection, Identification, Driving behavior, Ensemble tree, Machine learning, Accident investigations, In-vehicle systems, SHRP2},
abstract = {According to NHTSA, more than 3477 people (including 551 non-occupants) were killed and 391,000 were injured due to distraction-related crashes in 2015. The distracted driving epidemic has long been under research to identify its impact on driving behavior. There have been a few attempts to detect drivers’ engagement in secondary tasks from observed driving behavior. Yet, to the authors’ knowledge, not much effort has been directed to identify the types of secondary tasks from driving behavior parameters. This study proposes a bi-level hierarchical classification methodology using machine learning to identify the different types of secondary tasks drivers are engaged in using their driving behavior parameters. At the first level, drivers’ engagement in secondary tasks is detected, while at the second level, the distinct types of secondary tasks are identified. Comparative evaluation is performed between nine ensemble tree classification methods to identify three types of secondary tasks (hand-held cellphone calling, cellphone texting, and interaction with an adjacent passenger). The inputs to the models are five driving behavior parameters (speed, longitudinal acceleration, lateral acceleration, pedal position, and yaw rate) along with their standard deviations. The results showed that the overall secondary task detection accuracy ranged from 66\% to 96\%, except for the Decision Tree that was able to detect engagement in secondary tasks with a high accuracy of 99.8\%. For the identification of secondary tasks types, the overall accuracy ranged from 55\% to 79\%, with the highest accuracy of 82.2\% achieved by the Random Forest method. The findings of the paper show the proposed methodology promising to (1) characterize drivers’ engagement in unlawful secondary tasks (such as texting) as a counter measure to prevent crashes, and (2) alert drivers to pay attention back to the main driving task when risky changes to their driving behavior take place.},
institution = {LSU},
annotation = {Interesting in that it looked much more deeply at the data than other studies, looking for correlations between sets of variables.  I would like to know about this SHRP-2 },
addendum = {It is worth pointing out that this study did not account for the effect
of roadway type and geometric features and vehicle characteristics on
the driving behavior variables. However, the driving behavior variables
are analyzed as a pattern recognition problem in this study. In other
words, identification of secondary tasks is performed through studying
the pattern of changes in the driving behavior variables, rather than
targeting specific values of each variable as indicators of the type of
secondary task drivers are engaged in. Nonetheless, future research will
study the impact of roadway type and geometric features and vehicle
characteristics on driving behavior variables, hence on the predictability
power of the developed models.},
}

@article{TANG2019226,
title = {Crash injury severity analysis using a two-layer Stacking framework},
journal = {Accident Analysis \& Prevention},
volume = {122},
number = {nan},
pages = {226-238},
year = {2019},
author = {Jinjun Tang and Jian Liang and Chunyang Han and Zhibin Li and Helai Huang},
keywords = {Crash injury severity, Severity classification, Stacking model, Random Forests, Adaptive Boosting, Gradient Boosting Decision Tree},
abstract = {Crash injury severity analysis is useful for traffic management agency to further understand severity of crashes. A two-layer Stacking framework is proposed in this study to predict the crash injury severity: The fist layer integrates advantages of three base classification methods: RF (Random Forests), AdaBoost (Adaptive Boosting), and GBDT (Gradient Boosting Decision Tree); the second layer completes classification of crash injury severity based on a Logistic Regression model. A total of 5538 crashes were recorded at 326 freeway diverge areas. In the model calibration, several parameters including the number of trees in three base classification methods, learning rate, and regularization coefficient are optimized via a systematic grid search approach. In the model validation, the performance of the Stacking model is compared with several traditional models including the Support Vector Machine (SVM), Multi-Layer Perceptron (MLP) and Random Forests (RF) in the multi classification experiments. The prediction results show that Stacking model achieves superior performance evaluated by two indicators: accuracy and recall. Furthermore, all the factors used in severity prediction are classified into different categories according to their influence on the results, and sensitivity analysis of several significant factors is finally implemented to explore the impact of their value variation on the prediction accuracy.},
institution = {Central South U (Changsha), Southeast U (Nanjing)},
annotation = {Interesting.  Uses multiple methods, mixing ML and Statistics.},
addendum = {Further research
can focus on selecting more reasonable hyper parameters to
improve the performance of the model. In addition, a future research
direction could be how to consider the spatial-temporal correlations in
the modeling structure between crash severity and explanatory factors.},
}

@article{LI2020105432,
title = {Detection of driver manual distraction via image-based hand and ear recognition},
journal = {Accident Analysis \& Prevention},
volume = {137},
number = {nan},
pages = {105432},
year = {2020},
author = {Li Li and Boxuan Zhong and Clayton Hutmacher and Yulan Liang and William J. Horrey and Xu Xu},
keywords = {Driving distraction, Upper extremity kinematics, Deep learning, Computer vision, Multi-class classification},
abstract = {Driving distraction is a leading cause of fatal car accidents, and almost nine people are killed in the US each day because of distracting activities. Therefore, reducing the number of distraction-affected traffic accidents remains an imperative issue. A novel algorithm for detection of drivers’ manual distraction was proposed in this manuscript. The detection algorithm consists of two modules. The first module predicts the bounding boxes of the driver's right hand and right ear from RGB images. The second module takes the bounding boxes as input and predicts the type of distraction. 106,677 frames extracted from videos, which were collected from twenty participants in a driving simulator, were used for training (50\%) and testing (50\%). For distraction classification, the results indicated that the proposed framework could detect normal driving, using the touchscreen, and talking with a phone with F1-score 0.84, 0.69, 0.82, respectively. For overall distraction detection, it achieved F1-score of 0.74. The whole framework ran at 28 frames per second. The algorithm achieved comparable overall accuracy with similar research, and was more efficient than other methods. A demo video for the algorithm can be found at https://youtu.be/NKclK1bHRd4.},
institution = {NC State U},
annotation = {Not our data.  Analyzed images and videos of drivers taken from inside the driving simulator.},
addendum = {},
}

@article{BASSO2020105436,
title = {The importance of flow composition in real-time crash prediction},
journal = {Accident Analysis \& Prevention},
volume = {137},
number = {nan},
pages = {105436},
year = {2020},
author = {Franco Basso and Leonardo J. Basso and Raul Pezoa},
keywords = {Real-time crash prediction, Automatic vehicle identification, Flow composition, Support vector machines, Logistic regression},
abstract = {Previous real-time crash prediction models have scarcely used data disaggregated by vehicle type such as light, heavy and motorcycles. Thus, little effort has been made to quantify the impact of flow composition variables as crash precursors. We analyze the advantages of having access to this data by analyzing two scenarios, namely, with aggregated and disaggregated data. For each case, we build Logistics Regressions and Support Vector Machines models to predict accidents in a major urban expressway in Santiago, Chile. Our results show that having access to disaggregated data by vehicle type increases the prediction power up to 30 \% providing, at the same time, much better intuition about the actual traffic conditions that may lead to accidents. These results may be useful when evaluating technology investments and developments in urban freeways.},
institution = {U of Chile, Pontificia Universidad Católica de Valparaíso, Universidad Diego Portales,},
annotation = {Interesting for comparing two ways to treat the data.},
addendum = {},
}

@article{AMIRI2020105468,
title = {A comparison between Artificial Neural Network and Hybrid Intelligent Genetic Algorithm in predicting the severity of fixed object crashes among elderly drivers},
journal = {Accident Analysis \& Prevention},
volume = {138},
number = {nan},
pages = {105468},
year = {2020},
author = {Amir Mohammadian Amiri and Amirhossein Sadri and Navid Nadimi and Moe Shams},
keywords = {Hybrid models, Elderly drivers, Fixed object crashes, Crash severity},
abstract = {Run-off-road (ROR) crashes have always been a major concern as this type of crash is usually associated with a considerable number of serious injury and fatal crashes. A substantial portion of ROR fatalities occur in collisions with fixed objects at the roadside. Thus, this study seeks to investigate the severity of ROR crashes where elderly drivers, aged 65 years or more, hit a fixed object. The reason why the present study investigates this issue among older drivers is that, comparing to younger drivers, this age group of drivers have different psychological and physical features. Because of these differences, they are more likely to get injured in ROR types of crashes. This paper applies two types of Artificial Intelligence (AI) techniques, including hybrid Intelligent Genetic Algorithm and Artificial Neural Network (ANN) using the crashe information of California in 2012 obtained from Highway Safety Information System (HSIS) database. Although the results showed that the developed ANN outperformed the hybrid Intelligent Genetic Algorithm, the hybrid approach was more capable of predicting high-severity crashes. This is rooted in the way the hybrid model was trained by taking advantage of the Genetic Algorithm (GA). The results also indicated that the light condition has been the most significant parameter in evaluating the level of severity associated with fixed object crashes among elderly drivers, which is followed by the existence of the right and left shoulders. Following these three contributing factors, cause of collision, Average Annual Daily Traffic (AADT), number of involved vehicles, age, road surface condition, and gender have been identified as the most important variables in the developed ANN, respectively. This helps to identify gaps and improve public safety towards improving the overall highway safety situation of older drivers.},
institution = {Shahid Bahonar U},
annotation = {Identified factors associated with level of severity of crash.},
addendum = {None},
}

@article{WANG2019365,
title = {A crash prediction method based on bivariate extreme value theory and video-based vehicle trajectory data},
journal = {Accident Analysis \& Prevention},
volume = {123},
number = {nan},
pages = {365-373},
year = {2019},
author = {Chen Wang and Chengcheng Xu and Yulu Dai},
keywords = {Bivariate extreme value theory, Video-based vehicle trajectory, Traffic conflict, Crash prediction},
abstract = {Traditional statistical crash prediction models oftentimes suffer from poor data quality and require large amount of historical data. In this paper, we propose a crash prediction method based on a bivariate extreme value theory (EVT) framework, considering both drivers’ perception-reaction failure and failure to proper evasive actions. An unmanned aerial vehicle (UAV) was utilized to collect videos of ten intersections in Fengxian, China, at representative time periods. High-resolution vehicle trajectory data were extracted by a Kanade-Lucas-Tomasi (KLT) technique, based on four detailed metrics were derived including Time-to-accident (TA), Post-encroachment Time (PET), minimum Time-to-collision (mTTC), and Maximum Deceleration Rate (MaxD). TA was expected to capture the chance of perception-reaction failure, while other three metrics were used to measure the probability of failure to proper evasive actions. Univariate EVT models were applied to obtain marginal crash probability based on each metric. Bivariate EVT models were developed to obtain joint crash probability based on three pairs: TA and mTTC, TA and PET, and TA and MaxD. Thus, union crash probability within observation periods can be derived and the annual crash frequency of each intersection was predicted. The predictions were compared to actual annual crash frequencies, using multiple tests. The findings are three-folds: 1. The best conflict metrics for angle and rear-end crash predictions were different; 2. Bivariate EVT models were found to be superior to univariate models, regarding both angle and rear-end crash predictions; 3. TA appeared to be an important conflict metric that should be considered in a bivariate EVT model framework. In general, the proposed method can be considered as a promising tool for safety evaluation, when crash data are limited.},
institution = {Southeast U (Nanjing)},
annotation = {Not ML},
addendum = {},
}

@article{LI2020105345,
title = {Short-term prediction of safety and operation impacts of lane changes in oscillations with empirical vehicle trajectories},
journal = {Accident Analysis \& Prevention},
volume = {135},
number = {nan},
pages = {105345},
year = {2020},
author = {Meng Li and Zhibin Li and Chengcheng Xu and Tong Liu},
keywords = {Freeway, Safety, Prediction, Machine learning, Lane change impact},
abstract = {Lane changes made during traffic oscillations on freeways largely affect traffic safety and could increase collision potentials. Predicting the impacts of lane change can help to develop optimal lane change strategies of autonomous vehicles for safety improvement. The study aims at proposing a machine learning method for the short-term prediction of lane-changing impacts (LCI) during the propagation of traffic oscillations. The empirical lane-changing trajectory records were obtained from the Next Generation Simulation (NGSIM) platform. A support vector regression (SVR) model was trained in this study to predict the LCI on the crash risks and flow change using microscopic traffic variables such as individual speed, gap and acceleration on both original lanes and target lanes. Sensitivity analyses were conducted in the SVR to quantify the contributions of correlative lane changing factors. The results showed that the trained SVR model achieved an accuracy of 72.81 \% for the risk of crashes and 95.34 \% in predicting the flow change. The sensitivity analysis explored the optimal speed and acceleration for the lane changer to achieve the lowest time integrated time-to-collision (TIT) value for safety maximization. Finally, we compared the LCI for motorcycles, automobiles and trucks as well as the LCI for both lane-changing directions (from left to right and from right to left). It was found that motorcycles conducted lane changes with smaller gaps and larger speed differences, which brings the highest crash risks. Passenger cars were found to be the safest when they conduct lane changes. Lane changes to the right had more negative impacts on traffic flow and crash risks.},
institution = {Southeast U (Nanjing)},
annotation = {Not our data. Interesting graphics.},
addendum = {},
}

@article{SIEBERT2020105319,
title = {Detecting motorcycle helmet use with deep learning},
journal = {Accident Analysis \& Prevention},
volume = {134},
number = {nan},
pages = {105319},
year = {2020},
author = {Felix Wilhelm Siebert and Hanhe Lin},
keywords = {Deep learning, Helmet use detection, Motorcycle, Road safety, Injury prevention},
abstract = {The continuous motorization of traffic has led to a sustained increase in the global number of road related fatalities and injuries. To counter this, governments are focusing on enforcing safe and law-abiding behavior in traffic. However, especially in developing countries where the motorcycle is the main form of transportation, there is a lack of comprehensive data on the safety-critical behavioral metric of motorcycle helmet use. This lack of data prohibits targeted enforcement and education campaigns which are crucial for injury prevention. Hence, we have developed an algorithm for the automated registration of motorcycle helmet usage from video data, using a deep learning approach. Based on 91,000 annotated frames of video data, collected at multiple observation sites in 7 cities across the country of Myanmar, we trained our algorithm to detect active motorcycles, the number and position of riders on the motorcycle, as well as their helmet use. An analysis of the algorithm's accuracy on an annotated test data set, and a comparison to available human-registered helmet use data reveals a high accuracy of our approach. Our algorithm registers motorcycle helmet use rates with an accuracy of −4.4\% and +2.1\% in comparison to a human observer, with minimal training for individual observation sites. Without observation site specific training, the accuracy of helmet use detection decreases slightly, depending on a number of factors. Our approach can be implemented in existing roadside traffic surveillance infrastructure and can facilitate targeted data-driven injury prevention campaigns with real-time speed. Implications of the proposed method, as well as measures that can further improve detection accuracy are discussed.},
institution = {Technische Universitat Berlin, Universitat Konstanz},
annotation = {Not our data.  Video data.},
addendum = {There are a number of limitations to this study. Algorithmic accuracy
was only analyzed for road environments within Myanmar, limiting
the type of motorcycles and helmets present in the training set.
Future studies will need to assess whether the algorithm can maintain
the overall high accuracy in road environments in other countries. A
similar limitation can be seen in the position of the observation camera.
While the algorithm is able to detect motorcycles from a broad range of
angles due to diverse training data, there was no observation site where
the observation camera was installed in an overhead position, filming
traffic from above. Since traffic surveillance infrastructure is often installed
at this position, future studies will need to assess whether the
algorithm would produce accurate results from an overhead angle. This
is especially important in light of the results of the Yangon II observation
site, where an unusual camera angle lead to a large number of
missed detections. Furthermore, a more structured variation of camera
to lane angle would help to better understand optimal positioning of
observation equipment for maximum detection accuracy. While it was
included in the data annotation process, the algorithmic accuracy in
detecting the position of riders was not compared to human registered
data in this study. In light of large differences of motorcycle helmet use
for different rider positions (Siebert et al., 2019), future studies will
need to incorporate deeper analysis of position detection accuracy. For
the comparison of human- and machine-registered helmet use rates, it
appears promising to enable a detailed error analysis (false positive/
false negative) through the use of an adapted data structure of human
helmet use registration.},
}

@article{KATRAKAZAS201961,
title = {A new integrated collision risk assessment methodology for autonomous vehicles},
journal = {Accident Analysis \& Prevention},
volume = {127},
number = {nan},
pages = {61-79},
year = {2019},
author = {Christos Katrakazas and Mohammed Quddus and Wen-Hua Chen},
keywords = {None},
abstract = {Real-time risk assessment of autonomous driving at tactical and operational levels is extremely challenging since both contextual and circumferential factors should concurrently be considered. Recent methods have started to simultaneously treat the context of the traffic environment along with vehicle dynamics. In particular, interaction-aware motion models that take inter-vehicle dependencies into account by utilizing the Bayesian interference are employed to mutually control multiple factors. However, communications between vehicles are often assumed and the developed models are required many parameters to be tuned. Consequently, they are computationally very demanding. Even in the cases where these desiderata are fulfilled, current approaches cannot cope with a large volume of sequential data from organically changing traffic scenarios, especially in highly complex operational environments such as dense urban areas with heterogeneous road users. To overcome these limitations, this paper develops a new risk assessment methodology that integrates a network-level collision estimate with a vehicle-based risk estimate in real-time under the joint framework of interaction-aware motion models and Dynamic Bayesian Networks (DBN). Following the formulation and explanation of the required functions, machine learning classifiers were utilized for the real-time network-level collision prediction and the results were then incorporated into the integrated DBN model for predicting collision probabilities in real-time. Results indicated an enhancement of the interaction-aware model by up to 10\%, when traffic conditions are deemed as collision-prone. Hence, it was concluded that a well-calibrated collision prediction classifier provides a crucial hint for better risk perception by autonomous vehicles.},
institution = {Loughborough U},
annotation = {Perhaps Interesting.  I think they combined two types of data in the analysis.},
addendum = {None},
}

@article{JACOBEDENAUROIS201995,
title = {Detection and prediction of driver drowsiness using artificial neural network models},
journal = {Accident Analysis \& Prevention},
volume = {126},
number = {nan},
pages = {95-104},
year = {2019},
author = {Charlotte {Jacobé de Naurois} and Christophe Bourdin and Anca Stratulat and Emmanuelle Diaz and Jean-Louis Vercher},
keywords = {Drowsiness, Prediction, Artificial neural network, Physiological measurement, Behavioral measurement, Driving performance and activity},
abstract = {Not just detecting but also predicting impairment of a car driver’s operational state is a challenge. This study aims to determine whether the standard sources of information used to detect drowsiness can also be used to predict when a given drowsiness level will be reached. Moreover, we explore whether adding data such as driving time and participant information improves the accuracy of detection and prediction of drowsiness. Twenty-one participants drove a car simulator for 110min under conditions optimized to induce drowsiness. We measured physiological and behavioral indicators such as heart rate and variability, respiration rate, head and eyelid movements (blink duration, frequency and PERCLOS) and recorded driving behavior such as time-to-lane-crossing, speed, steering wheel angle, position on the lane. Different combinations of this information were tested against the real state of the driver, namely the ground truth, as defined from video recordings via the Trained Observer Rating. Two models using artificial neural networks were developed, one to detect the degree of drowsiness every minute, and the other to predict every minute the time required to reach a particular drowsiness level (moderately drowsy). The best performance in both detection and prediction is obtained with behavioral indicators and additional information. The model can detect the drowsiness level with a mean square error of 0.22 and can predict when a given drowsiness level will be reached with a mean square error of 4.18min. This study shows that, on a controlled and very monotonous environment conducive to drowsiness in a driving simulator, the dynamics of driver impairment can be predicted.},
institution = {Aix Marseille U},
annotation = {Not our data.  Driving simulator.},
addendum = {},
}

@article{TANG2020105551,
title = {Improving the transferability of the crash prediction model using the TrAdaBoost.R2 algorithm},
journal = {Accident Analysis \& Prevention},
volume = {141},
number = {nan},
pages = {105551},
year = {2020},
author = {Dongjie Tang and Xiaohan Yang and Xuesong Wang},
keywords = {Crash prediction model, Transferability, TrAdaBoost.R2, Calibration factor, Negative binomial model},
abstract = {The crash prediction model is a useful tool for traffic administrators to identify significant risk factors, estimate crash frequency, and screen hazardous locations, but some jurisdictions interested in traffic safety analysis can collect only limited or low-quality data. Existing crash prediction models can be transferred if calibrated, but the current aggregate calibration method limits prediction accuracy and the disaggregate method is resource-consuming. Transfer learning is another approach to calibration that acquires knowledge from old data domains to solve problems in new data domains. An instance-based transfer learning technique, TrAdaBoost.R2, is adopted in this study since it meets the requirement of site-based crash prediction model transfer. TrAdaBoost.R2 was compared with AdaBoost.R2 using a simply pooled data set to examine the efficiency in extracting knowledge from a spatially outdated source data domain (old data domain). The target data domain (new data domain) was sampled to test the technique’s adaptability to small sample size. The calibration factor method based on a negative binomial model was employed to compare its predictive performance with that of the transfer learning technique. Mean square error was calculated to evaluate the prediction accuracy. Two cities in China, Shanghai and Guangzhou, were taken mutually as source data domain and target data domain. Results showed that the models constructed with TrAdaBoost.R2 had better prediction accuracy than the conventional calibration method. The TrAdaBoost.R2 is recommended due to its predictive performance and adaptability to small sample size. Crash prediction models are proposed to construct for peak and off-peak hours separately.},
institution = {Tongji U, The Key Laboratory of Road and Traffic Engineering},
annotation = {Interesting.  Calibrating the transfer of a model built for one data set to },
addendum = {},
}

@article{HOSSAIN201966,
title = {Real-time crash prediction models: State-of-the-art, design pathways and ubiquitous requirements},
journal = {Accident Analysis \& Prevention},
volume = {124},
number = {nan},
pages = {66-84},
year = {2019},
author = {Moinul Hossain and Mohamed Abdel-Aty and Mohammed A. Quddus and Yasunori Muromachi and Soumik Nafis Sadeek},
keywords = {ITS, Real-time crash prediction model, Design pathway, Universal design requirements},
abstract = {Proactive traffic safety management systems can monitor traffic conditions in real-time, identify the formation of unsafe traffic dynamics, and implement suitable interventions to bring unsafe conditions back to normal traffic situations. Recent advancements in artificial intelligence, sensor fusion and algorithms have brought about the introduction of a proactive safety management system closer to reality. The basic prerequisite for developing such a system is to have a reliable crash prediction model that takes real-time traffic data as input and evaluates their association with crash risk. Since the early 21st century, several studies have focused on developing such models. Although the idea has considerably matured over time, the endeavours have been quite discrete and fragmented at best because the fundamental aspects of the overall modelling approach substantially vary. Therefore, a number of transitional challenges have to be identified and subsequently addressed before a ubiquitous proactive safety management system can be formulated, designed and implemented in real-world scenarios. This manuscript conducts a comprehensive review of existing real-time crash prediction models with the aim of illustrating the state-of-the-art and systematically synthesizing the thoughts presented in existing studies in order to facilitate its translation from an idea into a ready to use technology. Towards that journey, it conducts a systematic review by applying various text mining methods and topic modelling. Based on the findings, this paper ascertains the development pathways followed in various studies, formulates the ubiquitous design requirements of such models from existing studies and knowledge of similar systems. Finally, this study evaluates the universality and design compatibility of existing models. This paper is, therefore, expected to serve as a one stop knowledge source for facilitating a faster transition from the idea of real-time crash prediction models to a real-world operational proactive traffic safety management system.},
institution = {Islamic U of Technology, U of Central Florida, Loughborough U, Tokyo Institute of Technology, IUBAT-International U of Business Agriculture and Technology},
annotation = {Interesting.  Review of previous papers with text mining.  },
addendum = {},
}

@article{SCHLOGL2020105398,
title = {A multivariate analysis of environmental effects on road accident occurrence using a balanced bagging approach},
journal = {Accident Analysis \& Prevention},
volume = {136},
number = {nan},
pages = {105398},
year = {2020},
author = {Matthias Schlögl},
keywords = {Adverse weather effects, Imbalanced data, Binary classification, Balanced bagging, Accident analysis, Road safety, Random forest, xgBoost},
abstract = {Determining and understanding the environmental factors contributing to road traffic accident occurrence is of core importance in road safety research. In this study, a methodology to obtain robust and unbiased results when modeling imbalanced, high-resolution accident data is described. Based on a data set covering the whole highway network of Austria in a fine spatial (250 m) and temporal (1 h) scale, the effects of 48 covariates on accident occurrence are analyzed, with a special emphasis on real-time weather variables obtained through meteorological re-analysis. A balanced bagging approach is employed to cope with the issue of class imbalance. By fitting different tree-based classifiers to a large number of bootstrapped training samples, ensembles of binary classification models are established. The final prediction is achieved through majority vote across each ensemble, resulting in a robust prediction with reduced variance. Findings show the merits of the proposed approach in terms of model quality and robustness of the results, consistently displaying accuracies around 80\% while exhibiting sensitivities of approximately 50\%. In addition to certain features related to roadway geometrics, surface condition and traffic volume, a number of weather variables are found to be of importance for predicting accident occurrence. The proposed methodological take may not only pave the way for further analyses of high-resolution road safety data including real-time information, but can also be transferred to any other imbalanced classification problem.},
institution = {U of Natural Resources and Life Sciences, Vienna},
annotation = {Interesting for handling imbalanced data},
addendum = {This study also lays the foundation for future research in this area.
In particular, spatial and temporal autocorrelation of accidents could be
interesting to explore in future work. The benefits of nested spatial cross
validation over repeated random k-fold cross-validation could be assessed
together with an assessment of different (temporal) aggregation
levels.},
}

@article{HALBERSBERG2019350,
title = {Young driver fatal motorcycle accident analysis by jointly maximizing accuracy and information},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {350-361},
year = {2019},
author = {Dan Halbersberg and Boaz Lerner},
keywords = {Young drivers, Fatal accidents, Motorcycle, Machine learning, Information measure, Prediction, Bayesian network, Key factors},
abstract = {While young drivers (YDs) constitute ∼10\% of the driver population, their fatality rate in motorcycle accidents is up to three times higher. Thus, we are interested in predicting fatal motorcycle accidents (FMAs), and in identifying their key factors and possible causes. Accurate prediction of YD FMAs from data by risk minimization using the 0/1 loss function (i.e., the ordinary classification accuracy) cannot be guaranteed because these accidents are only ∼1\% of all YD motorcycle accidents, and classifiers tend to focus on the majority class of minor accidents at the expense of the minority class of fatal ones. Also, classifiers are usually uninformative (providing no information about the distribution of misclassifications), insensitive to error severity (making no distinction between misclassification of fatal accidents as severe or minor), and limited in identifying key factors. We propose to use an information measure (IM) that jointly maximizes accuracy and information and is sensitive to the error distribution and severity. Using a database of ∼3600 motorcycle accidents, a Bayesian network classifier optimized by IM predicted FMAs better than classifiers maximizing accuracy or other predictive or information measures, and identified fatal accident key factors and causal relations.},
institution = {},
annotation = {},
addendum = {},
}

@article{LI2020105371,
title = {Real-time crash risk prediction on arterials based on LSTM-CNN},
journal = {Accident Analysis \& Prevention},
volume = {135},
number = {nan},
pages = {105371},
year = {2020},
author = {Pei Li and Mohamed Abdel-Aty and Jinghui Yuan},
keywords = {Real-time crash risk, Urban arterials, Recurrent neural network, Deep learning},
abstract = {Real-time crash risk prediction is expected to play a crucial role in preventing traffic accidents. However, most existing studies only focus on freeways rather than urban arterials. This paper proposes a real-time crash risk prediction model on arterials using a long short-term memory convolutional neural network (LSTM-CNN). This model can explicitly learn from the various features, such as traffic flow characteristics, signal timing, and weather conditions. Specifically, LSTM captures the long-term dependency while CNN extracts the time-invariant features. The synthetic minority over-sampling technique (SMOTE) is used for resampling the training dataset. Five common models are developed to compare the results with the proposed model, such as the XGBoost, Bayesian Logistics Regression, LSTM, etc. Experiments suggest that the proposed model outperforms others in terms of Area Under the Curve (AUC) value, sensitivity, and false alarm rate. The findings of this paper indicate the promising performance of using LSTM-CNN to predict real-time crash risk on arterials.},
institution = {U of Central Florida},
annotation = {Interesting. Similar, with SMOTE.},
addendum = {},
}

@article{BAO2019239,
title = {A spatiotemporal deep learning approach for citywide short-term crash risk prediction with multi-source data},
journal = {Accident Analysis \& Prevention},
volume = {122},
number = {nan},
pages = {239-254},
year = {2019},
author = {Jie Bao and Pan Liu and Satish V. Ukkusuri},
keywords = {Multi-source data, Spatiotemporal, Crash risk prediction, Deep learning},
abstract = {The primary objective of this study is to investigate how the deep learning approach contributes to citywide short-term crash risk prediction by leveraging multi-source datasets. This study uses data collected from Manhattan in New York City to illustrate the procedure. The following multiple datasets are collected: crash data, large-scale taxi GPS data, road network attributes, land use features, population data and weather data. A spatiotemporal convolutional long short-term memory network (STCL-Net) is proposed for predicting the citywide short-term crash risk. A total of nine prediction tasks are conducted and compared, including weekly, daily and hourly models with 8 × 3, 15 × 5 and 30 × 10 grids, respectively. The results suggest that the prediction performance of the proposed model decreases as the spatiotemporal resolution of prediction task increases. Moreover, four commonly-used econometric models, and four state-of-the-art machine-learning models are selected as benchmark methods to compare with the proposed STCL-Net for all the crash risk prediction tasks. The comparative analyses suggest that in general the proposed STCL-Net outperforms the benchmark methods for different crash risk prediction tasks in terms of higher prediction accuracy rate and lower false alarm rate. The results verify that the proposed spatiotemporal deep learning approach performs better at capturing the spatiotemporal characteristics for the citywide short-term crash risk prediction. In addition, the comparative analyses also reveal that econometric models perform better than machine-learning models in weekly crash risk prediction tasks, while they exhibit worse results than machine-learning models in daily crash risk prediction tasks. The results can potentially guide transportation safety engineers to select appropriate methods for different crash risk prediction tasks.},
institution = {Southeast U (Nanjing), Purdue U},
annotation = {Perhaps interesting for comparing econometric and ML models.},
addendum = {[Get more data, and] Moreover, new spatiotemporal deep learning architecture should
also be explored to addressing the zero-inflated issue.},
}

@article{CHEN2019156,
title = {Key feature selection and risk prediction for lane-changing behaviors based on vehicles’ trajectory data},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {156-169},
year = {2019},
author = {Tianyi Chen and Xiupeng Shi and Yiik Diew Wong},
keywords = {Lane changing risk, Feature selection, Crash potential index, Resampling method, Random Forest},
abstract = {Risky lane-changing (LC) behavior of vehicles on the road has negative effects on traffic safety. This study presents a research framework for key feature selection and risk prediction of car’s LC behavior on the highway based on vehicles’ trajectory dataset. To the best of our knowledge, this is the first study that focuses on key feature selection and risk prediction for LC behavior on the highway. From the vehicles’ trajectory dataset, we extract car’s candidate features and apply fault tree analysis and k-Means clustering algorithm to determine the LC risk level based on the performance indicator of Crash Potential Index (CPI). Random Forest (RF) classifier is applied to select key features from car’s candidate features and predict LC risk level. This study also proposes a method to evaluate the resampling methods to resample the LC risk dataset in terms of fitness performance and prediction performance. The cars’ trajectory data collected from the Next Generation Simulation (NGSIM) dataset is used for framework development and verification. The sensitivity analysis of CPI indicates that the following cars in the original lane and target lane are respectively the safest and riskiest cars of the surrounding cars in an LC event. The results of resampling method evaluation show that SMOTETomek, which is less likely to be overfitting and has high prediction performance, is well suited for resampling the LC risk dataset on which RF classifier is trained. The results of key feature selection imply that the individual behaviors of the LC car and its surrounding cars in the original lane, the interactions between the LC car and its surrounding cars, and the interactions between the surrounding cars in the target lane (especially the interaction of the cars’ accelerations) are of importance to the LC risk.},
institution = {Nanyang Technological U},
annotation = {Not our data.  Interesting in that we could use that data.  },
addendum = {In this study, the validation of the research framework is conducted
from an experimental perspective. We consider the LC scenario that
involve five cars on the highway based on the vehicles’ trajectory dataset
collected in the US. To get a stronger validation and evaluation,
more research should be conducted to gain further insight into the LC
risk. For example, future study can focus on LC risk that involves more
vehicle types (e.g. truck, motorcycle, etc.), LC scenarios with more than
five vehicles, LC risk on different road types (e.g. urban road), and
comparison of LC risk across different countries. Besides vehicle’s behaviors,
it shall be useful to investigate human behaviors pertaining to
LC risk. The research framework proposed in this paper provides the
building blocks in these future studies. From a technical perspective, we
could explore more advanced methods to select key features and
achieve higher LC risk prediction accuracy.},
}

@article{OVIEDOTRESPALACIOS2020105412,
title = {“It is frustrating to not have control even though I know it’s not legal!”: A mixed-methods investigation on applications to prevent mobile phone use while driving},
journal = {Accident Analysis \& Prevention},
volume = {137},
number = {nan},
pages = {105412},
year = {2020},
author = {Oscar Oviedo-Trespalacios and Verity Truelove and Mark King},
keywords = {Cell phone, Ergonomics, Human-machine interactions, Inattention, Driver behaviour, UX},
abstract = {Mobile phone distracted driving is a major risk factor for crashes. However, this behaviour has been increasing in recent years. Effective enforcement of mobile phone bans while driving faces several obstacles; as such, it is important to consider additional countermeasures. Applications designed to prevent distracted driving are a promising solution, yet more research is needed that examines their effectiveness in reducing dangerous phone use while driving behaviours. Additionally, these applications are voluntary in nature; therefore, an understanding of drivers’ perceptions of the applications is necessary to determine how to improve uptake. A mixed methods design was utilised to examine these factors in a comprehensive manner. A total of 40 participants used the smartphone application “Do Not Disturb While Driving” for iOS phone operating systems or “Android Auto” for Android phone operating systems for approximately one week and completed three diary entries reporting on their experience. Two questionnaires that examined phone use while driving behaviours were also administered to participants; one before and one after completing the study. The quantitative results found that engagement in 1) visual-manual, 2) cognitive-auditory and 3) music mobile phone interactions significantly decreased while using the application. Distraction engagement and mental workload while driving also significantly decreased while using the application. The qualitative results identified a number of areas of improvement that need to be addressed, e.g. activation of the application and Bluetooth connection reliability. The features that required improvement presented an obstacle for effective use of the applications, and in some cases resulted in drivers deciding to stop using the application. Positive perceptions of the application were associated with the experiences of the application functioning appropriately and activating automatically. These results show that applications designed for voluntary use to prevent mobile phone distracted driving are a promising countermeasure, although current applications require several improvements.},
institution = {Queensland U of Technology},
annotation = {Not ML},
addendum = {},
}

@article{SMITS2019105280,
title = {Identifying risk of poor physical and mental health recovery following a road traffic crash: An industry-specific screening tool},
journal = {Accident Analysis \& Prevention},
volume = {132},
number = {nan},
pages = {105280},
year = {2019},
author = {Esther Smits and Charlotte Brakenridge and Elise Gane and Jacelle Warren and Michelle Heron-Delaney and Justin Kenardy and Venerina Johnston},
keywords = {Traffic accidents, Recovery of function, Mental Health Recovery, Decision support techniques},
abstract = {This study aimed to develop an industry-specific tool to identify risk of poor physical and mental recovery following minor to moderate injuries sustained in a road traffic crash (RTC). Existing tools are often designed for implementation by health professionals rather than insurer case managers who may not have a background in health. This study is a secondary analysis of a longitudinal cohort study using data collected at 2–6 months and 24 months post-RTC. Participants were claimants (n = 254; Mean age = 50 years; 65\% female) with mild-moderate injuries recruited through the common-law ‘fault-based’ compulsory third party scheme in Queensland, Australia. Sociodemographic, functional and psychological health factors were collected at baseline (2–6 months post RTC) and used as potential predictors for physical and mental health-related quality of life (Short Form 36 v2) at the 2-year follow-up. The LASSO (Least Absolute Shrinkage and Selection Operator) analysis identified six disability items (from the World Health Organization Disability Assessment Schedule 2) to predict poor physical and one item to predict poor mental health-related quality of life. Logistic regressions of these items in addition to age and gender were used to develop a screening tool. Using the tool, 90\% of those at risk of poor physical and 80\% of those at risk of poor mental health-related quality of life were identified correctly. To conclude, this study presents an 8-item, context-specific tool to help injury managers identify individuals at risk of poor physical and mental health recovery following mild-moderate RTC-related injuries. The tool requires validation in a new cohort and confirmation of acceptability by end-users.},
institution = {U of Queensland},
annotation = {Not our data, Not ML},
addendum = {},
}

@article{SCHLOGL2019134,
title = {A comparison of statistical learning methods for deriving determining factors of accident occurrence from an imbalanced high resolution dataset},
journal = {Accident Analysis \& Prevention},
volume = {127},
number = {nan},
pages = {134-149},
year = {2019},
author = {Matthias Schlögl and Rainer Stütz and Gregor Laaha and Michael Melcher},
keywords = {Statistical learning, Imbalanced data, Binary classification, Accident analysis, Road safety},
abstract = {One of the main aims of accident data analysis is to derive the determining factors associated with road traffic accident occurrence. While current studies mainly use variants of count data regression to achieve this aim, the problem can also be considered as a binary classification task, with the dichotomous target variable indicating events (accidents) and non-events (no accidents). The effects of 45 variables – describing road condition and geometry, traffic volume and regulations, weather, and accident time – are analyzed using a dataset in high temporal (1 h) and spatial (250 m) resolution, covering the whole highway network of Austria over the period of four consecutive years. A combination of synthetic minority oversampling and maximum dissimilarity undersampling is used to balance the training dataset. We employ and compare a series of statistical learning techniques with respect to their predictive performance and discuss the importance of determining factors of accident occurrence from the ensemble of models. Findings substantiate that a trade-off between accuracy and sensitivity is inherent to imbalanced classification problems. Results show satisfying performance of tree-based methods which exhibit accuracies between 75\% and 90\% while exhibiting sensitivities between 30\% and 50\%. Overall, this analysis emphasizes the merits of using high-resolution data in the context of accident analysis.},
institution = {U of Natural Resources and Life Sciences, Vienna},
annotation = {Statistical Learning},
addendum = {Having described the modeling approach with a methodological
focus, further work should be targeted at a more detailed assessment of
the results from a traffic-safety point of view. Therefore, next steps
should focus on investigating whose sections’ outcome is captured well,
and shed some light on the why. In addition, further analysis featuring
variants of bootstrap aggregating could be useful for improving the
robustness of the results. We propose several concrete analysis steps for
this empirical assessment:
Further temporal aggregation: Given the assumption that results
obtained from any learners applied to the dataset featuring hourly
values are subject to uncertainty, the temporal binning size could be
adjusted in order to create coarser, yet more robust aggregates.
These aggregated data could be used to test the hypothesis that the
significance of results would increase with increasing binning level.
While some information is lost, since variables related to some sort
of timestamp (i.e. hour and weekday classification, respectively)
have to be dropped, a more robust assessment might prove to be
conclusive.
Assessing model performance using a meta variable: In order to
further investigate contributing factors to model quality, several
approaches featuring a new binary meta target variable, which is
derived from the confusion matrices of the existing model results,
could be tested. Multiple definitions of how to derive such a metavariable
are possible. Machine learning models for binary classification
could again be trained to assess variable importance for this
new meta model.
Balanced bagging: Following the line of Wallace et al. (2011),
bagging an ensemble of classifiers induced over balanced bootstrap
training samples and predicting the outcome state by using a majority
vote could be a valuable approach to obtain more robust results.
Correlation issues: Further insights might be gained by considering
collinearity in variables and (spatio-temporal) autocorrelation effects.
Unobserved heterogeneity: Since it is impossible to include all the
data that could potentially determine the likelihood of a traffic accident
into a statistical model, future work might focus on model
formulations accounting for unobserved heterogeneity (Mannering,
2018).
Knowledge-extraction and expert assessment: Tools for further
assessment of black-box models, including – among others – Local
Interpretable Model-Agnostic Explanations [LIME, Ribeiro et al.
(2016)] and Descriptive mAchine Learning EXplanations [DALEX,
Biecek (2018)] could be used for an in-depth assessment of model
quality. In addition, the case-specific random forests (Xu et al.,
2016), which are tailored to specific points of interest in the regressor
space, could be employed to specifically assess certain road
sections of interest.
In addition, a comparison with similar analysis conducted in other
countries might provide substantial further insights into the applicability
of the proposed methodology.
Overall, we hope that our findings will contribute to opening up
new methodological applications of statistical learning methods in the
field of road safety research.},
}

@article{WANG2019180,
title = {Expressway crash risk prediction using back propagation neural network: A brief investigation on safety resilience},
journal = {Accident Analysis \& Prevention},
volume = {124},
number = {nan},
pages = {180-192},
year = {2019},
author = {Junhua Wang and Yumeng Kong and Ting Fu},
keywords = {Crash risk prediction, Expressway safety, Safety critical events, Safety resilience of traffic, Back-propagation neural network, Vehicle moving violation},
abstract = {This study presents the work in predicting crash risk on expressways with consideration of both the impact of safety critical events and traffic conditions. The traffic resilience theory is introduced to learn safety problems from the standpoint of 1) considering safety critical events, such as traffic violations, as the safety disturbances, and 2) considering safety resilience as the ability of the traffic, greatly associated with traffic conditions, to resist critical events turning into crashes. The concept of safety resilience was illustrated qualitatively through simulation experiments. Aimsun microsimulation software was used to simulate traffic conditions with safety critical events (vehicle violations, in this paper) involved based on the geometric design of the G15 Expressway in Shanghai. Based on data from the simulation experiment, a two-staged model was developed which classifies crash risk status into three types including no-risk, low-risk and high-risk status. Modeling approach that relies on the back propagation neural network method was applied. The performance of the model in prediction was validated through the Receiver Operating Characteristic (ROC) curve test. Results indicated that the model performed well in predicting crash risks in the simulated environment. After training the model, an extra simulation experiment involving six additional tests was conducted. Results show that the traffic resilience theory may work in explaining the relationship between traffic conditions, safety critical events and crash risk, which are the key elements in road safety field. The introduction of safety resilience may inspire further exploration on this topic in both research and practice. Meanwhile, the model can be used to predict and monitor risks on expressways in a potentially more precise way.},
institution = {Key Laboratory of Road and Traffic Engineering of the Ministry of Education, McGill U},
annotation = {Not our data.  Simulation},
addendum = {However, limitations exist in this study and should be further included
in future studies. Without traffic data collected from the road
section used in the simulation, we were not able to fully calibrate the
simulation. Though the use of the virtual and simplified simulation
scenario is able to serve the purpose of the study in illustrating the
model and the concept of traffic resilience, the simulation should be
better calibrated and the model should be further trained and validated
using traffic data from real road environments with the help of new
technologies such as computer vision and LiDAR techniques (Atev et al.,
2005; St-Aubin et al., 2015; Tarko et al., 2017). Slow moving vehicles
with different speeds may have different impacts on freeway safety, but
such impacts have not been extensively investigated in this study. A
sensitivity analysis for different speeds of slow moving vehicles can be
performed using the simulation software. In addition, environments
with other types of moving violations will be further investigated with
developments in simulation tools. Despite rear-end collisions are the
most common type of crashes on expressways, other collision types
need to be considered in future work. As being promising in crash
prediction, the approach using machine learning techniques in crash
risk analysis will be further explored with different advanced machine
learning methods applied and tested. The safety resilience of traffic will
be deeper explored both theoretically and practically. Finding proper
methods to quantify and identify indicators to explain the safety resilience
can be an interesting topic to study.},
}

@article{WEI2019324,
title = {Trajectory-based identification of critical instantaneous decision events at mixed-flow signalized intersections},
journal = {Accident Analysis \& Prevention},
volume = {123},
number = {nan},
pages = {324-335},
year = {2019},
author = {Yanning Wei and Keping Li and Keshuang Tang},
keywords = {Critical instantaneous decision events, Trajectory data, Permutation entropy, Cube searching algorithm, Mixed-flow intersections},
abstract = {Mixed-flow intersections are prevailing in many developing countries such as China and India. At mixed-flow intersections, there is no clear lane discipline or regular trajectories within the intersection, especially for the non-motorized traffic. This leads to more interactions and encounters between the motorized traffic and the non-motorized traffic. Hence, critical instantaneous decision events such as abrupt accelerating, decelerating, jerking, swerving, and swinging, may occur more frequently, which result in potential traffic conflicts and crashes. This study presents a methodology to identify critical instantaneous decision events at the mixed-flow signalized intersections, based on the entropy theory and high-resolution vehicle trajectory data. A three-dimensional cube searching algorithm is firstly proposed to extract general traffic events by examining the proximity between trajectories. A novel model incorporating vehicle kinematics and Permutation Entropy is then developed to identify critical events, by quantifying driving volatility based on the time-serial trajectory data. Next, 3, 349 vehicle trajectories and 805 bicycle trajectories with a resolution of 0.12 s collected at a signalized intersection in Shanghai are used to demonstrate the proposed method. Results show that the proposed method is capable of identifying critical instantaneous decision events, and tends to produce a higher identification ratio comparing with the conventional method solely based on kinematic thresholds. A sensitivity analysis is also conducted to investigate the effects of model parameters on the performance of the proposed method. The presented work could be applied for traffic safety assessment, real-time driving alert systems, and early diagnosis of risk-prone road users at mixed-flow intersections.},
institution = {},
annotation = {},
addendum = {},
}

@article{SCHLOGL2019136,
title = {Methodological considerations with data uncertainty in road safety analysis},
journal = {Accident Analysis \& Prevention},
volume = {130},
number = {nan},
pages = {136-150},
year = {2019},
author = {Matthias Schlögl and Rainer Stütz},
keywords = {Uncertainty, Road safety, Accident analysis, Linear referencing, GIS},
abstract = {The analysis of potential influencing factors that affect the likelihood of road accident occurrence has been of major interest for safety researchers throughout the recent decades. Even though steady methodological progresses were made over the years, several impediments pertaining to the statistical analysis of crash data remain. While issues related to methodological approaches have been subject to constructive discussion, uncertainties inherent to the most fundamental part of any analysis have been widely neglected: data. This paper scrutinizes data from various sources that are commonly used in road safety studies with respect to their actual suitability for applications in this area. Issues related to spatial and temporal aspects of data uncertainty are pointed out and their implications for road safety analysis are discussed in detail. These general methodological considerations are exemplary illustrated with data from Austria, providing suggestions and methods how to overcome these obstacles. Considering these aspects is of major importance for expediting further advances in road safety data analysis and thus for increasing road safety.},
institution = {Austrian Institute of Technology},
annotation = {Questions about Uncertainties in Data},
addendum = {},
}

@article{ALI2020105463,
title = {Understanding the discretionary lane-changing behaviour in the connected environment},
journal = {Accident Analysis \& Prevention},
volume = {137},
number = {nan},
pages = {105463},
year = {2020},
author = {Yasir Ali and Zuduo Zheng and Md. {Mazharul Haque} and Mehmet Yildirimoglu and Simon Washington},
keywords = {Lane changing, Connected vehicles, Driving simulator, Gap acceptance, Hazard-duration model},
abstract = {Discretionary lane-changing (DLC) is one of the complex driving manoeuvres that requires surrounding traffic information for efficient and safe manoeuvring. The connected environment not only provides such information but also increases situational awareness, which is useful for DLC decision-making. However, the literature is devoid of any concrete evidence of such impact of the connected environment on DLC decision-making. As such, this paper analyses the effects of the connected environment on DLC behaviour. Seventy-eight participants from a diverse background performed DLCs in randomised driving conditions using the CARRS-Q advanced driving simulator. These driving conditions are: baseline (without driving messages), connected environment with perfect communication (fully functioning and uninterrupted supply of driving messages), and connected environment with communication delay (impaired communication). Various key driving behaviour indicators are analysed and compared using a linear mixed model. To analyse the effects of the connected environment on DLC decision-making, two Generalised Estimation Equation (GEE) models are developed for gap acceptance and DLC duration. In addition, a Weibull accelerated failure time hazard-based duration model is developed to investigate the impact of the connected environment on safety associated with DLC manoeuvres. We find that drivers in the connected environment have a larger spacing, larger lead and lag gaps, a longer DLC duration, and a lower acceleration noise compared to the baseline condition. The GEE model on gap acceptance reveals that drivers tend to select relatively bigger gap sizes when the connected environment offers them the subsequent gap information. Similarly, the GEE model for DLC duration suggests that the connected environment increases DLC durations by 2.22 s and 2.11 s in perfect communication and communication delay driving conditions, respectively. Finally, the hazard-based duration model provides insights into the probability of avoiding a lane-changing collision, and indicates that the probability of a lane-changing collision is less in the connected environment driving conditions than in the baseline scenario. Overall, the connected environment improves the DLC driving behaviour and enhances traffic safety.},
institution = {},
annotation = {},
addendum = {},
}

@article{LIANG2019105,
title = {Prediction of drowsiness events in night shift workers during morning driving},
journal = {Accident Analysis \& Prevention},
volume = {126},
number = {nan},
pages = {105-114},
year = {2019},
author = {Yulan Liang and William J. Horrey and Mark E. Howard and Michael L. Lee and Clare Anderson and Michael S. Shreeve and Conor S. O’Brien and Charles A. Czeisler},
keywords = {Drowsy driving, Fatigue, Predictive models, Electroencephalogram (EEG), Driving performance, Infrared oculograph},
abstract = {The morning commute home is an especially vulnerable time for workers engaged in night shift work due to the heightened risk of experiencing drowsy driving. One strategy to manage this risk is to monitor the driver’s state in real time using an in vehicle monitoring system and to alert drivers when they are becoming sleepy. The primary objective of this study is to build and evaluate predictive models for drowsiness events occurring in morning drives using a variety of physiological and performance data gathered under a real driving scenario. We used data collected from 16 night shift workers who drove an instrumented vehicle for approximately two hours on a test track on two occasions: after a night shift and after a night of rest. Drowsiness was defined by two outcome events: performance degradation (Lane-Crossing models) and electroencephalogram (EEG) characterized sleep episodes (Microsleep Models). For each outcome, we assessed the accuracy of sets of predictors, including or not including a driver factor, eyelid measures, and driving performance measures. We also compared the predictions using different time intervals relative to the events (e.g., 1-min prior to the event through 10-min prior). By examining the Area Under the receiver operating characteristic Curve (AUC), accuracy, sensitivity, and specificity of the predictive models, the results showed that the inclusion of an individual driver factor improved AUC and prediction accuracy for both outcomes. Eyelid measures improved the prediction for the Lane-Crossing models, but not for Microsleep models. Prediction performance was not changed by adding driving performance predictors or by increasing the time to the event for either outcome. The best models for both measures of drowsiness were those considering driver individual differences and eyelid measures, suggesting that these indicators should be strongly considered when predicting drowsiness events. The results of this paper can benefit the development of real-time drowsiness detection and help to manage drowsiness to avoid related motor-vehicle crashes and loss.},
institution = {},
annotation = {Not ML, not our data.},
addendum = {},
}

@article{SHI2019170,
title = {A feature learning approach based on XGBoost for driving assessment and risk prediction},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {170-179},
year = {2019},
author = {Xiupeng Shi and Yiik Diew Wong and Michael Zhi-Feng Li and Chandrasekar Palanisamy and Chen Chai},
keywords = {Driving behaviour, Feature learning, XGBoost, Risk prediction},
abstract = {This study designs a framework of feature extraction and selection, to assess vehicle driving and predict risk levels. The framework integrates learning-based feature selection, unsupervised risk rating, and imbalanced data resampling. For each vehicle, about 1300 driving behaviour features are extracted from trajectory data, which produce in-depth and multi-view measures on behaviours. To estimate the risk potentials of vehicles in driving, unsupervised data labelling is proposed. Based on extracted risk indicator features, vehicles are clustered into various groups labelled with graded risk levels. Data under-sampling of the safe group is performed to reduce the risk-safe class imbalance. Afterwards, the linkages between behaviour features and corresponding risk levels are built using XGBoost, and key features are identified according to feature importance ranking and recursive elimination. The risk levels of vehicles in driving are predicted based on key features selected. As a case study, NGSIM trajectory data are used in which four risk levels are clustered by Fuzzy C-means, 64 key behaviour features are identified, and an overall accuracy of 89\% is achieved for behaviour-based risk prediction. Findings show that this approach is effective and reliable to identify important features for driving assessment, and achieve an accurate prediction of risk levels.},
institution = {Nanyang U, Tongji U},
annotation = {Interesting for focus on ML, Not our dataset, but we could use it.},
addendum = {None},
}

@article{ZHOU2019105256,
title = {Analysis of commercial truck drivers’ potentially dangerous driving behaviors based on 11-month digital tachograph data and multilevel modeling approach},
journal = {Accident Analysis \& Prevention},
volume = {132},
number = {nan},
pages = {105256},
year = {2019},
author = {Tuqiang Zhou and Junyi Zhang},
keywords = {Truck driver, Digital tachograph data, Driving behavior, PCA, DBSCAN, Multilevel modeling, cluster analysis},
abstract = {This study analyzed the potentially dangerous driving behaviors of commercial truck drivers from both macro and micro perspectives. The analysis was based on digital tachograph data collected over an 11-month period and comprising 4373 trips made by 70 truck drivers. First, different types of truck drivers were identified using principal component analysis (PCA) and a density-based spatial clustering of applications with noise (DBSCAN) at the macro level. Then, a multilevel model was built to extract the variation properties of speeding behavior at the micro level. Results showed that 40\% of the truck drivers tended to drive in a substantially dangerous way and the explained variance proportion of potentially extremely dangerous truck drivers (79.76\%) was distinctly higher than that of other types of truck drivers (14.70\%˜34.17\%). This paper presents a systematic approach to extracting and examining information from a big data source of digital tachograph data. The derived findings make valuable contributions to the development of safety education programs, regulations, and proactive road safety countermeasures and management.},
institution = {Jiaotong U, Hiroshima U},
annotation = {Not the data we have.},
addendum = {The paper proposes an innovative approach to extracting useful
information about commercial truck driver behavior from widely
available big data sources. This study used eleven months of digital
tachograph data that comprised 4373 trips made by 70 truck drivers in
Japan. Results suggest that 40\% of truck drivers exhibit substantially
dangerous driving tendencies. The explanatory variables introduced in
this study accurately expressed the influence of unobserved conditions
and phenomena for potential extremely dangerous truck drivers,
especially in comparison with other types of truck drivers.
Although many factors may affect driving behavior, because of data
constraints, truck drivers’ personal attributes (e.g., age, gender, education)
and psychological conditions (e.g., upset, tired, angry) were
ignored, and GPS data in this research was only used for extracting OD
information. Furthermore, although the intuitive aspects of multilevel
modeling are appealing, many challenges remain to its practical application
and interpretation. Despite these limitations, this paper provides
a systematic approach to identifying potential risks among
different truck drivers that considers both macro and micro perspectives.
We suggest that future work focus on the following four aspects.
First, big data should be integrated with questionnaire survey data
about truck drivers’ personal characteristics and psychological factors.
Second, more spatial information could be derived from GPS data.
Third, effective data fusion approaches should be developed to support
the above data integration and maximize statistical and epidemiological
methods, deep learning techniques, and behavioral models.
Finally, the above efforts should be extrapolated to implement practical
safety improvements by developing effective decision support systems.},
}

@article{FORMOSA2020105429,
title = {Predicting real-time traffic conflicts using deep learning},
journal = {Accident Analysis \& Prevention},
volume = {136},
number = {nan},
pages = {105429},
year = {2020},
author = {Nicolette Formosa and Mohammed Quddus and Stephen Ison and Mohamed Abdel-Aty and Jinghui Yuan},
keywords = {Safety Surrogate Measures, traffic conflicts, data integration architecture, Regional–Convolution Neural Network (R-CNN), Deep Neural Network (DNN)},
abstract = {Recently, technologies for predicting traffic conflicts in real-time have been gaining momentum due to their proactive nature of application and the growing implementation of ADAS technology in intelligent vehicles. In ADAS, machine learning classifiers are utilised to predict potential traffic conflicts by analysing data from in-vehicle sensors. In most cases, a condition is classified as a traffic conflict when a safety surrogate (e.g. time-to-collision, TTC) crosses a pre-defined threshold. This approach, however, largely ignores other factors that influence traffic conflicts such as speed variance, traffic density, speed and weather conditions. Considering all these factors in detecting traffic conflicts is rather complex as it requires an integration and mining of heterodox data, the unavailability of traffic conflicts and conflict prediction models capable of extracting meaningful and accurate information in a timely manner. In addition, the model has to effectively handle large imbalanced data. To overcome these limitations, this paper presents a centralised digital architecture and employs a Deep Learning methodology to predict traffic conflicts. Highly disaggregated traffic data and in-vehicle sensors data from an instrumented vehicle are collected from a section of the UK M1 motorway to build the model. Traffic conflicts are identified by a Regional–Convolution Neural Network (R-CNN) model which detects lane markings and tracks vehicles from images captured by a single front-facing camera. This data is then integrated with traffic variables and calculated safety surrogate measures (SSMs) via a centralised digital architecture to develop a series of Deep Neural Network (DNN) models to predict these traffic conflicts. The results indicate that TTC, as expected, varies by speed, weather and traffic density and the best DNN model provides an accuracy of 94\% making it reliable to employ in ADAS technology as proactive safety management strategies. Furthermore, by exchanging this traffic conflict awareness data, connected vehicles (CVs) can mitigate the risk of traffic collisions.},
institution = {Loughborough U, U of Central Florida},
annotation = {Interesting, but not our data.

\vskip 0pt

Only talks about accuracy in the abstract, introduction, and conclusion, although does talk about 

\vskip 0pt

Prediction models for one roadway can't be applied to others.  (lots of studies, but not cited).

\vskip 12pt

Interestingly, gives Sensitivity, False Alarm Rate (FAR) and Precision as percentages, but Accuracy as a decimal.  },
addendum = {While the proposed DNN outperformed other machine learning
classifiers, there are some limitations in the study such as the lack of
detail in the data namely the weather conditions, drivers, road design
which can improve the performance of the DNN. These added variables
could be beneficial for the model to improve the prediction accuracy
further since they can characterise a traffic condition. Moreover, in this
work 50,000 data points were dealt with and by increasing the size of
the data set the predictability of these models is expected to increase.
Therefore, future work will include more testing especially in different
weather conditions, to further assess the performance of the model and
tune it accordingly as well as testing the predictive performance of the
DNN model on a validation model.},
}

@article{WANG201944,
title = {Exploring causes and effects of automated vehicle disengagement using statistical modeling and classification tree based on field test data},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {44-54},
year = {2019},
author = {Song Wang and Zhixia Li},
keywords = {Automated vehicles, Automated driving, Disengagement, Human factor, Transportation safety},
abstract = {Automated vehicles (AV) testing on the public roads is ongoing in several states in the US as well as in Europe and Asia. As long as the automated vehicle technology has not achieved full automation (Level 5), human drivers are still expected to take over the steering wheel and throttles when there is an automated vehicle disengagement. However, contributing factors and the mechanism about automated vehicle-initiated disengagement has not been quantitatively and comprehensively explored and investigated due to the lack of field test data. Besides, understanding human drivers’ perception and promptness of reaction to the AV disengagement is essential to ensure safety transition between automated and manual driving. By harnessing California’s Autonomous Vehicle Disengagement Report Database, which includes the AV disengagement data from field tests in 2016–2017, this paper quantitatively investigated the AV disengagement using multiple statistical modeling approaches that involve statistical modeling and classification tree. Specifically, the paper identifies the contributing factors impacting human drivers’ promptness to AV disengagements, and quantitatively investigates the underlying causes to AV disengagements. Results indicate that current AV disengagement on public roads is dominated by causes due to a planning issue. The cause of an AV disengagement is significantly induced by lacking certain numbers of radar and LiDAR sensors installed on the automated vehicles. These thresholds of these sensors needed are revealed. Cause of disengagement and roadway characteristics significantly impact drivers’ take-over time when facing an AV disengagement. AV perception or control issue-based disengagement can significantly extend drivers’ perception-reaction time to take over the driving. The quantitative knowledge obtained ultimately facilitates revealing the mechanisms of the automated vehicle disengagements to ensure safe AV operations on public roads.},
institution = {U of Louisville},
annotation = {Not our data.},
addendum = {},
}

@article{JIANG2020105520,
title = {A long short-term memory-based framework for crash detection on freeways with traffic data of different temporal resolutions},
journal = {Accident Analysis \& Prevention},
volume = {141},
number = {nan},
pages = {105520},
year = {2020},
author = {Feifeng Jiang and Kwok Kit Richard Yuen and Eric Wai Ming Lee},
keywords = {Crash detection, Deep learning methods, Long short-term memory networks, Traffic condition, Different temporal resolutions},
abstract = {Traffic crash detection is a major component of intelligent transportation systems. It can explore inner relationships between traffic conditions and crash risk, prevent potential crashes, and improve road safety. However, there exist some limitations in current studies on crash detection: (1) The commonly used machine learning methods cannot simulate the evolving transitions of traffic conditions before crash occurrences; (2) Current models collected traffic data of only one temporal resolution, which cannot fully represent traffic trends in different time intervals. Therefore, this study proposes a Long short-term memory (LSTM) based framework considering traffic data of different temporal resolutions (LSTMDTR) for crash detection. LSTM is an effective deep learning method to capture the long-term dependency and dynamic transitions of pre-crash conditions. Three LSTM networks considering traffic data of different temporal resolutions are constructed, which can comprehensively indicate traffic variations in different time intervals. A fully-connected layer is used to combine the outputs of three LSTM networks, and a dropout layer is used to reduce overfitting and improve prediction performance. The LSTMDTR model is implemented on datasets of I880-N and I805-N in California, America. The results indicate that the LSTMDTR model can obtain satisfactory performance on crash detection, with the highest crash accuracy of 70.43 \%. LSTMDTR models constructed on one freeway can be transferred to other similar freeways, with 65.12 \% of crash accuracy on transferability. Compared with machine learning methods and LSTM models with one or two temporal resolutions, the LSTMDTR model has been validated to perform better on crash detection and transferability. A proper number of neurons in the LSTMDTR model should be determined in real applications considering acceptable detection performance and computation time. The dropout technique can reduce overfitting and improve the generalization ability of the LSTMDTR model, increasing crash accuracy from 64.49 \% to 70.43 \%.},
institution = {City University of Hong Kong},
annotation = {Interesting for taking temporal resolution into account.  Real-time applications?},
addendum = {The limitation of this study is that cases with very poor data quality
(e.g., no data recorded in more than one stations) are deleted in data
preprocessing. However, this kind of missing data accounts for a large
proportion of all cases. Future work needs to propose proper methods to
supplement these missing data and improve prediction performance.},
}

@article{SAHA2020105456,
title = {Application of the Poisson-Tweedie distribution in analyzing crash frequency data},
journal = {Accident Analysis \& Prevention},
volume = {137},
number = {nan},
pages = {105456},
year = {2020},
author = {Dibakar Saha and Priyanka Alluri and Eric Dumbaugh and Albert Gan},
keywords = {Traffic safety, Poisson-Tweedie distribution, Negative binomial model, Geometric Poisson model, Poisson inverse Gaussian model, Dispersion parameter},
abstract = {This paper describes a study that applies the Poisson-Tweedie distribution in developing crash frequency models. The Poisson-Tweedie distribution offers a unified framework to model overdispersed, underdispersed, zero-inflated, spatial, and longitudinal count data, as well as multiple response variables of similar or mixed types. The form of its variance function is simple, and can be specified as the mean added to the product of dispersion and mean raised to the power P. The flexibility of the Poisson-Tweedie distribution lies in the domain of P, which includes positive real number values. Special cases of the Poisson-Tweedie distribution models include the linear form of the negative binomial (NB1) model with P equal to 1.0, the geometric Poisson (GeoP) model with P equal to 1.5, the quadratic form of the negative binomial (NB2) model with P equal to 2.0, and the Poisson Inverse Gaussian (PIG) model with P equal to 3.0. A series of models were developed in this study using the Poisson-Tweedie distribution without any restrictions on the value of the power parameter as well as with specific values of the power parameter representing NB1, GeoP, NB2, and PIG models. The effects of fixed and varying dispersion parameters (i.e., dispersion as a function of covariates) on the variance and expected crash frequency estimates were also examined. Three years (2012–2014) of crash data from urban three-leg stop-controlled intersections and urban four-leg signalized intersections in the state of Florida were used to develop the models. The Poisson-Tweedie models or the GeoP models were found to perform better when the dispersion parameter was constant or fixed. With the varying dispersion parameter, the NB2 and PIG models were found to perform better, with both performing equally well. Also, the fixed dispersion parameter values were found to be smaller in the models with a higher value of the power parameter. The variation across the models in their estimates of weight factor, expected crash frequency, and potential for safety improvement of hazardous sites based on the empirical Bayes method was also discussed.},
institution = {Florida Atlantic U, Florida International U},
annotation = {Not ML},
addendum = {},
}

@article{KITA2020105514,
title = {Differences between males and females in the prediction of smartphone use while driving: Mindfulness and income},
journal = {Accident Analysis \& Prevention},
volume = {140},
number = {nan},
pages = {105514},
year = {2020},
author = {Erez Kita and Gil Luria},
keywords = {Mindfulness, Income, Biological sex, Using smartphones while driving, Young drivers},
abstract = {Introduction
This study examines the relationship between two variables–mindfulness and income–with regards to their relationship to the use of smartphones by young drivers, which has been known to increase the likelihood of car accidents, endangering young drivers and other road users. The study focuses on the relationship between these variables and the use of smartphones while driving, and how this relationship differs between males and females.
Method
The study sample included 221 young drivers who were legally permitted to drive without supervision. The subjects were first asked to complete questionnaires on mindfulness and income. Next, their smartphone use while driving was monitored over a one-month period. This study is unique as it used an objective smartphone monitoring application (rather than self-reporting) to count the number of times the young participants actually touched their smartphones while driving.
Results
The findings show that the effects of social and personal factors (i.e., income and mindfulness) on the use of smartphones while driving are significant for males but not for females.
Conclusions
Most studies that investigate differences between males and females with respect to safety focus on differences in the averages of safety-related variables (such as safety performance and outcomes). In the current study, however, we identified differences in relationships between variables and demonstrated that what predicts safety-related behavior in males may not be a good predictor for females.
Practical applications
Mindfulness and income can be used to identify male populations that are at risk of using smartphones while driving. Interventions that improve mindfulness can be used to reduce the use of smartphones by male drivers.},
institution = {U of Haifa},
annotation = {Not ML.  Small sample size.},
addendum = {},
}

@article{GUPTA2019163,
title = {Pedestrian's risk-based negotiation model for self-driving vehicles to get the right of way},
journal = {Accident Analysis \& Prevention},
volume = {124},
number = {nan},
pages = {163-173},
year = {2019},
author = {Surabhi Gupta and Maria Vasardani and Bharat Lohani and Stephan Winter},
keywords = {Negotiation, Self-driving vehicles, Vehicle–pedestrian interaction, Traffic flow, Pedestrian risk},
abstract = {Negotiations among drivers and pedestrians are common on roads, but it is still challenging for a self-driving vehicle to negotiate for its right of way with other human road users, especially pedestrians. Currently, the self-driving vehicles are programmed for conservative behavior, yielding to approaching pedestrians. Consequently, the future urban traffic will slow down significantly. In this paper, a conceptual model of vehicle–pedestrian negotiation is proposed. This model allows individual decision making of multiple vehicles and pedestrians, extending a prior negotiation model for a single vehicle and a single pedestrian. The possible negotiation opportunities for vehicles are modeled considering different risk-taking behaviors of pedestrians. Simulation results show an overall improvement in the waiting time of vehicles and thus in the intersection throughput, compared to conservative vehicle behavior. The simulation results show also that the benefit of reduced waiting times for vehicles comes at the cost of some waiting time for pedestrians. However, the observed pedestrian waiting times in this model are not more than the generally accepted waiting times reported in empirical studies.},
institution = {U of Melbourne, Indian Institute of Technology},
annotation = {Not our data.  Not ML.  Model for how autonomous vehicles },
addendum = {},
}

@article{ZIAKOPOULOS2020105323,
title = {A review of spatial approaches in road safety},
journal = {Accident Analysis \& Prevention},
volume = {135},
number = {nan},
pages = {105323},
year = {2020},
author = {Apostolos Ziakopoulos and George Yannis},
keywords = {Road safety, spatial analysis, crash analysis, study characteristics, areal units},
abstract = {Spatial analyses of crashes have been adopted in road safety for decades in order to determine how crashes are affected by neighboring locations, how the influence of parameters varies spatially and which locations warrant interventions more urgently. The aim of the present research is to critically review the existing literature on different spatial approaches through which researchers handle the dimension of space in its various aspects in their studies and analyses. Specifically, the use of different areal unit levels in spatial road safety studies is investigated, different modelling approaches are discussed, and the corresponding study design characteristics are summarized in respective tables including traffic, road environment and area parameters and spatial aggregation approaches. Developments in famous issues in spatial analysis such as the boundary problem, the modifiable areal unit problem and spatial proximity structures are also discussed. Studies focusing on spatially analyzing vulnerable road users are reviewed as well. Regarding spatial models, the application, advantages and disadvantages of various functional/econometric approaches, Bayesian models and machine learning methods are discussed. Based on the reviewed studies, present challenges and future research directions are determined.},
institution = {National Technical University of Athens},
annotation = {Interesting.  Essential.  This article will give me an overview of the vocabulary, techniques, and issues.},
addendum = {},
}

@article{ROCHA2019105269,
title = {A multivariate-based variable selection framework for clustering traffic conflicts in a brazilian freeway},
journal = {Accident Analysis \& Prevention},
volume = {132},
number = {nan},
pages = {105269},
year = {2019},
author = {Miriam Rocha and Michel Anzanello and Felipe Caleffi and Helena Cybis and Gabrielli Yamashita},
keywords = {Collision risk, Traffic conflicts, variable selection, Clustering, NLPCA, SOM},
abstract = {More than one million people die or suffer non-fatal injuries annually due to road accidents around the world. Understanding the causes that give rise to different types of conflict events, as well as their characteristics, can help researchers and traffic authorities to draw up strategies aimed at mitigating collision risks. This paper proposes a framework for grouping traffic conflicts relying on similar profiles and factors that contribute to conflict occurrence using self-organizing maps (SOM). In order to improve the quality of the formed groups, we developed a novel variable importance index relying on the outputs of the nonlinear principal component analysis (NLPCA) that intends to identify the most informative variables for grouping collision events. Such index guides a backward variable selection procedure in which less relevant variables are removed one-by-one; after each removal, the clustering quality is assessed via the Davies-Bouldin (DB) index. The proposed framework was applied to a real-time dataset collected from a Brazilian highway aimed at allocating traffic conflicts into groups presenting similar profiles. The selected variables suggest that lower average speeds, which are typically verified during congestion events, contribute to conflict occurrence. Higher variability on speed (denoted by high standard deviation, and speed’s coefficient of variation levels on that variable), which are also perceived in the assessed freeway near to congestion periods, also contribute to conflicts.},
institution = {Federal University of Rio Grade do Sul (Brazil), Federal Rural University of Semi-Arid (Brazil)},
annotation = {Not ML},
addendum = {Future research includes the application of supervised multivariate
techniques (e.g., k-Nearest Neighbor or Support Vector Machine) to
insert events into categories of conflict severity. The use of the parameters
derived from Partial Least Squares regression to build a new
variable importance index is also promising.},
}

@article{WANG2019160,
title = {Modeling when and where a secondary accident occurs},
journal = {Accident Analysis \& Prevention},
volume = {130},
number = {nan},
pages = {160-166},
year = {2019},
author = {Junhua Wang and Boya Liu and Ting Fu and Shuo Liu and Joshua Stipancic},
keywords = {Secondary accident, Spatiotemporal Gap, BP neural network, LSSVM, Incident management},
abstract = {The occurrence of secondary accidents leads to traffic congestion and road safety issues. Secondary accident prevention has become a major consideration in traffic incident management. This paper investigates the location and time of a potential secondary accident after the occurrence of an initial traffic accident. With accident data and traffic loop data collected over three years from California interstate freeways, a shock wave-based method was introduced to identify secondary accidents. A linear regression model and two machine learning algorithms, including a back-propagation neural network (BPNN) and a least squares support vector machine (LSSVM), were implemented to explore the distance and time gap between the initial and secondary accidents using inputs of crash severity, violation category, weather condition, tow away, road surface condition, lighting, parties involved, traffic volume, duration, and shock wave speed generated by the primary accident. From the results, the linear regression model was inadequate in describing the effect of most variables and its goodness-of-fit and accuracy in prediction was relatively poor. In the training programs, the BPNN and LSSVM demonstrated adequate goodness-of-fit, though the BPNN was superior with a higher CORR and lower MSE. The BPNN model also outperformed the LSSVM in time prediction, while both failed to provide adequate distance prediction. Therefore, the BPNN model could be used to forecast the time gap between initial and secondary accidents, which could be used by decision makers and incident management agencies to prevent or reduce secondary collisions.},
institution = {Tongji U, McGill U},
annotation = {Not our data, but interesting.  
\vskip 12pt
Takes into account crash severity, violation category, weather conditions, tow away, road surface conditions, lighting, parties involved (?), traffic volume, duration, and shock wave speed (?).  

\vskip 12pt

Got "accident data and traffic loop data collected over three years from California interstate freeways,'' but none of them are from California.  Data is 2010-2012, even though the paper is from 2019. (?)  

\vskip 0pt

Doesn't say where they got the weather report, unless it's in the SWITRS records.  },
addendum = {},
}

@article{HALL2019148,
title = {Adequacy of negative binomial models for managing safety on rural local roads},
journal = {Accident Analysis \& Prevention},
volume = {128},
number = {nan},
pages = {148-158},
year = {2019},
author = {Thomas Hall and Andrew P. Tarko},
keywords = {Rural local roads, Rural local intersections, Low-volume county roads, Low sample mean, Bivariate negative binomial model, Bivariate ordered probit model},
abstract = {Count models, such as negative binomial regression, are well-established statistical methods for analyzing road safety. Although count models are widely used for arterial roads, their application to rural local roads is sparse, partly due to the concern of possible estimation bias caused by low crash counts. This paper revisits the matter to further evaluate the suitability of negative binomial models for rural local roads with low crash frequencies, comparing the performance of the model to probabilistic regression (ordered probit) proposed in the past. The negative binomial model was estimated to predict crashes for rural local intersections and compared to predictions obtained from the ordered probit model. Bivariate versions of both models were applied to improve model efficiency by incorporating correlation between two severity outcomes, fatal/injury (FI) and property damage only (PDO) crashes. The estimated models included several significant variables with intuitive signs. These results are discussed in the paper to support the claim that both models are adequate. Furthermore, the cumulative sums of the model-predicted and observed crashes conditioned on the estimated effects were compared to detect any systematic bias in the results. Although both models showed similar performance and no obvious biases could be detected, the negative binomial model seemed to behave slightly better than the ordered probit model, demonstrating the model’s suitability in the analyzed case. The results point to the possibility of applying the Highway Safety Manual methodology to lower-volume county roads with focus shifted from individual high-crash locations to safety-deficient road features present at multiple locations.},
institution = {Purdue U},
annotation = {Not ML},
addendum = {Future research should compare safety effects estimated on rural
local roads with those effects on well-studied rural arterial roads. If the
similarity of effects on both road types are confirmed, then this could
allow transferring at least part of the knowledge of highway safety
factors (for example, crash modification factors) to rural local roads to
facilitate the development of road screening and safety improvement
measures for these roads.
While the current study focused on rural local intersections, future
research should extend further to cover rural local segments. A similar
statistical methodology may be used in examining the effect of segmentlevel
variables related to the road curvature, driveways and access
points, and the presence of roadside obstructions, among other factors.
Segments may also offer further opportunities for safety improvements
through the alignment, cross-sectional, and roadside components.},
}

@article{GUO2019164,
title = {Modeling correlation and heterogeneity in crash rates by collision types using full bayesian random parameters multivariate Tobit model},
journal = {Accident Analysis \& Prevention},
volume = {128},
number = {nan},
pages = {164-174},
year = {2019},
author = {Yanyong Guo and Zhibin Li and Pan Liu and Yao Wu},
keywords = {Crash rates, Collision types, Multivariate Tobit model, Random parameters, Full bayesian estimation},
abstract = {Crashes present different collision types. There usually exist unobserved risk factors which could jointly affect crash rates of different types, resulting in correlation and heterogeneity issues across observations. The primary objective of the study is to propose a novel random parameters multivariate Tobit (RPMV-Tobit) model for evaluating risk factors on crash rates of different collision types. Crash data from 367 freeway diverge areas in a three-year period were obtained for modeling. Three major types of collisions including rear-end, sideswipe, and angle collisions were considered. The RPMV-Tobit model was structured to simultaneously accommodate correlations between crash rates across collision types and unobserved heterogeneity across observations. The RPMV-Tobit model was compared with a multivariate Tobit (MV-Tobit) model, a random effect multivariate Tobit (REMV-Tobit) model, and independent univariate Tobit (IU-Tobit) models under the Bayesian framework. The results showed that MV-Tobit model outperforms the IU-Tobit models on fitting crash rates, indicating that accounting for the correlation between crash types can improve model fit. The RPMV-Tobit model and REMV-Tobit model perform better than the MV-Tobit model, suggesting that accounting for the unobserved heterogeneous can further improve model fit. The improvement of model performance with the RPMV-Tobit model is higher than that with the REMV-Tobit model. The impacts of each risk factor on crash rates were estimated and some differences were found across different collision types. The lane-balanced design, number of lanes on mainline, speed limit, and speed difference present significant heterogeneous effects on crash rates. Findings suggest that the RPMV-Tobit model is a superior approach for comprehensive crash rates modeling and traffic safety evaluation purposes.},
institution = {Southeast U (Nanjing), U of British Columbia},
annotation = {Data from 367 freeway exits.  Not ML},
addendum = {The analysis suggests the considerable potential of the proposed
model in crash rates analysis at freeway diverge areas. Although some
findings regarding collision types were obtained, there are some limitations
to this study. First, research efforts still need to be conducted
with crash data collected from other states or areas to validate the results
of this paper before the results can be used to direct the exit ramp
designs. Second, this study did not give enough insight into occurrence
mechanism for different crashes. Rear-end crashes could be related to
abrupt deceleration at diverge bottlenecks, and sideswipe/angle crashes
could be caused by intense lane changes. As such, high-resolution traffic
data from loop detectors on freeway mainlines and ramps could be
collected to develop the real time crash risk prediction models in future
study. Third, the insignificant variables that excluded in the final
models can introduce omitted variable bias, which should be considered
by optimizing the statistical modeling frameworks. There are
several areas of further research that can be investigated to improve the
current study. First, due to the limited access to the crash severity, this
paper did not incorporate injury-severity in the developed models. An
extension of the current study can examine the injury-severity rates
across collision types. This will provide new insights regarding the injury-
severity mechanism across different collision types. Second, this
study did not consider the temporal and spatial correlation in crash
rates, further study could be conducted to extend the current model to
accommodate the temporal and spatial effect. Moreover, further research
efforts could also be made to compare the risk factors with crash
frequency and that with crash rates. Last but not least, future study can
further decompose the Tobit coefficients to the effect of the parameters
on the overall rates, and on the probability of an observation being in
the zero-state. They will help with the model parameters’ inferences.},
}

@article{ALGHUSON2019105300,
title = {Toward an integrated traffic law enforcement and network management in connected vehicle environment: Conceptual model and survey study of public acceptance},
journal = {Accident Analysis \& Prevention},
volume = {133},
number = {nan},
pages = {105300},
year = {2019},
author = {Moahd Alghuson and Khaled Abdelghany and Ahmed Hassan},
keywords = {Traffic law enforcement, Transportation demand management, Connected vehicle, Driver performance monitoring},
abstract = {The increasing number of traffic accidents and their associated traffic congestion have prompted the development of innovative technologies to curb such problems. This paper proposes a novel score-based traffic law-enforcement and network management system (SLEM) that is based on connected vehicles (CV) technology. SLEM assigns a score to each driver which reflects her/his driving performance and compliance with traffic laws. The proposed system adopts a rewarding mechanism that rewards high-performing drivers and penalizes low-performing drivers who fail to obey the laws. The reward mechanism is in the form of a route guidance strategy that restricts low-score drivers from accessing certain roadway sections and time periods that are strategically selected in order to achieve an optimal traffic pattern in the network in which high-score drivers experience less congestion and a higher level of safety. A nationwide survey study was conducted to measure public acceptance of the proposed system. Another survey targeted a focused group of traffic operation and safety professionals. Based on the results of these surveys, a set of logistic regression models were developed to examine the sensitivity of public acceptance to policy and behavioral variables. The results showed that about 65.7 percent of the public and about 60.0 percent of professionals who participated in this study support the real-world implementation of SLEM.},
institution = {Southern Methodist U, U of Tabuk, Cairo U},
annotation = {Creepy law enforcement monitoring.},
addendum = {},
}

@article{ALREFAIE2019180,
title = {In a heart beat: Using driver’s physiological changes to determine the quality of a takeover in highly automated vehicles},
journal = {Accident Analysis \& Prevention},
volume = {131},
number = {nan},
pages = {180-190},
year = {2019},
author = {Mohamed Taher Alrefaie and Stever Summerskill and Thomas W Jackon},
keywords = {Physiological data, Highly automated driving, Take-over, Driver performance, Heart rate, Pupil diameter, Autonomous vehicle, Accident prevention},
abstract = {Developing conditionally automated driving systems is on the rise. Vehicles with full longitudinal and latitudinal control will allow drivers to engage in secondary tasks without monitoring the roadway, but users may be required to resume vehicle control to handle critical hazards. The loss of driver’s situational awareness increases the potential for accidents. Thus, the automated systems need to estimate the driver’s ability to resume control of the driving task. The aim of this study was to assess the physiological behaviour (heart rate and pupil diameter) of drivers. The assessment was performed during two naturalistic secondary tasks. The tasks were the email and the twenty questions task in addition to a control group that did not perform any tasks. The study aimed at finding possible correlations between the driver’s physiological data and their responses to a takeover request. A driving simulator study was used to collect data from a total of 33 participants in a repeated measures design to examine the physiological changes during driving and to measure their takeover quality and response time. Secondary tasks induced changes on physiological measures and a small influence on response time. However, there was a strong observed correlation between the physiological measures and response time. Takeover quality in this study was assessed using two new performance measures called PerSpeed and PerAngle. They are identified as the mean percentage change of vehicle’s speed and heading angle starting from a take-over request time. Using linear mixed models, there was a strong interaction between task, heart rate and pupil diameter and PerSpeed, PerAngle and response time. This, in turn, provided a measurable understanding of a driver’s future responses to the automated system based on the driver’s physiological changes to allow better decision making. The present findings of this study emphasised the possibility of building a driver mental state model and prediction system to determine the quality of the driver's responses in a highly automated vehicle. Such results will reduce accidents and enhance the driver’s experience in highly automated vehicles.},
institution = {Loughborough U},
annotation = {Not our data.},
addendum = {As identified through the literature review of this study, there are
some factors affecting response time and quality such as fatigue (Driver,
2014), age (Körber et al., 2016), traffic density (Christian Gold et al.,
2016), weather conditions (Louw et al., 2016) and driving experience
(Larsson et al., 2014). Those variables were not taken into consideration
due to the limitations of the study; however, it should be considered
for future work. Additionally, future work will need to recruit
different age groups which was identified by others as a critical variable
in driver’s performance in highly automated driving
Finally, the study acknowledges the limited effort placed on comparing
PerSpeed and PerAngle with other measures that were surveyed
and introduced in Radlmayr's et al., (2019) comprehensive study. The
comparison between TOPS model and their affiliated vehicle-based
performance measure would be a great contribution to the research of
highly automated vehicles.},
}

@article{PARSA2019202,
title = {Real-time accident detection: Coping with imbalanced data},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {202-210},
year = {2019},
author = {Amir Bahador Parsa and Homa Taghipour and Sybil Derrible and Abolfazl (Kouros) Mohammadian},
keywords = {Accident detection, Real-time data, Probabilistic neural network, Support vector machine, Machine learning},
abstract = {Detecting accidents is of great importance since they often impose significant delay and inconvenience to road users. This study compares the performance of two popular machine learning models, Support Vector Machine (SVM) and Probabilistic Neural Network (PNN), to detect the occurrence of accidents on the Eisenhower expressway in Chicago. Accordingly, since the detection of accidents should be as rapid as possible, seven models are trained and tested for each machine learning technique, using traffic condition data from 1 to 7 min after the actual occurrence. The main sources of data used in this study consist of weather condition, accident, and loop detector data. Furthermore, to overcome the problem of imbalanced data (i.e., underrepresentation of accidents in the dataset), the Synthetic Minority Oversampling TEchnique (SMOTE) is used. The results show that although SVM achieves overall higher accuracy, PNN outperforms SVM regarding the Detection Rate (DR) (i.e., percentage of correct accident detections). In addition, while both models perform best at 5 min after the occurrence of accidents, models trained at 3 or 4 min after the occurrence of an accident detect accidents more rapidly while performing reasonably well. Lastly, a sensitivity analysis of PNN for Time-To-Detection (TTD) reveals that the speed difference between upstream and downstream of accidents location is particularly significant to detect the occurrence of accidents.},
institution = {U of Illinois at Chicago},
annotation = {Not prediction, but identification from real-time data.  Also not severity of crash, but just occurrence of a crash.  Interesting for discussion of techniques for imbalanced data. },
addendum = {When attempting to detect accident occurrence, the number of accidents
in a dataset tends to be small, and therefore most studies must
cope with highly imbalanced data. To further improve model performance,
if available, more spatiotemporal data could be used. Finally, as
future work, the performance of deep learning models, such as
Recurrent Neural Network (RNN) and Convolutional Neural Network
(CNN), could be investigated, especially when used alongside techniques
to deal with imbalanced data and that create more data such as
SMOTE.},
}

@article{KHATTAK2019151,
title = {Crash severity effects of adaptive signal control technology: An empirical assessment with insights from Pennsylvania and Virginia},
journal = {Accident Analysis \& Prevention},
volume = {124},
number = {nan},
pages = {151-162},
year = {2019},
author = {Zulqarnain H. Khattak and Michael D. Fontaine and Brian L. Smith and Jiaqi Ma},
keywords = {Adaptive signal control technology crashes, Injury severity, Intelligent transportation systems, Safety, Spatial transferability, Random parameters ordered probit models},
abstract = {Adaptive signal control technology (ASCT) is an intelligent transportation systems (ITS) technology that optimizes signal timings in real time to improve corridor flow. While a few past studies have examined the impact of ASCT on crash frequency, little is known about its effect on injury severity outcomes. Similarly, the impact of different types of ASCTs deployed across different states is also uncertain. This paper therefore, used ordered probit models with random parameters to estimate the injury severity outcomes resulting from ASCT deployment across Pennsylvania and Virginia. Two disparate systems deployed across the two different states were analyzed to assess whether they had similar impacts on injury severity, although signal timings are optimized using different algorithms by both systems. The estimation results revealed that both ASCT systems were associated with reductions in injury severity levels. Marginal effects showed that Type A ASCT systems reduced the propensity of severe plus moderate and minor injury crashes by 11.70\% and 10.36\% while type B ASCT reduced the propensity of severe plus moderate and minor injury crashes by 4.39\% and 6.92\%. Similarly, the ASCTs deployed across the two states were also observed to reduce injury severities. The combined best fit model also revealed a similar trend towards reductions in severe plus moderate and minor injury crashes by 5.24\% and 9.91\%. This model performed well on validation data with a low forecast error of 0.301 and was also observed to be spatially transferable. These results encourage the consideration of ASCT deployments at intersections with high crash severities and have practical implications for aiding agencies in making future deployment decisions about ASCT.},
institution = {UVA, U of Cincinatti},
annotation = {Not ML},
addendum = {Furthermore, the use of random parameter logit model with heterogeneity
in means and variance may help in improving the prediction
power of the severe plus moderate injury category at the cost of neglecting
the ordinal nature of severities. It may also make sense to try
machine learning algorithms such (K-Nearest Neighbor Classifier and
Random Forest) instead of discrete choice models, which could yield
better prediction power for disaggregate severity levels since they don’t
rely on making assumptions about the functional form of the data and
require fewer parameters to tune.
Since the main objective of this paper was to perform exploratory
analysis of ASCT’s impact on signalized intersection crash severity,
crash frequency and individual crash type models were not considered
in this research. Another reason was that the authors have already
developed crash modification factors for ASCT (Khattak et al., 2017a)
and considered those to be more useful to both practitioners and researchers.
However, an interesting future research direction would be
to examine how the results of crash frequency and individual crash type
models compare with the crash severities presented in this paper and
the CMFs developed by the authors. The optimization algorithms vary
across the ASCT systems and may provide differing benefits thus, future
studies could also look at crash severity effects of other ASCT systems as
opposed to the two systems analyzed in this research and draw a
comparison. Likewise, the emergence of automated traffic signal performance
measurement systems provides an additional technology that
could be compared against ASCT. With the development of connected
and automated vehicles (CAV), CAV-enabled signal controls may also
be analyzed in the future to see whether they provide any additional
safety benefits compared to the ASCT systems analyzed in this research.
Since crash trends vary across states, data from additional states across
the United States can also provide significant insights about the crash
severity effects of ASCTs. Another promising research direction could
be to analyze the different econometric models and machine learning
algorithms in order to see which modeling approach could provide
better prediction accuracy with the severe plus moderate injury category,
since that category had the lowest number of observations.},
}

@article{PARK2019230,
title = {A vehicle speed harmonization strategy for minimizing inter-vehicle crash risks},
journal = {Accident Analysis \& Prevention},
volume = {128},
number = {nan},
pages = {230-239},
year = {2019},
author = {Hyunjin Park and Cheol Oh},
keywords = {Risk estimation, Speed control, Risk map, Risk minimization, Vehicle trajectory data, Reinforcement Learning},
abstract = {Recent technological advancements have facilitated the implementation of speed harmonization based on connected and automated vehicles (CAV) to prevent crashes on the road. In addition, trajectory-level vehicle controls are receiving substantial attention as sensors, wireless communications, and control systems are rapidly advancing. This study proposes a novel vehicle speed control strategy to minimize inter-vehicle crash risks in automated driving environments. The proposed methodology consists of the following three components: a risk estimation module, a risk map construction module, and a vehicle speed control module. The essence of the proposed strategy is to adjust the subject vehicle speed based on an analysis of the interactions among a subject vehicle and the surrounding vehicles. Crash risks are quantified by a fault tree analysis (FTA) method to integrate the crash occurrence potential and crash severity at every time step. A crash risk map is then constructed by projecting the integrated risk of the subject vehicle into a two-dimensional space composed of relative speed and relative spacing data. Next, the vehicle speed is continuously controlled to reach the target speed using risk map analysis to prevent a crash. The performance of the proposed methodology is evaluated by a VISSIM simulator with various traffic congestion levels and market penetration rates (MPR) of controlled vehicles. For example, an approximate 50\% reduction rate of the crash potential was achievable without a loss of the operational performance of the traffic stream when all vehicles were controlled by the proposed methodology under the level of service (LOS) C conditions. This study is meaningful in that vehicle speed control is performed for the purpose of speed harmonization in a traffic stream based on a comprehensive analysis of inter-vehicle risks. It is expected that the outcome of this study will be valuable for supporting the development of vehicle control systems for preventing crashes in automated driving environments.},
institution = {Korea Expressway Corporation Institute, Hanyang U},
annotation = {Controlling the speed of vehicles in traffic to keep spacing.  },
addendum = {Although useful insights were derived from this study, further research
needs to be conducted to achieve results with greater reliability.
First, there is an opportunity to improve the risk estimation method.
Various contributing factors affecting inter-vehicle risks need to be
considered when estimating the risk, including adverse weather and
road geometric conditions in addition to the vehicle performance.
Second, more effective and intelligent techniques for obtaining the
target speed should be studied. For example, machine learning techniques
that have received much attention recently should be applied
and investigated to improve the performance. One feasible alternative
is the design of an artificial intelligence controller based on reinforcement
learning, which the authors have been working on as a further
study. Third, there should be an attempt to obtain the target speed to
address multiple other objectives, including the operational efficiency
and the environmental impacts, rather than just focusing on the safety.
This is because these three objectives are fundamentally determined by
individual vehicle maneuverings. Finally, more systematic simulation
calibration and validation need to be conducted with a larger vehicle
trajectory dataset. Various traffic conditions and vehicle types should
also be taken into consideration in comparing the actual data and the
simulated data.},
}

@article{LI2019143,
title = {Effects of an in-vehicle eco-safe driving system on drivers’ glance behaviour},
journal = {Accident Analysis \& Prevention},
volume = {122},
number = {nan},
pages = {143-152},
year = {2019},
author = {Xiaomeng Li and Atiyeh Vaezipour and Andry Rakotonirainy and Sebastien Demmel},
keywords = {Eco-safe driving, In-vehicle HMI, Glance behaviour, Driver distraction, Traffic situation},
abstract = {We have designed a new in-vehicle eco-safe driving system and shown its effectiveness in prompting drivers to execute a fuel-saving and safe driving style (Vaezipour et al., 2018, submitted for publication). However, the system could also bring potential negative outcomes, i.e. driver distraction. This simulator study investigated drivers’ glance behaviours as indicators of driver distraction when using our Eco-Safe Human-Machine-Interface (HMI). Four types of eco-safe information display conditions (baseline, advice only, feedback only, both advice and feedback) were tested on different traffic situations with varied road traffic complexity. Results showed that the eco-safe HMI system did not cause visual distraction. In contrast, the advice only or feedback only information improved forward gazing on the roadway. In addition, drivers tended to adapt their visual scanning strategies according to the traffic situations. In the car-following situation they paid longer glances to the forward roadway, while in the intersections they spent more time to look at the HMI system. The findings indicated that our eco-safe driving system improved drivers’ eco-safe behaviours and meanwhile enhanced their visual attention on road while no evidence showed that drivers were distracted by it.},
institution = {Queensland U of Technology, U of Queensland},
annotation = {Not ML.  Not our data.},
addendum = {},
}

@article{HUANG2020105392,
title = {Highway crash detection and risk estimation using deep learning},
journal = {Accident Analysis \& Prevention},
volume = {135},
number = {nan},
pages = {105392},
year = {2020},
author = {Tingting Huang and Shuo Wang and Anuj Sharma},
keywords = {Crash detection, Crash prediction, Deep learning},
abstract = {Crash Detection is essential in providing timely information to traffic management centers and the public to reduce its adverse effects. Prediction of crash risk is vital for avoiding secondary crashes and safeguarding highway traffic. For many years, researchers have explored several techniques for early and precise detection of crashes to aid in traffic incident management. With recent advancements in data collection techniques, abundant real-time traffic data is available for use. Big data infrastructure and machine learning algorithms can utilize this data to provide suitable solutions for the highway traffic safety system. This paper explores the feasibility of using deep learning models to detect crash occurrence and predict crash risk. Volume, Speed and Sensor Occupancy data collected from roadside radar sensors along Interstate 235 in Des Moines, IA is used for this study. This real-world traffic data is used to design feature set for the deep learning models for crash detection and crash risk prediction. The results show that a deep model has better crash detection performance and similar crash prediction performance than state of the art shallow models. Additionally, a sensitivity analysis was conducted for crash risk prediction using data 1-minute, 5-minutes and 10-minutes prior to crash occurrence. It was observed that is hard to predict the crash risk of a traffic condition, 10 min prior to a crash.},
institution = {Iowa State U},
annotation = {Not our data.  Radar sensors},
addendum = {},
}

@article{WEN2019105249,
title = {Bayesian spatial-temporal model for the main and interaction effects of roadway and weather characteristics on freeway crash incidence},
journal = {Accident Analysis \& Prevention},
volume = {132},
number = {nan},
pages = {105249},
year = {2019},
author = {Huiying Wen and Xuan Zhang and Qiang Zeng and N.N. Sze},
keywords = {Freeway safety, Roadway alignment, Weather condition, Interaction effect, Spatio-Temporal model},
abstract = {This study attempts to examine the main and interaction effects of roadway and weather conditions on crash incidence, using the comprehensive crash, traffic and weather data from the Kaiyang Freeway in China in 2014. The dependent variable is monthly crash count on a roadway segment (with homogeneous horizontal and vertical profiles). A Bayesian spatio-temporal model is proposed to measure the association between crash frequency and possible risk factors including traffic composition, presence of curve and slope, weather conditions, and their interactions. The proposed model can also accommodate the unstructured random effect, and spatio-temporal correlation and interactions. Results of parameter estimation indicate that the interactions between wind speed and slope, between precipitation and curve, and between visibility and slope are significantly correlated to the increase in the freeway crash risk, while the interaction between precipitation and slope is significantly correlated to the reduction in the freeway crash risk, respectively. These findings are indicative of the design and implementation of real-time traffic management and control measures, e.g. variable message sign, that could mitigate the crash risk under the adverse weather conditions.},
institution = {South China U of Technology, Hong Kong Polytechnic U},
annotation = {Not ML},
addendum = {Yet, the effects of only two roadway factors on the freeway crash
risk are explored in current study. It would be worth exploring the effects
of other geometric design characteristics, e.g., number of lanes,
lane width, and shoulder width, and their interactions with the weather
conditions, on the crash risk, when the comprehensive traffic and crash
data of a bigger freeway network are available in the extended study.
Methodological-wise, it is a common approach to examine the interaction
effects on the association by adding the corresponding interaction
terms into the link function of regression. Yet, it is worth exploring
the viability of other alternate approaches, e.g., machine learning
techniques (Zeng et al., 2016), to reveal the interaction effects when
more comprehensive traffic, driver and weather data are available in
future study. Additionally, a random-parameter model can be set out to
capture the heterogeneous effects of the observed factors on the association
(Mannering et al., 2016).},
}

@article{WANG2019105320,
title = {Crash prediction based on traffic platoon characteristics using floating car trajectory data and the machine learning approach},
journal = {Accident Analysis \& Prevention},
volume = {133},
number = {nan},
pages = {105320},
year = {2019},
author = {Junhua Wang and Tianyang Luo and Ting Fu},
keywords = {Urban expressway, Floating car trajectory, Traffic platoon, Crash propensity prediction, Binary logistic regression, Support vector machine},
abstract = {Predicting crash propensity helps study safety on urban expressways in order to implement countermeasures and make improvements. It also helps identify and prevent crashes before they happen. However, collecting real-time wide-coverage traffic information for crash prediction has been challenging. More importantly, previous studies have failed to consider the characteristics of the traffic platoon (vehicle group) that the crash vehicle belongs to before the crash occurs. This paper aims to model crash propensity based on traffic platoon characteristics collected by the floating car method, which provides a time-efficient and reliable solution to collecting traffic information. Crash and floating car data are collected from the Middle Ring Expressway in Shanghai, China. Both the binary logistic model and the support vector machine are applied. A data preparation method, involving crash data filtering, floating car data filtering and data matching on the road network, is introduced for the safety analysis purpose. Results suggest that the traffic platoon information collected from floating cars accompanied works reasonably in predicting crashes on expressways. The support vector machine, with an overall accuracy of 85\%, outperformed the binary logistic model which had an overall accuracy of 60\%. Results further suggest the application of floating car technologies and the support vector machine in real-time crash prediction. Despite this, the study also concludes the merits of the binary logistic model over the support vector machine model in explaining the impact of different factors that contribute to crash occurrences.},
institution = {Tongji U, U of Waterloo},
annotation = {Not our data.  Traffic platoon is the group of vehicles the crash vehicle belongs to before the crash.},
addendum = {For future work, the models
will be tested and improved with data from a large number of expressway
environments. Crash prediction at expressway ramps should
be further explored using different methods. Other urban road environments
should also be investigated. Real-time crash prediction
using live floating car data will also be tested.},
}

@article{SOLEIMANI201965,
title = {A Comprehensive Railroad-Highway Grade Crossing Consolidation Model: A Machine Learning Approach},
journal = {Accident Analysis \& Prevention},
volume = {128},
number = {nan},
pages = {65-77},
year = {2019},
author = {Samira Soleimani and Saleh R. Mousa and Julius Codjoe and Michael Leitner},
keywords = {Highway-Rail Grade Crossing Consolidation, Closure Rating Formula, Safety, XGboost, Machine Learning},
abstract = {In the United States, there are approximately 212,000 highway-rail grade crossings, some of which experience vehicle-train incidents that often cause a massive financial burden, loss of life, and injury. In 2017, there were 2,108 highway-rail incidents resulting in 827 injuries and 307 fatalities nationwide. To eliminate collision risks, crossing grade separation and active alarm improvement are commonly used. Moreover, crossing closures are considered to be the most effective safety improvement program. While it may be very difficult, and in some cases impossible to close crossings, there are some incentive programs that facilitate the closure process. One of these programs is a working consolidation model that aims to determine crossing closure suitability. Using details of highway-rail grade crossings in the United States and applying an eXtreme Gradient Boosting (XGboost) algorithm, this paper proposes a data-driven consolidation model that takes into consideration a number of engineering variables. The results indicated an overall accuracy of 0.991 for the proposed model. In addition, the developed XGboost consolidation model reported the relative importance of the variables input to the model, offering an in-depth understanding of the model’s behavior. Finally, for the practical implementation of the model, a simplified version containing fewer variables was developed. A sensitivity analysis was performed considering the aggregate gain and the different correlation threshold values between variables. This analysis developed a simplified model utilizing 14 variables, with aggregated gain values of 75\% and a correlation threshold of 0.9 which would perform similarly to the full model. Based on this model, 62\% of current highway-rail grade crossings should be closed.},
institution = {LSU},
annotation = {Interesting.  Thorough analysis.},
addendum = {None},
}

@article{GIUMMARRA2020105333,
title = {A systematic review of the association between fault or blame-related attributions and procedures after transport injury and health and work-related outcomes},
journal = {Accident Analysis \& Prevention},
volume = {135},
number = {nan},
pages = {105333},
year = {2020},
author = {Melita J. Giummarra and Georgina Lau and Genevieve Grant and Belinda J. Gabbe},
keywords = {Fault, Recovery, Road trauma, Transport injury, Pain, Mental health, PTSD, Depression, Anxiety},
abstract = {Attributions of fault are often associated with worse injury outcomes; however, the consistency and magnitude of these impacts is not known. This review examined the prognostic role of fault on health, mental health, pain and work outcomes after transport injury. A systematic search of five electronic databases (Medline, Embase, CINAHL, PsycINFO, Cochrane Library) yielded 16,324 records published between 2000 and January 2018. Eligibility criteria were: adult transport injury survivors; prospective design; multivariable analysis; fault-related factor analysed; pain, mental health, general health or work-related outcome. Citations (n = 10,558, excluding duplicates) and full text articles (n = 555) were screened manually (Reviewer 1), and using concurrent machine learning and text mining (Reviewer 2; using Abstrackr, WordStat and QDA miner). Data from 55 papers that met all inclusion criteria were extracted, papers were evaluated for risk of bias using the QUIPS tool, and overall level of evidence was assessed using the GRADE tool. There were six main fault-related factors classified as: fault or responsibility, fault-based compensation, lawyer involvement or litigation, blame or guilt, road user or position in vehicle, and impact direction. Overall there were inconsistent associations between fault and transport injury outcomes, and 60\% of papers had high risk of bias. There was moderate evidence that fault-based compensation claims were associated with poorer health-related outcomes, and that lawyer involvement was associated with poorer work outcomes beyond 12 months post-injury. However, the evidence of negative associations between fault-based compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims).},
institution = {Monash U, Caulfield Hospital, Swansea U},
annotation = {Interesting for Text Mining},
addendum = {None},
}

@article{XING2020105343,
title = {Comparison of different models for evaluating vehicle collision risks at upstream diverging area of toll plaza},
journal = {Accident Analysis \& Prevention},
volume = {135},
number = {nan},
pages = {105343},
year = {2020},
author = {Lu Xing and Jie He and Ye Li and Yina Wu and Jinghui Yuan and Xin Gu},
keywords = {Collision risk, Trajectory data, Toll plaza, Diverging area, Logistic regression, Non-Parametric model},
abstract = {Toll plazas with both Electronic Toll Collection (ETC) lane(s) and Manual Toll Collection (MTC) lane(s) could increase crash risks especially at upstream diverging areas because of frequency lane-change behaviors. This study develops the logistic regression (LR) model and five typical non-parametric models including, K-Nearest Neighbor (KNN), Artificial Neural Networks (ANN), Support Vector Machines (SVM), Decision Trees (DT), and Random Forest (RF) to examine the relationship between influencing factors and vehicle collision risk. Based on the vehicle trajectory data extracted from unmanned aerial vehicle (UAV) videos using an automated video analysis system, the unconstrained vehicle motion’s collision risk can be evaluated by the extended time to collision (ETTC). Results of model performance comparison indicate that not all non-parametric models have a better prediction performance than the LR model. Specifically, the KNN, SVM, DT and RF models have better model performance than LR model in model training, while the ANN model has the worst model performance. In model prediction, the accuracy of LR model is higher than that of other five non-parametric models under various ETTC thresholds conditions. The LR model implies a pretty good performance and its results also indicate that vehicle yields the higher collision risk when it drives on the left side of toll plaza diverging area and more dangerous situations could be found for an ETC vehicle. Moreover, the vehicle collision risks are positively associated with the speed of the following vehicle and the angle between the leading vehicle speed vector and X axis. Furthermore, the results of DT model show that three factors play important roles in classifying vehicle collision risk and the effects of them on collision risk are consistent with the results of LR model. These findings provide valuable information for accurate assessment of collision risk, which is a key step toward improving safety performance of the toll plaza diverging area.},
institution = {Southeast U (Nanjing), Central South U (Changsha), U of Central Florida},
annotation = {Not our data, Automated analysis of video from drones},
addendum = {},
}

@article{YANG2019105296,
title = {Comparison among driving state prediction models for car-following condition based on EEG and driving features},
journal = {Accident Analysis \& Prevention},
volume = {133},
number = {nan},
pages = {105296},
year = {2019},
author = {Liu Yang and Wei Guan and Rui Ma and Xiaomeng Li},
keywords = {Driving behavior state, Electroencephalography, Independent component analysis, Feature extraction, Driving simulator},
abstract = {Risky driving states such as aggressive driving and unstable driving are the cause of many traffic accidents. Many studies have used either driving data or physiological data such as electroencephalography (EEG) to estimate and monitor driving states. However, few studies made comparison among those driving-feature-based, EEG-feature-based and hybrid-feature-based (combination of driving features and EEG features) models. Further, limited types of EEG features have been extracted and investigated in the existing studies. To fill these research gaps aforementioned, this study adopts two EEG analysis techniques (i.e., independent component analysis and brain source localization), two signal processing methods (i.e., power spectrum analysis and wavelets analysis) to extract twelve kinds of EEG features for the short-term driving state prediction. The prediction performance of driving features, EEG features and hybrid features of them was evaluated and compared. The results indicated that EEG-based model has better performance than driving-data-based model (i.e., 83.84\% versus 71.59\%) and the integrated model of driving features and the full brain regions features extracted by wavelet analysis outperforms other types of features with the highest accuracy of 86.27\%.},
institution = {Wuhan U of Technology, Beijing Jiaotong U, U of Alabama Huntsville, },
annotation = {Not our data, },
addendum = {},
}

@article{WALI2019105277,
title = {Exploring microscopic driving volatility in naturalistic driving environment prior to involvement in safety critical events—Concept of event-based driving volatility},
journal = {Accident Analysis \& Prevention},
volume = {132},
number = {nan},
pages = {105277},
year = {2019},
author = {Behram Wali and Asad J. Khattak and Thomas Karnowski},
keywords = {Naturalistic driving studies, Event-based volatility, Vehicular jerk, Crash, Near-crash, Crash propensity, Crash risk, Fixed and random parameters, Logit models},
abstract = {The sequence of instantaneous driving decisions and its variations, known as driving volatility, prior to involvement in safety critical events can be a leading indicator of safety. This study focuses on the component of “driving volatility matrix” related to specific normal and safety-critical events, named “event-based volatility.” The research issue is characterizing volatility in instantaneous driving decisions in the longitudinal and lateral directions, and how it varies across drivers involved in normal driving, crash, and/or near-crash events. To explore the issue, a rigorous quasi-experimental study design is adopted to help compare driving behaviors in normal vs unsafe outcomes. Using a unique real-world naturalistic driving database from the 2nd Strategic Highway Research Program (SHRP), a test set of 9593 driving events featuring 2.2 million temporal samples of real-world driving are analyzed. This study features a plethora of kinematic sensors, video, and radar spatiotemporal data about vehicle movement and therefore offers the opportunity to initiate such exploration. By using information related to longitudinal and lateral accelerations and vehicular jerk, 24 different aggregate and segmented measures of driving volatility are proposed that captures variations in extreme instantaneous driving decisions. In doing so, careful attention is given to the issue of intentional vs. unintentional volatility. The volatility indices, as leading indicators of near-crash and crash events, are then linked with safety critical events, crash propensity, and other event specific explanatory variables. Owing to the presence of unobserved heterogeneity and omitted variable bias, fixed- and random-parameter discrete choice models are developed that relate crash propensity to unintentional driving volatility and other factors. Statistically significant evidence is found that driver volatilities in near-crash and crash events are significantly greater than volatility in normal driving events. After controlling for traffic, roadway, and unobserved factors, the results suggest that greater intentional volatility increases the likelihood of both crash and near-crash events. A one-unit increase in intentional volatility is associated with positive vehicular jerk in longitudinal direction increases the chance of crash and near-crash outcome by 15.79 and 12.52 percentage points, respectively. Importantly, intentional volatility in positive vehicular jerk in lateral direction has more negative consequences than intentional volatility in positive vehicular jerk in longitudinal direction. Compared to acceleration/deceleration, vehicular jerk can better characterize the volatility in microscopic instantaneous driving decisions prior to involvement in safety critical events. Finally, the magnitudes of correlations exhibit significant heterogeneity, and that accounting for the heterogeneous effects in the modeling framework can provide more reliable and accurate results. The study demonstrates the value of quasi-experimental study design and big data analytics for understanding extreme driving behaviors in safe vs. unsafe driving outcomes.},
institution = {MIT, U of Tennessee, Oak Ridge},
annotation = {Not our data.},
addendum = {},
}

@article{XIONG201930,
title = {A forward collision avoidance algorithm based on driver braking behavior},
journal = {Accident Analysis \& Prevention},
volume = {129},
number = {nan},
pages = {30-43},
year = {2019},
author = {Xiaoxia Xiong and Meng Wang and Yingfeng Cai and Long Chen and Haneen Farah and Marjan Hagenzieker},
keywords = {Collision avoidance, Deceleration curve, Cluster analysis, Fuzzy logic, Driver braking behavior profile, Dynamic time warping},
abstract = {Measuring risk is critical for collision avoidance. The paper aims to develop an online risk level classification algorithm for forward collision avoidance systems. Assuming risk levels are reflected by braking profiles, deceleration curves from critical evasive braking events from the Virginia “100-car” database were first extracted. The curves are then clustered into different risk levels based on spectrum clustering, using curve distance and curve changing rate as dissimilarity metrics among deceleration curves. Fuzzy logic rules of safety indicators at critical braking onset for risk classification were then extracted according to the clustered risk levels. The safety indicators include time to collision, time headway, and final relative distance under emergency braking, which characterizes three kinds of uncertain critical conditions respectively. Finally, the obtained fuzzy risk level classification algorithm was tested and compared with other Automatic Emergency Braking (AEB) algorithms under Euro-NCAP testing scenarios in simulation. Results show the proposed algorithm is promising in balancing the objectives of avoiding collision and reducing interference with driver’s normal driving compared with other algorithms.},
institution = {Jiangsu U, Deft U},
annotation = {Not ML.  Interesting for (claim of) being new approach.},
addendum = {The proposed framework
provides a new perspective on real-time risk level classification and
collision avoidance system development. However, since there is a
limitation in data sample size representing critical event-reaction
braking, more deceleration profiles (by collecting more near-crash 
records from other resources) should be explored to improve parameter
tuning of the proposed fuzzy logic in the future (especially obtaining
more higher-speed observations to overcome the current limitation in
the algorithm for higher-speed braking scenarios). Besides, traffic/
driver/vehicle characteristics (such as vehicle type, driver state, and
vehicle response during braking, etc.) need to be investigated in future
research concerning their possible effects on timing of critical braking.
Also, variations of safety indicators representing uncertain critical
driving scenarios could be further considered, and the probability of the
uncertain scenarios could also be explored (by predicting accelerating/
decelerating behaviors of SV and POV in V2V environments) and introduced
into the fuzzy logic (by assigning probability-based weights of
fuzzy rules) to improve its risk level classification performance. In addition,
other machine learning classification algorithms (such as
Support Vector Machine) instead of fuzzy logic could be explored to
learn the effective representation of risk levels derived from offline
deceleration profiles in further study.},
}

@article{YU201970,
title = {Exploring crash mechanisms with microscopic traffic flow variables: A hybrid approach with latent class logit and path analysis models},
journal = {Accident Analysis \& Prevention},
volume = {125},
number = {nan},
pages = {70-78},
year = {2019},
author = {Rongjie Yu and Yin Zheng and Mohamed Abdel-Aty and Zhen Gao},
keywords = {Crash mechanism, Microscopic traffic flow variables, Heterogeneous effects, Latent class logit, Path analysis},
abstract = {Understanding the occurrence mechanisms of crashes is critical for traffic safety improvement. Efforts have been investigated to reveal the crash mechanisms and analyze the contributing factors from the aspects of vehicle, driver, and operational perspectives. In this study, special attention has been paid to the operational level analyses while bridging the research gaps of: (1) failing to identify the heterogeneous impact of microscopic traffic flow variables on crash occurrence, and (2) focusing on correlation effects without further investigations for the causal relationships. A hybrid modeling approach with latent class logit (LCL) and path analysis (PA) models was proposed to account for the heterogeneous influencing effects and reveal the causal relationships between crash occurrence and microscopic traffic flow variables. Data from Shanghai urban expressway system were utilized for the empirical analyses. First, the LCL model has concluded four latent subsets of crash occurrence influencing factors. Then, PA models were conducted to identify the concurrent relationships (direct and indirect eﬀ ;ects) for the four sets of crash occurrence influencing factors separately. Finally, the results of the LCL model and PA models were compared and the crash-prone scenarios were inferred. And the potential safety improvement countermeasures were discussed.},
institution = {Tongj U, U of Central Florida},
annotation = {Not our data},
addendum = {However, given the interesting findings from the proposed modeling
approach, there are still several limitations of the current study.
(1) First, this study employed matched case-control data structure with
a fixed crash and non-crash ratio (1:4) to deal with the imbalanced
crash risk analysis dataset. In future studies, other sampling techniques,
such as over-sampling methods of synthetic minority oversampling
technique (SMOTE) (Chawla et al., 2002) and full-size
data would be tested. And the effects of sampling methods on the
concurrent microscopic influencing factors need to be revealed.
(2) Second, this study utilized the LCL model to group observations to
account for the heterogeneity issues, and future efforts would be
conducted to identify how to improve the proposed hybrid approach
from the aspects of incorporating other clustering methods,
such finite mixture model (FMM) (Park and Lord, 2009).
(3) Moreover, after applying the LCL model to solve the heterogeneity
issues, repeated measures still exist within a latent class. In this
study, the matched case-control data preparation process can
greatly reduce the impacts of repeated measures on the analysis
results. While in future studies, other methods would be tested to
solve this repeated measurement issues, such as incorporating the
LCL model with roadway section unique random effect terms.
(4) In addition, in this study, the PA models were employed to conduct
the causal inference, which is a typical mediation analysis method.
Additional efforts are needed to utilize other causal inference
methods (Pearl, 2018), like propensity score matching (PSM) (Li
et al., 2013; Li and Graham, 2016), to further explorations the
causal relationships between crash occurrence and the microscopic
traffic flow variables.},
}

@article{PARSA2020105405,
title = {Toward safer highways, application of XGBoost and SHAP for real-time accident detection and feature analysis},
journal = {Accident Analysis \& Prevention},
volume = {136},
number = {nan},
pages = {105405},
year = {2020},
author = {Amir Bahador Parsa and Ali Movahedi and Homa Taghipour and Sybil Derrible and Abolfazl (Kouros) Mohammadian},
keywords = {Accident detection, XGBoost, SHAP, Real time data, Machine learning},
abstract = {Detecting traffic accidents as rapidly as possible is essential for traffic safety. In this study, we use eXtreme Gradient Boosting (XGBoost)—a Machine Learning (ML) technique—to detect the occurrence of accidents using a set of real time data comprised of traffic, network, demographic, land use, and weather features. The data used from the Chicago metropolitan expressways was collected between December 2016 and December 2017, and it includes 244 traffic accidents and 6073 non-accident cases. In addition, SHAP (SHapley Additive exPlanation) is employed to interpret the results and analyze the importance of individual features. The results show that XGBoost can detect accidents robustly with an accuracy, detection rate, and a false alarm rate of 99 \%, 79 \%, and 0.16 \%, respectively. Several traffic related features, especially difference of speed between 5 min before and 5 min after an accident, are found to have relatively more impact on the occurrence of accidents. Furthermore, a feature dependency analysis is conducted for three pairs of features. First, average daily traffic and speed after accidents/non-accidents time at the upstream location are interpreted jointly. Then, distance to Central Business District and residential density are analyzed. Finally, speed after accidents/non-accidents time at upstream location and speed after accidents/non-accidents time at downstream location are evaluated with respect to the model’s output.},
institution = {U of Illinois at Chicago},
annotation = {},
addendum = {},
}


